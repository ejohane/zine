{"id":"zine-lfp","title":"Frontend Spec Review: Gaps, Inconsistencies, and Refinements","description":"Comprehensive review of features/subscriptions/frontend-spec.md identifying gaps, inconsistencies, missing context, and areas needing refinement. This epic tracks all findings from the spec proofreading and polish session.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-16T22:03:05.293187-06:00","updated_at":"2025-12-16T22:03:05.293187-06:00"}
{"id":"zine-lfp.1","title":"Missing hook implementations referenced in Settings screen","description":"**Issue**: The Settings screen (Section 3) references hooks that are not defined anywhere in the spec:\n- `useConnections()` - returns `{ data: connections }`\n- `useSubscriptions()` - returns `{ data: subscriptions }`\n\n**Location**: Lines 281-286 in frontend-spec.md\n\n**Problem**: These hooks are used to fetch provider connections and subscriptions, but there's no definition of:\n1. The hook implementation\n2. The tRPC endpoints they call\n3. The return type shape\n\n**Fix Required**: Add a dedicated \"Data Hooks\" section defining:\n```typescript\n// apps/mobile/hooks/use-connections.ts\nexport function useConnections() {\n  return trpc.subscriptions.connections.list.useQuery();\n}\n```\n\nAnd document the expected return types from the backend.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:05.366678-06:00","updated_at":"2025-12-16T22:03:14.592406-06:00","dependencies":[{"issue_id":"zine-lfp.1","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.367044-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.10","title":"Navigation structure missing settings layout file","description":"**Issue**: The navigation structure (Section 2) shows `settings/` as a route group but Expo Router requires a `_layout.tsx` file for navigation configuration.\n\n**Current structure** (lines 191-205):\n```\nsettings/\n├── index.tsx        # Settings main screen\n├── connections.tsx  # Manage connected providers\n├── account.tsx      # Account settings\n└── about.tsx        # App info, version, etc.\n```\n\n**Missing**:\n- `settings/_layout.tsx` - Required for:\n  - Stack navigator configuration\n  - Header styling\n  - Back navigation behavior\n  - Screen transition animations\n\n**Fix Required**: Add layout file specification:\n```typescript\n// apps/mobile/app/settings/_layout.tsx\nimport { Stack } from 'expo-router';\n\nexport default function SettingsLayout() {\n  return (\n    \u003cStack\n      screenOptions={{\n        headerBackTitle: 'Settings',\n        headerStyle: { backgroundColor: colors.background },\n        headerTintColor: colors.text,\n      }}\n    \u003e\n      \u003cStack.Screen name=\"index\" options={{ title: 'Settings' }} /\u003e\n      \u003cStack.Screen name=\"connections\" options={{ title: 'Connected Accounts' }} /\u003e\n      \u003cStack.Screen name=\"account\" options={{ title: 'Account' }} /\u003e\n      \u003cStack.Screen name=\"about\" options={{ title: 'About' }} /\u003e\n    \u003c/Stack\u003e\n  );\n}\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.008989-06:00","updated_at":"2025-12-16T22:04:09.809088-06:00","dependencies":[{"issue_id":"zine-lfp.10","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.009344-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.11","title":"Error boundary examples mix Tailwind classes with StyleSheet","description":"**Issue**: Error boundary components (Section 8) mix Tailwind/NativeWind className syntax with React Native's StyleSheet approach, creating inconsistent and potentially non-functional code.\n\n**Examples**:\n- Line 1147: `\u003cView className=\"flex-1 items-center justify-center p-6\"\u003e`\n- Line 1149: `\u003cText className=\"text-xl font-semibold mb-2 text-gray-900 dark:text-white\"\u003e`\n- Line 1155: `\u003cPressable onPress={this.handleReset} className=\"bg-blue-500 px-6 py-3 rounded-lg\"\u003e`\n\n**Problem**: \n1. The codebase doesn't appear to use NativeWind (not in package.json, no nativewind config visible)\n2. Even if using NativeWind, dark mode classes (`dark:text-white`) require additional configuration\n3. Mixing approaches makes code harder to maintain\n\n**The Settings screen example** (Section 3) correctly uses StyleSheet:\n```typescript\nconst styles = StyleSheet.create({\n  sectionTitle: { fontSize: 12, fontWeight: '600', ... },\n});\n```\n\n**Fix Required**: Convert all className usage to StyleSheet, using the design system tokens:\n```typescript\n\u003cView style={[styles.container, { backgroundColor: colors.background }]}\u003e\n  \u003cText style={[styles.heading, { color: colors.text }]}\u003eSomething went wrong\u003c/Text\u003e\n\u003c/View\u003e\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.07911-06:00","updated_at":"2025-12-16T22:04:16.173998-06:00","dependencies":[{"issue_id":"zine-lfp.11","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.079441-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.12","title":"Missing TypeScript interface for InboxItem used in renderItem","description":"**Issue**: The inbox screen example (Section 6.2) uses `InboxItem` type in `renderItem` (line 606) but this type is never defined.\n\n**Code reference**:\n```typescript\nrenderItem={renderItem}\n// ...\n\u003cFlatList\n  data={data.items as InboxItem[]}\n```\n\n**The existing codebase** defines `ItemWithUserState` in `apps/mobile/hooks/use-items.ts`:\n```typescript\nexport interface ItemWithUserState {\n  item: { id, title, summary, creator, ... };\n  userItem: { id, itemId, state, ingestedAt, ... };\n}\n```\n\n**Missing**:\n1. `InboxItem` interface definition\n2. How it differs from `ItemWithUserState` (if at all)\n3. Whether it includes subscription-specific fields (source attribution, sync status)\n\n**Fix Required**: Either:\n1. Define `InboxItem` interface with subscription source info:\n```typescript\ninterface InboxItem extends ItemWithUserState {\n  subscription?: {\n    id: string;\n    name: string;\n    provider: 'YOUTUBE' | 'SPOTIFY';\n    imageUrl?: string;\n  };\n}\n```\n2. Or clarify that `InboxItem` is just an alias for `ItemWithUserState`","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.148812-06:00","updated_at":"2025-12-16T22:04:21.403728-06:00","dependencies":[{"issue_id":"zine-lfp.12","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.149133-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.13","title":"Offline queue retry logic lacks error type discrimination","description":"**Issue**: The offline queue's `executeAction` method (Section 9.3, lines 1519-1535) catches all errors uniformly but should discriminate between error types for proper retry behavior.\n\n**Current code**:\n```typescript\nfor (const action of queue) {\n  try {\n    await this.executeAction(action);\n  } catch (error) {\n    if (action.retryCount \u003c 3) {\n      remainingActions.push({\n        ...action,\n        retryCount: action.retryCount + 1,\n        lastError: error instanceof Error ? error.message : 'Unknown error',\n      });\n    }\n  }\n}\n```\n\n**Problem**: All errors are treated the same, but:\n1. **Network errors** - Should retry (temporary failure)\n2. **4xx client errors** - Should NOT retry (permanent failure)\n3. **401 Unauthorized** - Should refresh auth and retry once\n4. **409 Conflict** - Subscription already exists, resolve differently\n\n**Fix Required**: Add error type discrimination:\n```typescript\ncatch (error) {\n  const shouldRetry = isRetryableError(error);\n  const isAuthError = error.data?.code === 'UNAUTHORIZED';\n  \n  if (isAuthError) {\n    await refreshAuthAndRetry(action);\n  } else if (shouldRetry \u0026\u0026 action.retryCount \u003c 3) {\n    remainingActions.push({ ...action, retryCount: action.retryCount + 1 });\n  } else {\n    // Permanent failure - notify user, remove from queue\n    await notifyActionFailed(action, error);\n  }\n}\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.22131-06:00","updated_at":"2025-12-16T22:04:27.663581-06:00","dependencies":[{"issue_id":"zine-lfp.13","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.221636-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.14","title":"Deep linking configuration references incorrect plugin syntax","description":"**Issue**: The app.json deep linking configuration (Section 7.1, line 823) uses incorrect Expo plugin syntax.\n\n**Current** (line 823):\n```json\n\"plugins\": [\"expo-router\", \"expo-secure-store\", [\"expo-linking\", { \"scheme\": \"zine\" }]]\n```\n\n**Problems**:\n1. `expo-linking` is not a valid Expo plugin - it's a core Expo module\n2. The `scheme` should be defined at the root level of app.json, not as a plugin config\n3. For Expo SDK 50+, scheme handling is automatic when `scheme` is set at root\n\n**Correct configuration**:\n```json\n{\n  \"expo\": {\n    \"name\": \"zine\",\n    \"slug\": \"zine\",\n    \"scheme\": \"zine\",\n    // ...\n    \"plugins\": [\n      \"expo-router\",\n      \"expo-secure-store\"\n    ]\n  }\n}\n```\n\n**Additional notes**:\n- `expo-web-browser` may need to be added to plugins if using `openAuthSessionAsync`\n- For production, may need `expo-linking` plugin only if customizing URL handling beyond the scheme","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:06.291247-06:00","updated_at":"2025-12-16T22:04:32.972774-06:00","dependencies":[{"issue_id":"zine-lfp.14","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.291614-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.15","title":"Missing Replicache integration context from local-first architecture","description":"**Issue**: The frontend spec's offline handling (Section 9) doesn't integrate with the local-first architecture documented in `docs/zine-sync-local-first.md`.\n\n**Architecture doc states**:\n- Replicache is the sync protocol\n- Client data is denormalized KV store\n- Server-authoritative truth via Durable Objects\n- Index strategy: `item/{id}`, `state/{id}`, `idx/list/{state}/{timeKey}/{id}`\n\n**Frontend spec states**:\n- Uses `AsyncStorage` for offline queue (line 1425)\n- Uses React Query for caching (`staleTime`, `gcTime`)\n- Uses tRPC directly with `fetch` under the hood\n\n**Disconnect**:\n1. If using Replicache, mutations should go through Replicache mutators, not tRPC directly\n2. Offline queue duplicates what Replicache provides natively\n3. React Query caching conflicts with Replicache's local KV store\n\n**Fix Required**: Clarify the architecture choice:\n- **Option A**: Remove offline queue, use Replicache for all data sync (aligns with local-first doc)\n- **Option B**: Clarify that subscriptions feature uses tRPC directly (not Replicache) and update local-first doc\n- **Option C**: Document hybrid approach where subscription metadata uses tRPC but inbox items use Replicache\n\nAdd a \"Data Architecture\" section to frontend spec explaining the relationship.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:06.36168-06:00","updated_at":"2025-12-16T22:04:40.962994-06:00","dependencies":[{"issue_id":"zine-lfp.15","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.36203-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.16","title":"SyncStatusIndicator animation may cause memory leak","description":"**Issue**: The `SyncStatusIndicator` component (Section 9.7, lines 1787-1834) has a potential memory leak in its animation effect.\n\n**Current code**:\n```typescript\nuseEffect(() =\u003e {\n  if (pendingCount \u003e 0) {\n    const pulse = Animated.loop(\n      Animated.sequence([\n        Animated.timing(pulseAnim, { toValue: 0.5, duration: 500, useNativeDriver: true }),\n        Animated.timing(pulseAnim, { toValue: 1, duration: 500, useNativeDriver: true }),\n      ])\n    );\n    pulse.start();\n    return () =\u003e pulse.stop();\n  } else {\n    pulseAnim.setValue(1);\n  }\n}, [pendingCount, pulseAnim]);\n```\n\n**Problems**:\n1. `pulseAnim` is a `useRef` value but is in the dependency array - this is unusual and may cause issues\n2. The cleanup only runs when `pendingCount` changes, not on unmount\n3. Missing cleanup for the case when component unmounts while `pendingCount === 0`\n\n**Fix Required**:\n```typescript\nconst pulseAnim = useRef(new Animated.Value(1)).current;\nconst animationRef = useRef\u003cAnimated.CompositeAnimation | null\u003e(null);\n\nuseEffect(() =\u003e {\n  if (pendingCount \u003e 0) {\n    animationRef.current = Animated.loop(\n      Animated.sequence([\n        Animated.timing(pulseAnim, { toValue: 0.5, duration: 500, useNativeDriver: true }),\n        Animated.timing(pulseAnim, { toValue: 1, duration: 500, useNativeDriver: true }),\n      ])\n    );\n    animationRef.current.start();\n  } else {\n    pulseAnim.setValue(1);\n  }\n\n  return () =\u003e {\n    animationRef.current?.stop();\n  };\n}, [pendingCount]); // Remove pulseAnim from deps\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.432299-06:00","updated_at":"2025-12-16T22:04:46.940703-06:00","dependencies":[{"issue_id":"zine-lfp.16","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.432672-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.17","title":"OAuth error handler completeOAuthFlow function not defined","description":"**Issue**: The `OAuthCallbackHandler` component (Section 7.6) calls `completeOAuthFlow` (line 943) which is dynamically imported but never defined anywhere in the spec.\n\n**Code reference**:\n```typescript\nconst { completeOAuthFlow } = await import('../lib/oauth');\nconst result = await completeOAuthFlow(params.code, params.state);\n```\n\n**Expected function signature**:\n```typescript\ninterface OAuthFlowResult {\n  success: boolean;\n  provider?: 'YOUTUBE' | 'SPOTIFY';\n  error?: string;\n}\n\nasync function completeOAuthFlow(code: string, state: string): Promise\u003cOAuthFlowResult\u003e\n```\n\n**Required implementation**:\n1. Parse provider from state (see bead zine-lfp.7)\n2. Retrieve PKCE verifier from SecureStore\n3. Call `trpc.subscriptions.connections.callback.mutate()`\n4. Clean up SecureStore entries\n5. Return success/failure with provider info\n\n**Fix Required**: Add complete function definition to Section 1 (OAuth Configuration):\n```typescript\nexport async function completeOAuthFlow(code: string, state: string): Promise\u003cOAuthFlowResult\u003e {\n  const [provider, stateId] = state.split(':') as ['YOUTUBE' | 'SPOTIFY', string];\n  \n  const storedState = await SecureStore.getItemAsync(`${provider.toLowerCase()}_oauth_state`);\n  if (storedState !== state) {\n    return { success: false, error: 'State mismatch' };\n  }\n  \n  const verifier = await SecureStore.getItemAsync(`${provider.toLowerCase()}_code_verifier`);\n  if (!verifier) {\n    return { success: false, error: 'Verifier not found' };\n  }\n  \n  try {\n    await trpc.subscriptions.connections.callback.mutate({ provider, code, state: stateId, codeVerifier: verifier });\n    await SecureStore.deleteItemAsync(`${provider.toLowerCase()}_code_verifier`);\n    await SecureStore.deleteItemAsync(`${provider.toLowerCase()}_oauth_state`);\n    return { success: true, provider };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n}\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:06.504364-06:00","updated_at":"2025-12-16T22:04:55.331573-06:00","dependencies":[{"issue_id":"zine-lfp.17","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.504695-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.18","title":"Missing Surface component import in inbox screen example","description":"**Issue**: The inbox screen example (Section 6.2) uses a `Surface` component as its root container but never imports or defines it.\n\n**Code reference** (line 576):\n```typescript\nreturn (\n  \u003cSurface style={[styles.container, { backgroundColor: colors.background }]}\u003e\n    \u003cSafeAreaView style={styles.safeArea} edges={['top']}\u003e\n```\n\n**Problem**: `Surface` is not a standard React Native component. It could be:\n1. A custom component from a UI library (e.g., react-native-paper)\n2. A custom component from the codebase\n3. A typo/mistake (should be `View`)\n\n**Looking at the codebase**: There's no `Surface` component in `apps/mobile/components/`\n\n**Fix Required**: Either:\n1. Define `Surface` component (if it's meant to provide elevation/shadow):\n```typescript\n// apps/mobile/components/surface.tsx\nexport function Surface({ style, children, ...props }) {\n  return (\n    \u003cView style={[Shadows.sm, style]} {...props}\u003e\n      {children}\n    \u003c/View\u003e\n  );\n}\n```\n\n2. Or replace with `View` if `Surface` provides no additional functionality:\n```typescript\nreturn (\n  \u003cView style={[styles.container, { backgroundColor: colors.background }]}\u003e\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.579381-06:00","updated_at":"2025-12-16T22:05:00.045399-06:00","dependencies":[{"issue_id":"zine-lfp.18","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.579749-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.19","title":"Inconsistent RefreshControl props between empty and populated states","description":"**Issue**: The inbox screen's RefreshControl props differ between the empty state ScrollView and the populated FlatList, leading to inconsistent behavior.\n\n**Empty state** (lines 595-600):\n```typescript\n\u003cRefreshControl\n  refreshing={isRefreshing}\n  onRefresh={handleRefresh}\n  tintColor={colors.primary}\n/\u003e\n```\n\n**Populated state** (lines 611-618):\n```typescript\n\u003cRefreshControl\n  refreshing={isRefreshing}\n  onRefresh={handleRefresh}\n  tintColor={colors.primary}\n  colors={[colors.primary]}  // Android-specific, missing from empty state\n  progressBackgroundColor={colors.background}  // Android-specific, missing from empty state\n/\u003e\n```\n\n**Problems**:\n1. Android users will see different refresh indicator styling between empty and populated states\n2. The `colors` prop is an array (Android uses multiple colors in sequence)\n3. Missing `progressViewOffset` for consistent positioning\n\n**Fix Required**: Create a shared RefreshControl configuration:\n```typescript\nconst refreshControlProps = {\n  refreshing: isRefreshing,\n  onRefresh: handleRefresh,\n  tintColor: colors.primary,\n  colors: [colors.primary],\n  progressBackgroundColor: colors.background,\n  progressViewOffset: 0,\n};\n\n// Usage:\n\u003cRefreshControl {...refreshControlProps} /\u003e\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.650037-06:00","updated_at":"2025-12-16T22:05:05.048222-06:00","dependencies":[{"issue_id":"zine-lfp.19","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.650378-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.2","title":"Inconsistent theme token usage across code examples","description":"**Issue**: Code examples inconsistently use theme tokens. Some use the design system (Colors, Spacing, Radius from @/constants/theme), while others use hardcoded values or Tailwind-style classes.\n\n**Examples of inconsistency**:\n1. Settings screen (line 296): Uses `{ backgroundColor: colors.card }` - correct\n2. Error boundaries (line 1147): Uses `className=\"flex-1 items-center justify-center p-6\"` - Tailwind\n3. SyncNowButton (line 698): Uses `className=\"px-3 py-1.5 rounded-full\"` - Tailwind\n4. OfflineBanner (line 1410): Uses `className=\"absolute top-0...\"` - Tailwind\n\n**Problem**: The actual codebase uses React Native StyleSheet (see apps/mobile/constants/theme.ts), not Tailwind/NativeWind class-based styling. The spec should be consistent with the existing architecture.\n\n**Fix Required**: Decide on styling approach and update all examples to match. If using NativeWind, add it to the tech stack section. If using StyleSheet, convert all Tailwind classes to proper RN styles.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:05.437392-06:00","updated_at":"2025-12-16T22:03:20.770569-06:00","dependencies":[{"issue_id":"zine-lfp.2","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.437755-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.20","title":"Settings screen missing imports section and hook definitions","description":"**Issue**: The Settings screen code (Section 3) jumps directly into the component without showing necessary imports, making it incomplete as a reference implementation.\n\n**Missing imports**:\n```typescript\n// Required imports not shown:\nimport { View, Text, ScrollView, Pressable, StyleSheet } from 'react-native';\nimport { useRouter } from 'expo-router';\nimport { SafeAreaView } from 'react-native-safe-area-context';\nimport { Colors, Typography, Spacing, Radius } from '@/constants/theme';\nimport { useColorScheme } from '@/hooks/use-color-scheme';\nimport { useAuth } from '@/providers/auth-provider';\n\n// These hooks are used but not defined:\nimport { useConnections } from '@/hooks/use-connections';\nimport { useSubscriptions } from '@/hooks/use-subscriptions';\n```\n\n**Missing hook definitions**:\n1. `useConnections()` - Should return provider connection status\n2. `useSubscriptions()` - Should return subscription list with count\n\n**Fix Required**: \n1. Add imports section at top of code block\n2. Add \"Prerequisites\" callout noting dependent hooks\n3. Either inline simple hook implementations or reference a \"Data Hooks\" section:\n\n```typescript\n// apps/mobile/hooks/use-connections.ts\nexport function useConnections() {\n  return trpc.subscriptions.connections.list.useQuery();\n}\n\n// apps/mobile/hooks/use-subscriptions.ts  \nexport function useSubscriptions() {\n  return trpc.subscriptions.list.useQuery({});\n}\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:06.720179-06:00","updated_at":"2025-12-16T22:05:12.014927-06:00","dependencies":[{"issue_id":"zine-lfp.20","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:06.720517-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.3","title":"PKCE generatePKCE function has incorrect base64URLEncode logic","description":"**Issue**: The PKCE `base64URLEncode` function (lines 163-166) has incorrect logic that will produce invalid challenges.\n\n**Current code**:\n```typescript\nfunction base64URLEncode(input: Uint8Array | string): string {\n  const base64 = typeof input === 'string' ? input : btoa(String.fromCharCode(...input));\n  return base64.replace(/\\+/g, '-').replace(/\\//g, '_').replace(/=/g, '');\n}\n```\n\n**Problems**:\n1. When `input` is already a base64 string (from `Crypto.digestStringAsync`), the function doesn't re-encode it - it just does URL-safe replacement. But the digest result needs different handling.\n2. `Crypto.digestStringAsync` with `BASE64` encoding returns standard base64, but the verifier encoding from `Uint8Array` uses a different path.\n3. The verifier should be base64url-encoded from raw bytes, but the challenge is SHA256(verifier) encoded to base64url.\n\n**Correct implementation**:\n```typescript\nfunction base64URLEncode(buffer: Uint8Array): string {\n  return btoa(String.fromCharCode(...buffer))\n    .replace(/\\+/g, '-')\n    .replace(/\\//g, '_')\n    .replace(/=/g, '');\n}\n\nasync function generatePKCE() {\n  const randomBytes = await Crypto.getRandomBytesAsync(32);\n  const verifier = base64URLEncode(randomBytes);\n  \n  const digestBuffer = await Crypto.digest(\n    Crypto.CryptoDigestAlgorithm.SHA256,\n    new TextEncoder().encode(verifier)\n  );\n  const challenge = base64URLEncode(new Uint8Array(digestBuffer));\n  \n  return { verifier, challenge };\n}\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:05.510528-06:00","updated_at":"2025-12-16T22:03:28.104619-06:00","dependencies":[{"issue_id":"zine-lfp.3","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.510895-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.4","title":"Missing tRPC procedure definitions referenced in frontend","description":"**Issue**: The frontend spec references tRPC procedures that aren't fully aligned with the backend spec's API design.\n\n**Frontend references**:\n- `trpc.subscriptions.connections.registerState.mutate()` (line 74)\n- `trpc.subscriptions.connections.callback.mutate()` (line 128)\n- `trpc.subscriptions.add.mutate()` (line 1524)\n- `trpc.subscriptions.remove.mutate()` (line 1526)\n- `trpc.subscriptions.pause.mutate()` (line 1528)\n- `trpc.subscriptions.resume.mutate()` (line 1534)\n\n**Backend spec defines** (Section 5.1):\n- `subscriptions.connections.list` - Query\n- `subscriptions.connections.registerState` - Mutation\n- `subscriptions.connections.callback` - Mutation\n- `subscriptions.connections.disconnect` - Mutation\n- `subscriptions.add` - Mutation\n- `subscriptions.remove` - Mutation\n- `subscriptions.pause` - Mutation\n- `subscriptions.resume` - Mutation\n- `subscriptions.syncNow` - Mutation\n\n**Missing from backend spec**:\n- Input/output type definitions for each procedure\n- Full procedure signatures with Zod schemas\n\n**Fix Required**: Add a \"tRPC Contract\" section to frontend spec that explicitly lists all procedures with their input/output types, OR add these to backend spec and cross-reference.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:05.580958-06:00","updated_at":"2025-12-16T22:03:33.742606-06:00","dependencies":[{"issue_id":"zine-lfp.4","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.58132-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.5","title":"Inbox screen code example imports non-existent components","description":"**Issue**: The Inbox screen code example (Section 6.2, lines 553-625) imports/uses components that aren't defined anywhere:\n- `Surface` - used as root container, never imported or defined\n- `LoadingState` - referenced but not defined\n- `ErrorState` - referenced but not defined  \n- `EmptyState` - referenced but not defined\n- `useInboxItems` - different signature than the one in apps/mobile/hooks/use-items.ts\n\n**The actual codebase** (apps/mobile/hooks/use-items.ts) shows `useInboxItems()` returns `ItemWithUserState[]`, not `{ data, isLoading, error, refetch }`.\n\n**Fix Required**:\n1. Define or import `Surface`, `LoadingState`, `ErrorState`, `EmptyState` components\n2. Align the hook signature - either update the spec to match existing code, or document that this is a new API\n3. Add imports section to the code example","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:05.653456-06:00","updated_at":"2025-12-16T22:03:38.514682-06:00","dependencies":[{"issue_id":"zine-lfp.5","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.653815-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.6","title":"useSyncNow hook referenced but not defined in spec","description":"**Issue**: The `useSyncNow` hook is used in `SyncNowButton` component (line 645) but never defined in the spec.\n\n**Usage**:\n```typescript\nconst { syncNow, isLoading, cooldownSeconds, lastResult } = useSyncNow(subscriptionId);\n```\n\n**Expected behavior** (from context):\n- Calls `trpc.subscriptions.syncNow.mutate({ subscriptionId })`\n- Handles 5-minute cooldown per subscription (backend rate limit)\n- Tracks last result for success/error feedback\n\n**Missing definition should include**:\n1. Hook implementation with tRPC mutation\n2. Cooldown state management\n3. Result caching for UI feedback\n4. Error handling for `TOO_MANY_REQUESTS` response\n\n**Fix Required**: Add complete hook implementation:\n```typescript\n// apps/mobile/hooks/use-sync-now.ts\nexport function useSyncNow(subscriptionId: string) {\n  const [cooldownSeconds, setCooldownSeconds] = useState(0);\n  const [lastResult, setLastResult] = useState\u003cSyncResult | null\u003e(null);\n  \n  const mutation = trpc.subscriptions.syncNow.useMutation({\n    onSuccess: (data) =\u003e {\n      setLastResult({ success: true, itemsFound: data.itemsFound });\n      setCooldownSeconds(300); // 5 minutes\n    },\n    onError: (error) =\u003e {\n      if (error.data?.code === 'TOO_MANY_REQUESTS') {\n        // Parse cooldown from error\n      }\n      setLastResult({ success: false, message: error.message });\n    },\n  });\n  \n  return { syncNow: mutation.mutate, isLoading: mutation.isPending, cooldownSeconds, lastResult };\n}\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:05.724523-06:00","updated_at":"2025-12-16T22:03:45.315849-06:00","dependencies":[{"issue_id":"zine-lfp.6","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.724888-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.7","title":"OAuth callback handler lacks provider identification logic","description":"**Issue**: The OAuth callback handler (Section 7.6, lines 896-976) parses the callback URL but doesn't determine which provider the callback is for.\n\n**Current code** (line 943):\n```typescript\nconst result = await completeOAuthFlow(params.code, params.state);\n```\n\n**Problem**: The `completeOAuthFlow` function needs to know the provider to:\n1. Retrieve the correct PKCE verifier from SecureStore (`${provider}_code_verifier`)\n2. Retrieve the correct state from SecureStore (`${provider}_oauth_state`)\n3. Call the correct tRPC procedure\n\nBut the callback URL `zine://oauth/callback?code=xxx\u0026state=yyy` doesn't include the provider.\n\n**Solutions**:\n1. **Encode provider in state**: Make state = `${provider}:${uuid}` and parse it\n2. **Use provider-specific callback URLs**: `zine://oauth/youtube/callback` vs `zine://oauth/spotify/callback`\n3. **Lookup state in SecureStore**: Try both providers' stored states to find a match\n\n**Fix Required**: Implement provider identification. Recommended approach is option 1 (encode in state) as it's simplest and aligns with common OAuth patterns:\n```typescript\nconst state = `${provider}:${crypto.randomUUID()}`;\n// Later: const [provider, stateId] = returnedState.split(':');\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:05.796803-06:00","updated_at":"2025-12-16T22:03:51.357893-06:00","dependencies":[{"issue_id":"zine-lfp.7","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.797124-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.8","title":"Missing connection between offline queue and tRPC client","description":"**Issue**: The offline queue (Section 9.3) stores actions but the tRPC client isn't configured to use it. There's a disconnect between the queue and actual mutation execution.\n\n**Current architecture**:\n1. `useOfflineMutation` checks `isOnline` and queues if offline\n2. `offlineQueue.processQueue()` calls tRPC endpoints directly via dynamic import\n\n**Problems**:\n1. The queue imports tRPC client dynamically (line 1520): `const { trpc } = await import('./trpc')` - this creates a new client instance\n2. No integration with React Query's mutation cache\n3. Optimistic updates in `useOfflineMutation` won't sync with the actual tRPC query cache when queue processes\n\n**Missing integration points**:\n1. Configure `trpc.subscriptions.add` to automatically queue when offline instead of requiring a wrapper hook\n2. Sync queue processing results back to React Query cache\n3. Handle conflicts when queue processes (e.g., subscription was already added on another device)\n\n**Fix Required**: Document integration pattern between offline queue and tRPC client, potentially using tRPC's `links` feature for offline-first behavior:\n```typescript\n// trpc.ts\nconst offlineLink = () =\u003e {\n  return ({ op, next }) =\u003e {\n    if (!isOnline() \u0026\u0026 op.type === 'mutation') {\n      return offlineQueue.enqueue(op);\n    }\n    return next(op);\n  };\n};\n```","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:03:05.869323-06:00","updated_at":"2025-12-16T22:03:58.591155-06:00","dependencies":[{"issue_id":"zine-lfp.8","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.869673-06:00","created_by":"daemon"}]}
{"id":"zine-lfp.9","title":"useSubscriptions hook references non-existent tRPC endpoints","description":"**Issue**: The `useSubscriptions` hook (Section 9.5, lines 1637-1718) references tRPC endpoints that don't match the backend spec's router structure.\n\n**Frontend hook uses**:\n- `trpc.subscriptions.list.useQuery({})` \n- `utils.client.subscriptions.add.mutate(payload)`\n- `utils.client.subscriptions.remove.mutate(payload)`\n\n**Backend spec defines** (Section 5.1):\n- `subscriptions.list` with input `{ provider?, status?, limit, cursor }`\n- `subscriptions.add` with input `{ provider, providerChannelId, name?, imageUrl? }`\n- `subscriptions.remove` with input `{ subscriptionId }`\n\n**Mismatches**:\n1. Frontend passes empty object `{}` to list, but backend expects optional pagination params\n2. Frontend `add` payload includes `{ provider, providerChannelId, name, imageUrl }` which matches\n3. Frontend `remove` payload uses `{ subscriptionId }` which matches\n4. Missing: Frontend doesn't handle cursor-based pagination from list response\n\n**Fix Required**: \n1. Update hook to handle pagination: `{ items, nextCursor, hasMore }`\n2. Add infinite query support for subscription list\n3. Align input types with Zod schemas from backend","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-16T22:03:05.938273-06:00","updated_at":"2025-12-16T22:04:04.555822-06:00","dependencies":[{"issue_id":"zine-lfp.9","depends_on_id":"zine-lfp","type":"parent-child","created_at":"2025-12-16T22:03:05.938617-06:00","created_by":"daemon"}]}
{"id":"zine-teq","title":"Subscriptions Backend Implementation","description":"Complete backend implementation for the Zine subscriptions feature, enabling users to subscribe to YouTube channels and Spotify podcasts with automated content polling and inbox delivery.\n\n## Overview\nThis epic implements the server-side infrastructure for subscriptions as specified in features/subscriptions/backend-spec.md. The feature allows users to:\n- Connect their YouTube and Spotify accounts via OAuth\n- Subscribe to channels/shows from those providers\n- Receive new content automatically delivered to their inbox via background polling\n\n## Architecture Summary\n- **Data Model**: provider_connections, subscriptions, subscription_items, provider_items_seen tables\n- **OAuth**: PKCE flow with server-side state validation and encrypted token storage\n- **Polling**: Cron-triggered batch processing with distributed locks and adaptive intervals\n- **Ingestion**: Idempotent pipeline with atomic transactions and deduplication\n- **API**: tRPC routers for connections, discovery, and subscription management\n\n## Key Design Decisions\n1. **Millisecond timestamps**: All _at columns use Unix ms (matches JS Date.now())\n2. **Soft delete for subscriptions**: Preserves metadata for re-subscribe scenarios\n3. **Two deduplication tables**: subscription_items (per-subscription tracking) vs provider_items_seen (user-wide idempotency)\n4. **Proactive token refresh**: Refresh 5 min before expiry to avoid mid-operation failures\n5. **Distributed locks via KV**: Prevents cron collisions and token refresh races\n\n## Success Criteria\n- Users can connect/disconnect YouTube and Spotify accounts\n- Users can browse and subscribe to channels/shows\n- New content appears in inbox within 15-60 minutes of publication\n- System handles rate limits gracefully without data loss\n- Tokens remain valid through automatic refresh\n\n## Related Documentation\n- Backend spec: features/subscriptions/backend-spec.md\n- Frontend spec: features/subscriptions/frontend-spec.md\n- Main spec: features/subscriptions/spec.md","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-16T22:07:11.239958-06:00","updated_at":"2025-12-16T22:07:11.239958-06:00"}
{"id":"zine-teq.1","title":"Database Schema: provider_connections table","description":"Create the provider_connections table to store OAuth credentials for connected providers (YouTube, Spotify).\n\n## Table Definition\n```sql\nCREATE TABLE provider_connections (\n  id TEXT PRIMARY KEY,           -- ULID\n  user_id TEXT NOT NULL,         -- FK to users\n  provider TEXT NOT NULL,        -- 'YOUTUBE' | 'SPOTIFY'\n  provider_user_id TEXT,         -- Provider's user ID (for reference)\n  access_token TEXT NOT NULL,    -- AES-256-GCM encrypted\n  refresh_token TEXT NOT NULL,   -- AES-256-GCM encrypted\n  token_expires_at INTEGER NOT NULL, -- Unix timestamp in MILLISECONDS\n  scopes TEXT,                   -- Comma-separated granted scopes\n  connected_at INTEGER NOT NULL DEFAULT (unixepoch() * 1000),\n  last_refreshed_at INTEGER,\n  status TEXT NOT NULL DEFAULT 'ACTIVE', -- ACTIVE | EXPIRED | REVOKED\n  \n  UNIQUE(user_id, provider)\n);\n```\n\n## Implementation Notes\n- **Timestamp convention**: All _at columns store milliseconds (not seconds) to match JS Date.now()\n- **Token encryption**: access_token and refresh_token are stored encrypted; encryption utilities are a separate task\n- **Unique constraint**: One connection per provider per user; reconnecting updates existing row\n- **Status values**: ACTIVE (working), EXPIRED (refresh failed), REVOKED (user revoked on provider side)\n\n## Why This Design\n- Storing provider_user_id allows detecting if a different account is connected on reconnect\n- Scopes field enables checking if we have required permissions without hitting the provider\n- last_refreshed_at helps debug token issues and track refresh patterns\n- Soft status instead of deleting allows preserving connection history\n\n## Files to Modify\n- apps/worker/src/db/schema.ts - Add table definition\n- apps/worker/src/db/migrations/ - New migration file\n\n## Acceptance Criteria\n- [ ] Table created with all columns and constraints\n- [ ] Migration runs successfully\n- [ ] Drizzle schema exports the table for use in queries\n- [ ] Indexes on (user_id, provider) for lookups","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:07:24.884764-06:00","updated_at":"2025-12-16T22:07:24.884764-06:00","dependencies":[{"issue_id":"zine-teq.1","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:07:24.885119-06:00","created_by":"daemon"}]}
{"id":"zine-teq.10","title":"YouTube: SDK integration and client factory","description":"Integrate the googleapis package for YouTube API access and create a client factory.\n\n## Package Installation\n```bash\nnpm install googleapis\n```\n\n## Required OAuth Scope\n`https://www.googleapis.com/auth/youtube.readonly`\n\nThis scope provides read-only access to:\n- User's subscriptions\n- Channel details\n- Video metadata\n- Playlist contents\n\n## Client Factory\n\n### apps/worker/src/providers/youtube.ts\n```typescript\nimport { google, youtube_v3 } from 'googleapis';\n\nexport interface YouTubeClient {\n  api: youtube_v3.Youtube;\n  oauth2Client: OAuth2Client;\n}\n\nexport function createYouTubeClient(\n  accessToken: string,\n  refreshToken: string,\n  env: Env\n): YouTubeClient {\n  const oauth2Client = new google.auth.OAuth2(\n    env.YOUTUBE_CLIENT_ID,\n    env.YOUTUBE_CLIENT_SECRET,\n    env.YOUTUBE_REDIRECT_URI\n  );\n  \n  oauth2Client.setCredentials({\n    access_token: accessToken,\n    refresh_token: refreshToken,\n  });\n  \n  const api = google.youtube({ version: 'v3', auth: oauth2Client });\n  \n  return { api, oauth2Client };\n}\n\n// Convenience wrapper for getting a client from a connection\nexport async function getYouTubeClientForConnection(\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cYouTubeClient\u003e {\n  const accessToken = await getValidAccessToken(connection, env);\n  const refreshToken = await decrypt(connection.refreshToken, env.ENCRYPTION_KEY);\n  \n  return createYouTubeClient(accessToken, refreshToken, env);\n}\n```\n\n## API Quota Costs\n| Operation | Method | Quota Cost | Notes |\n|-----------|--------|------------|-------|\n| List subscriptions | subscriptions.list | 1 | User's YouTube subscriptions |\n| Get channel | channels.list | 1 | Channel details + uploads playlist |\n| List playlist items | playlistItems.list | 1 | Videos in uploads playlist |\n| Search | search.list | **100** | Avoid when possible! |\n\n**Daily quota**: 10,000 units (resets midnight Pacific)\n\n## Key API Methods\n\n### Get User's Subscriptions\n```typescript\nexport async function getUserSubscriptions(client: YouTubeClient): Promise\u003cChannel[]\u003e {\n  const subscriptions = await client.api.subscriptions.list({\n    part: ['snippet'],\n    mine: true,\n    maxResults: 50, // Max per page\n  });\n  \n  // Returns channels the user is subscribed to on YouTube\n  return subscriptions.data.items?.map(sub =\u003e ({\n    id: sub.snippet?.resourceId?.channelId,\n    name: sub.snippet?.title,\n    imageUrl: sub.snippet?.thumbnails?.default?.url,\n  })) || [];\n}\n```\n\n### Get Channel's Uploads Playlist\n```typescript\nexport async function getChannelUploadsPlaylistId(\n  client: YouTubeClient,\n  channelId: string\n): Promise\u003cstring\u003e {\n  const channel = await client.api.channels.list({\n    part: ['contentDetails'],\n    id: [channelId],\n  });\n  \n  const uploads = channel.data.items?.[0]?.contentDetails?.relatedPlaylists?.uploads;\n  if (!uploads) {\n    throw new YouTubeError('NO_UPLOADS_PLAYLIST', 'Channel has no uploads playlist');\n  }\n  \n  return uploads;\n}\n```\n\n### Fetch Recent Videos\n```typescript\nexport async function fetchRecentVideos(\n  client: YouTubeClient,\n  uploadsPlaylistId: string,\n  maxResults = 10\n): Promise\u003cYouTubeVideo[]\u003e {\n  const videos = await client.api.playlistItems.list({\n    part: ['snippet', 'contentDetails'],\n    playlistId: uploadsPlaylistId,\n    maxResults,\n  });\n  \n  return videos.data.items?.map(item =\u003e ({\n    videoId: item.contentDetails?.videoId,\n    title: item.snippet?.title,\n    channelTitle: item.snippet?.channelTitle,\n    publishedAt: item.snippet?.publishedAt,\n    thumbnailUrl: item.snippet?.thumbnails?.high?.url,\n  })) || [];\n}\n```\n\n## Environment Variables\nAdd to wrangler.toml:\n```toml\n[vars]\nYOUTUBE_REDIRECT_URI = \"https://your-domain.com/auth/youtube/callback\"\n\n# Secrets (set via wrangler secret put)\n# YOUTUBE_CLIENT_ID\n# YOUTUBE_CLIENT_SECRET\n```\n\n## Error Handling\n- quotaExceeded → Stop polling, log, notify (graceful degradation)\n- 401/403 → Token invalid, trigger refresh or mark expired\n- 404 → Channel/playlist not found, mark subscription disconnected\n\n## Files to Create\n- apps/worker/src/providers/youtube.ts\n\n## Dependencies\n- zine-teq.9 (token refresh)\n- zine-teq.6 (encryption)\n\n## Acceptance Criteria\n- [ ] googleapis package installed\n- [ ] Client factory creates authenticated YouTube client\n- [ ] getUserSubscriptions returns user's subscribed channels\n- [ ] fetchRecentVideos returns videos from uploads playlist\n- [ ] Error handling for quota, auth, and not-found errors\n- [ ] Unit tests with mocked API responses","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:10:08.511186-06:00","updated_at":"2025-12-16T22:10:08.511186-06:00","dependencies":[{"issue_id":"zine-teq.10","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:10:08.51155-06:00","created_by":"daemon"},{"issue_id":"zine-teq.10","depends_on_id":"zine-teq.9","type":"blocks","created_at":"2025-12-16T22:19:12.320006-06:00","created_by":"daemon"},{"issue_id":"zine-teq.10","depends_on_id":"zine-teq.6","type":"blocks","created_at":"2025-12-16T22:19:12.370706-06:00","created_by":"daemon"}]}
{"id":"zine-teq.11","title":"Spotify: SDK integration and client factory","description":"Integrate the @spotify/web-api-ts-sdk package for Spotify API access and create a client factory.\n\n## Package Installation\n```bash\nnpm install @spotify/web-api-ts-sdk\n```\n\n## Required OAuth Scope\n`user-library-read`\n\nThis scope provides access to:\n- User's saved shows (podcasts)\n- Show details\n- Episode lists\n\n## Critical Note on Client Credentials vs User Tokens\n**The Spotify SDK supports Client Credentials flow, but this ONLY accesses PUBLIC data.**\n\nFor user-specific data (saved shows, etc.), we MUST use the user's stored OAuth tokens from provider_connections. Do NOT use SpotifyApi.withClientCredentials() for polling user subscriptions.\n\n## Client Factory\n\n### apps/worker/src/providers/spotify.ts\n```typescript\nimport { SpotifyApi, AccessToken } from '@spotify/web-api-ts-sdk';\n\nexport function createSpotifyClient(\n  accessToken: string,\n  env: Env\n): SpotifyApi {\n  // Create a minimal AccessToken object\n  // We handle refresh externally via token-refresh.ts\n  const token: AccessToken = {\n    access_token: accessToken,\n    token_type: 'Bearer',\n    expires_in: 3600, // Nominal - we manage expiry externally\n    refresh_token: '', // We don't give SDK our refresh token\n  };\n  \n  return SpotifyApi.withAccessToken(env.SPOTIFY_CLIENT_ID, token);\n}\n\n// Convenience wrapper for getting a client from a connection\nexport async function getSpotifyClientForConnection(\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cSpotifyApi\u003e {\n  const accessToken = await getValidAccessToken(connection, env);\n  return createSpotifyClient(accessToken, env);\n}\n```\n\n## Rate Limits\nSpotify uses rolling 30-second windows with ~100-180 requests depending on endpoint and quota mode. The SDK handles 429 responses with retry-after.\n\n## Key API Methods\n\n### Get User's Saved Shows (Podcasts)\n```typescript\nexport async function getUserSavedShows(client: SpotifyApi): Promise\u003cSpotifyShow[]\u003e {\n  const shows: SpotifyShow[] = [];\n  let offset = 0;\n  const limit = 50; // Max per request\n  \n  while (true) {\n    const response = await client.currentUser.shows.savedShows(limit, offset);\n    shows.push(...response.items.map(item =\u003e ({\n      id: item.show.id,\n      name: item.show.name,\n      description: item.show.description,\n      imageUrl: item.show.images[0]?.url,\n      publisher: item.show.publisher,\n      totalEpisodes: item.show.total_episodes,\n      externalUrl: item.show.external_urls.spotify,\n    })));\n    \n    if (!response.next) break;\n    offset += limit;\n  }\n  \n  return shows;\n}\n```\n\n### Get Show Episodes\n```typescript\nexport async function getShowEpisodes(\n  client: SpotifyApi,\n  showId: string,\n  limit = 10\n): Promise\u003cSpotifyEpisode[]\u003e {\n  const response = await client.shows.episodes(showId, undefined, limit);\n  \n  return response.items.map(episode =\u003e ({\n    id: episode.id,\n    name: episode.name,\n    description: episode.description,\n    releaseDate: episode.release_date,\n    durationMs: episode.duration_ms,\n    externalUrl: episode.external_urls.spotify,\n    imageUrl: episode.images[0]?.url,\n  }));\n}\n```\n\n## Type Definitions\n```typescript\nexport interface SpotifyShow {\n  id: string;\n  name: string;\n  description: string;\n  imageUrl?: string;\n  publisher: string;\n  totalEpisodes: number;\n  externalUrl: string;\n}\n\nexport interface SpotifyEpisode {\n  id: string;\n  name: string;\n  description: string;\n  releaseDate: string; // YYYY-MM-DD or YYYY-MM or YYYY\n  durationMs: number;\n  externalUrl: string;\n  imageUrl?: string;\n}\n```\n\n## Environment Variables\nAdd to wrangler.toml:\n```toml\n[vars]\nSPOTIFY_REDIRECT_URI = \"https://your-domain.com/auth/spotify/callback\"\n\n# Secrets (set via wrangler secret put)\n# SPOTIFY_CLIENT_ID\n# SPOTIFY_CLIENT_SECRET\n```\n\n## Error Handling\n- 429 (rate limit) → SDK handles retry-after automatically\n- 401 → Token invalid, trigger refresh\n- 404 → Show not found, mark subscription disconnected\n\n## Release Date Handling\nSpotify release_date can be:\n- Full date: \"2024-01-15\"\n- Month only: \"2024-01\"\n- Year only: \"2024\"\n\nParse carefully:\n```typescript\nfunction parseSpotifyReleaseDate(dateStr: string): number {\n  // Pad incomplete dates to avoid timezone issues\n  if (dateStr.length === 4) dateStr += '-01-01';\n  else if (dateStr.length === 7) dateStr += '-01';\n  return new Date(dateStr).getTime();\n}\n```\n\n## Files to Create\n- apps/worker/src/providers/spotify.ts\n\n## Dependencies\n- zine-teq.9 (token refresh)\n- zine-teq.6 (encryption)\n\n## Acceptance Criteria\n- [ ] @spotify/web-api-ts-sdk package installed\n- [ ] Client factory creates authenticated Spotify client with user token\n- [ ] getUserSavedShows returns user's saved podcasts with pagination\n- [ ] getShowEpisodes returns episodes for a show\n- [ ] Release date parsing handles all Spotify date formats\n- [ ] Error handling for rate limits, auth, and not-found errors\n- [ ] Unit tests with mocked API responses","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:10:33.598756-06:00","updated_at":"2025-12-16T22:10:33.598756-06:00","dependencies":[{"issue_id":"zine-teq.11","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:10:33.599166-06:00","created_by":"daemon"},{"issue_id":"zine-teq.11","depends_on_id":"zine-teq.9","type":"blocks","created_at":"2025-12-16T22:19:16.119858-06:00","created_by":"daemon"},{"issue_id":"zine-teq.11","depends_on_id":"zine-teq.6","type":"blocks","created_at":"2025-12-16T22:19:16.168973-06:00","created_by":"daemon"}]}
{"id":"zine-teq.12","title":"tRPC: Connections router (list, disconnect)","description":"Implement the connections tRPC router for listing and disconnecting provider connections.\n\n## Router Structure\n```typescript\n// apps/worker/src/trpc/routers/connections.ts\nexport const connectionsRouter = router({\n  // List user's connected providers\n  list: protectedProcedure.query(/* ... */),\n  \n  // Register OAuth state (implemented in zine-teq.7)\n  registerState: protectedProcedure.mutation(/* ... */),\n  \n  // Exchange code for tokens (implemented in zine-teq.8)\n  callback: protectedProcedure.mutation(/* ... */),\n  \n  // Disconnect a provider\n  disconnect: protectedProcedure.mutation(/* ... */),\n});\n```\n\n## List Endpoint\nReturns all connected providers for the authenticated user with status.\n\n```typescript\nlist: protectedProcedure.query(async ({ ctx }) =\u003e {\n  const connections = await ctx.db.query.providerConnections.findMany({\n    where: eq(providerConnections.userId, ctx.userId),\n    columns: {\n      provider: true,\n      status: true,\n      connectedAt: true,\n      lastRefreshedAt: true,\n      // Explicitly exclude tokens!\n    },\n  });\n  \n  // Return a map for easy lookup\n  return {\n    YOUTUBE: connections.find(c =\u003e c.provider === 'YOUTUBE') ?? null,\n    SPOTIFY: connections.find(c =\u003e c.provider === 'SPOTIFY') ?? null,\n  };\n}),\n```\n\n## Disconnect Endpoint\nRevokes access and cleans up related data.\n\n```typescript\ndisconnect: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema,\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    const connection = await ctx.db.query.providerConnections.findFirst({\n      where: and(\n        eq(providerConnections.userId, ctx.userId),\n        eq(providerConnections.provider, input.provider)\n      ),\n    });\n    \n    if (!connection) {\n      throw new TRPCError({ code: 'NOT_FOUND', message: 'Provider not connected' });\n    }\n    \n    // 1. Attempt to revoke tokens with provider (best effort)\n    try {\n      await revokeProviderTokens(connection, ctx.env);\n    } catch (e) {\n      // Log but don't fail - we'll delete our copy anyway\n      console.error('Failed to revoke tokens with provider:', e);\n    }\n    \n    // 2. Update subscriptions to DISCONNECTED\n    await ctx.db.update(subscriptions)\n      .set({ status: 'DISCONNECTED', updatedAt: Date.now() })\n      .where(and(\n        eq(subscriptions.userId, ctx.userId),\n        eq(subscriptions.provider, input.provider)\n      ));\n    \n    // 3. Delete our stored connection\n    await ctx.db.delete(providerConnections)\n      .where(eq(providerConnections.id, connection.id));\n    \n    return { success: true };\n  }),\n```\n\n## Token Revocation\n```typescript\n// apps/worker/src/lib/oauth.ts\nasync function revokeProviderTokens(\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cvoid\u003e {\n  const accessToken = await decrypt(connection.accessToken, env.ENCRYPTION_KEY);\n  \n  if (connection.provider === 'YOUTUBE') {\n    // Google's revoke endpoint\n    await fetch(`https://oauth2.googleapis.com/revoke?token=${accessToken}`, {\n      method: 'POST',\n    });\n  } else if (connection.provider === 'SPOTIFY') {\n    // Spotify doesn't have a revoke endpoint\n    // Users must revoke via Spotify account settings\n  }\n}\n```\n\n## Rate Limiting\n| Endpoint   | Window | Max | Key    |\n|------------|--------|-----|--------|\n| disconnect | 1 min  | 3   | userId |\n\n## Response Types\n```typescript\ninterface ConnectionInfo {\n  provider: 'YOUTUBE' | 'SPOTIFY';\n  status: 'ACTIVE' | 'EXPIRED' | 'REVOKED';\n  connectedAt: number;\n  lastRefreshedAt: number | null;\n}\n\ninterface ListConnectionsResponse {\n  YOUTUBE: ConnectionInfo | null;\n  SPOTIFY: ConnectionInfo | null;\n}\n```\n\n## Files to Create/Modify\n- apps/worker/src/trpc/routers/connections.ts - Main router file\n- apps/worker/src/trpc/router.ts - Register connectionsRouter\n- apps/worker/src/lib/oauth.ts - Add revokeProviderTokens\n\n## Dependencies\n- zine-teq.1 (provider_connections table)\n- zine-teq.7 (registerState - same file)\n- zine-teq.8 (callback - same file)\n\n## Acceptance Criteria\n- [ ] list returns connected providers without exposing tokens\n- [ ] disconnect revokes with provider and deletes connection\n- [ ] disconnect marks related subscriptions as DISCONNECTED\n- [ ] Rate limiting prevents disconnect abuse\n- [ ] Integration tests cover happy path and error cases","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:10:54.217868-06:00","updated_at":"2025-12-16T22:10:54.217868-06:00","dependencies":[{"issue_id":"zine-teq.12","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:10:54.218258-06:00","created_by":"daemon"},{"issue_id":"zine-teq.12","depends_on_id":"zine-teq.1","type":"blocks","created_at":"2025-12-16T22:19:19.888624-06:00","created_by":"daemon"},{"issue_id":"zine-teq.12","depends_on_id":"zine-teq.7","type":"blocks","created_at":"2025-12-16T22:19:19.936998-06:00","created_by":"daemon"},{"issue_id":"zine-teq.12","depends_on_id":"zine-teq.8","type":"blocks","created_at":"2025-12-16T22:19:19.982516-06:00","created_by":"daemon"}]}
{"id":"zine-teq.13","title":"tRPC: Subscriptions router (add, remove, list)","description":"Implement the core subscriptions tRPC router for subscription management.\n\n## Router Structure\n```typescript\n// apps/worker/src/trpc/routers/subscriptions.ts\nexport const subscriptionsRouter = router({\n  // List user's subscriptions\n  list: protectedProcedure.query(/* paginated list */),\n  \n  // Add a subscription\n  add: protectedProcedure.mutation(/* subscribe to channel/show */),\n  \n  // Remove a subscription\n  remove: protectedProcedure.mutation(/* unsubscribe */),\n  \n  // Pause/resume (separate task)\n  // Sync now (separate task)\n  // Discovery (separate task)\n});\n```\n\n## List Endpoint (Paginated)\n```typescript\nlist: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema.optional(),\n    status: SubscriptionStatusSchema.optional(),\n    limit: z.number().min(1).max(100).default(50),\n    cursor: z.string().optional(), // ULID for cursor-based pagination\n  }))\n  .query(async ({ ctx, input }) =\u003e {\n    const conditions = [eq(subscriptions.userId, ctx.userId)];\n    \n    if (input.provider) {\n      conditions.push(eq(subscriptions.provider, input.provider));\n    }\n    if (input.status) {\n      conditions.push(eq(subscriptions.status, input.status));\n    }\n    if (input.cursor) {\n      conditions.push(gt(subscriptions.id, input.cursor));\n    }\n    \n    const results = await ctx.db.query.subscriptions.findMany({\n      where: and(...conditions),\n      orderBy: [asc(subscriptions.id)],\n      limit: input.limit + 1,\n    });\n    \n    const hasMore = results.length \u003e input.limit;\n    const items = hasMore ? results.slice(0, -1) : results;\n    \n    return {\n      items,\n      nextCursor: hasMore ? items[items.length - 1].id : null,\n      hasMore,\n    };\n  }),\n```\n\n## Add Endpoint (Subscribe)\n```typescript\nadd: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema,\n    providerChannelId: z.string(), // Validated by provider-specific schema\n    name: z.string().optional(),\n    imageUrl: z.string().url().optional(),\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    // 1. Validate provider channel ID format\n    if (input.provider === 'YOUTUBE') {\n      YouTubeChannelIdSchema.parse(input.providerChannelId);\n    } else {\n      SpotifyShowIdSchema.parse(input.providerChannelId);\n    }\n    \n    // 2. Check provider connection exists and is active\n    const connection = await ctx.db.query.providerConnections.findFirst({\n      where: and(\n        eq(providerConnections.userId, ctx.userId),\n        eq(providerConnections.provider, input.provider),\n        eq(providerConnections.status, 'ACTIVE')\n      ),\n    });\n    \n    if (!connection) {\n      throw new TRPCError({\n        code: 'PRECONDITION_FAILED',\n        message: `${input.provider} account not connected`,\n      });\n    }\n    \n    // 3. Fetch channel/show details if not provided\n    let name = input.name;\n    let imageUrl = input.imageUrl;\n    let description: string | undefined;\n    let externalUrl: string | undefined;\n    \n    if (!name || !imageUrl) {\n      const details = await fetchChannelDetails(connection, input.providerChannelId, ctx.env);\n      name = name || details.name;\n      imageUrl = imageUrl || details.imageUrl;\n      description = details.description;\n      externalUrl = details.externalUrl;\n    }\n    \n    // 4. Create subscription (upsert for re-subscribe)\n    const subscriptionId = ulid();\n    await ctx.db.insert(subscriptions).values({\n      id: subscriptionId,\n      userId: ctx.userId,\n      provider: input.provider,\n      providerChannelId: input.providerChannelId,\n      name,\n      description,\n      imageUrl,\n      externalUrl,\n      status: 'ACTIVE',\n      pollIntervalSeconds: 3600, // Default 1 hour\n      createdAt: Date.now(),\n      updatedAt: Date.now(),\n    }).onConflictDoUpdate({\n      target: [subscriptions.userId, subscriptions.provider, subscriptions.providerChannelId],\n      set: {\n        status: 'ACTIVE',\n        name,\n        imageUrl,\n        description,\n        externalUrl,\n        updatedAt: Date.now(),\n      },\n    });\n    \n    // 5. Trigger initial fetch (fetch latest item only)\n    await triggerInitialFetch(ctx.userId, subscriptionId, connection, input.provider, input.providerChannelId, ctx.env);\n    \n    return { subscriptionId, name, imageUrl };\n  }),\n```\n\n## Remove Endpoint (Unsubscribe)\n```typescript\nremove: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    const subscription = await ctx.db.query.subscriptions.findFirst({\n      where: and(\n        eq(subscriptions.id, input.subscriptionId),\n        eq(subscriptions.userId, ctx.userId)\n      ),\n    });\n    \n    if (!subscription) {\n      throw new TRPCError({ code: 'NOT_FOUND' });\n    }\n    \n    await ctx.db.transaction(async (tx) =\u003e {\n      // 1. Soft delete subscription (preserves metadata for re-subscribe)\n      await tx.update(subscriptions)\n        .set({ status: 'UNSUBSCRIBED', updatedAt: Date.now() })\n        .where(eq(subscriptions.id, input.subscriptionId));\n      \n      // 2. Hard delete subscription_items (tracking records)\n      await tx.delete(subscriptionItems)\n        .where(eq(subscriptionItems.subscriptionId, input.subscriptionId));\n      \n      // 3. Delete INBOX user_items from this subscription\n      // Note: Keeps SAVED, ARCHIVED items (user committed to those)\n      const itemIds = await tx.query.subscriptionItems.findMany({\n        where: eq(subscriptionItems.subscriptionId, input.subscriptionId),\n        columns: { itemId: true },\n      });\n      \n      if (itemIds.length \u003e 0) {\n        await tx.delete(userItems)\n          .where(and(\n            eq(userItems.userId, ctx.userId),\n            eq(userItems.state, 'INBOX'),\n            inArray(userItems.itemId, itemIds.map(i =\u003e i.itemId))\n          ));\n      }\n      \n      // 4. DO NOT delete provider_items_seen (prevents duplicates on re-subscribe)\n    });\n    \n    return { success: true };\n  }),\n```\n\n## Unsubscribe Behavior Summary\n| Table | Action | Rationale |\n|-------|--------|-----------|\n| subscriptions | Soft delete (UNSUBSCRIBED) | Preserves metadata for re-subscribe |\n| subscription_items | Hard delete | Tracking records have no value |\n| user_items (INBOX) | Hard delete | User hasn't committed to these |\n| user_items (SAVED/ARCHIVED) | Preserved | User's intentional saves |\n| provider_items_seen | Preserved | Prevents duplicates on re-subscribe |\n\n## Files to Create/Modify\n- apps/worker/src/trpc/routers/subscriptions.ts - Main router\n- apps/worker/src/trpc/router.ts - Register subscriptionsRouter\n\n## Dependencies\n- zine-teq.2 (subscriptions table)\n- zine-teq.3 (subscription_items table)\n- zine-teq.5 (validation schemas)\n- zine-teq.10 (YouTube SDK for details fetch)\n- zine-teq.11 (Spotify SDK for details fetch)\n\n## Acceptance Criteria\n- [ ] list returns paginated subscriptions with cursor\n- [ ] add validates provider channel ID format\n- [ ] add requires active provider connection\n- [ ] add fetches channel details if not provided\n- [ ] add handles re-subscription (upsert to ACTIVE)\n- [ ] remove soft-deletes subscription\n- [ ] remove hard-deletes subscription_items and INBOX user_items\n- [ ] remove preserves SAVED/ARCHIVED items and provider_items_seen\n- [ ] Integration tests cover subscription lifecycle","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:11:22.563292-06:00","updated_at":"2025-12-16T22:11:22.563292-06:00","dependencies":[{"issue_id":"zine-teq.13","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:11:22.563689-06:00","created_by":"daemon"},{"issue_id":"zine-teq.13","depends_on_id":"zine-teq.2","type":"blocks","created_at":"2025-12-16T22:19:23.823902-06:00","created_by":"daemon"},{"issue_id":"zine-teq.13","depends_on_id":"zine-teq.3","type":"blocks","created_at":"2025-12-16T22:19:23.873062-06:00","created_by":"daemon"},{"issue_id":"zine-teq.13","depends_on_id":"zine-teq.5","type":"blocks","created_at":"2025-12-16T22:19:23.91813-06:00","created_by":"daemon"},{"issue_id":"zine-teq.13","depends_on_id":"zine-teq.10","type":"blocks","created_at":"2025-12-16T22:19:23.964909-06:00","created_by":"daemon"},{"issue_id":"zine-teq.13","depends_on_id":"zine-teq.11","type":"blocks","created_at":"2025-12-16T22:19:24.00941-06:00","created_by":"daemon"}]}
{"id":"zine-teq.14","title":"tRPC: Subscriptions discovery endpoints","description":"Implement discovery endpoints for browsing available channels/shows to subscribe to.\n\n## Discovery Use Cases\n1. **Available**: Show channels/podcasts the user follows on YouTube/Spotify but hasn't subscribed to in Zine\n2. **Search**: Search for channels/podcasts by name (for subscribing to things not in their provider library)\n\n## Router Additions\n```typescript\n// apps/worker/src/trpc/routers/subscriptions.ts (add to existing)\n\ndiscover: router({\n  // Get user's provider subscriptions not yet in Zine\n  available: protectedProcedure\n    .input(z.object({\n      provider: ProviderSchema,\n    }))\n    .query(/* ... */),\n  \n  // Search for channels/shows on provider\n  search: protectedProcedure\n    .input(z.object({\n      provider: ProviderSchema,\n      query: z.string().min(2).max(100),\n      limit: z.number().min(1).max(20).default(10),\n    }))\n    .query(/* ... */),\n}),\n```\n\n## Available Endpoint\nReturns channels/shows the user follows on the provider but hasn't subscribed to in Zine.\n\n```typescript\navailable: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema,\n  }))\n  .query(async ({ ctx, input }) =\u003e {\n    // 1. Get active provider connection\n    const connection = await getActiveConnection(ctx.userId, input.provider, ctx);\n    if (!connection) {\n      return { items: [], connectionRequired: true };\n    }\n    \n    // 2. Fetch user's subscriptions from provider\n    let providerSubs: ProviderChannel[];\n    if (input.provider === 'YOUTUBE') {\n      const client = await getYouTubeClientForConnection(connection, ctx.env);\n      providerSubs = await getUserSubscriptions(client);\n    } else {\n      const client = await getSpotifyClientForConnection(connection, ctx.env);\n      providerSubs = await getUserSavedShows(client);\n    }\n    \n    // 3. Get existing Zine subscriptions for this provider\n    const existingIds = await ctx.db.query.subscriptions.findMany({\n      where: and(\n        eq(subscriptions.userId, ctx.userId),\n        eq(subscriptions.provider, input.provider),\n        ne(subscriptions.status, 'UNSUBSCRIBED')\n      ),\n      columns: { providerChannelId: true },\n    }).then(rows =\u003e new Set(rows.map(r =\u003e r.providerChannelId)));\n    \n    // 4. Filter to only show not-yet-subscribed\n    const available = providerSubs.filter(sub =\u003e !existingIds.has(sub.id));\n    \n    return {\n      items: available,\n      connectionRequired: false,\n    };\n  }),\n```\n\n## Search Endpoint\n**Note**: YouTube search costs 100 quota units per call. Use sparingly and consider caching.\n\n```typescript\nsearch: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema,\n    query: z.string().min(2).max(100),\n    limit: z.number().min(1).max(20).default(10),\n  }))\n  .query(async ({ ctx, input }) =\u003e {\n    // 1. Rate limit search (expensive, especially YouTube)\n    await rateLimitSearch(ctx.userId, input.provider, ctx.env);\n    \n    // 2. Get active provider connection\n    const connection = await getActiveConnection(ctx.userId, input.provider, ctx);\n    if (!connection) {\n      throw new TRPCError({\n        code: 'PRECONDITION_FAILED',\n        message: `${input.provider} account not connected`,\n      });\n    }\n    \n    // 3. Search provider\n    let results: ProviderChannel[];\n    if (input.provider === 'YOUTUBE') {\n      const client = await getYouTubeClientForConnection(connection, ctx.env);\n      results = await searchYouTubeChannels(client, input.query, input.limit);\n    } else {\n      const client = await getSpotifyClientForConnection(connection, ctx.env);\n      results = await searchSpotifyShows(client, input.query, input.limit);\n    }\n    \n    return { items: results };\n  }),\n```\n\n## Provider Search Implementations\n\n### YouTube Search (100 quota units!)\n```typescript\n// apps/worker/src/providers/youtube.ts\nexport async function searchYouTubeChannels(\n  client: YouTubeClient,\n  query: string,\n  limit: number\n): Promise\u003cProviderChannel[]\u003e {\n  const response = await client.api.search.list({\n    part: ['snippet'],\n    q: query,\n    type: ['channel'],\n    maxResults: limit,\n  });\n  \n  return response.data.items?.map(item =\u003e ({\n    id: item.id?.channelId,\n    name: item.snippet?.title,\n    description: item.snippet?.description,\n    imageUrl: item.snippet?.thumbnails?.default?.url,\n  })) || [];\n}\n```\n\n### Spotify Search\n```typescript\n// apps/worker/src/providers/spotify.ts\nexport async function searchSpotifyShows(\n  client: SpotifyApi,\n  query: string,\n  limit: number\n): Promise\u003cProviderChannel[]\u003e {\n  const response = await client.search(query, ['show'], undefined, limit);\n  \n  return response.shows.items.map(show =\u003e ({\n    id: show.id,\n    name: show.name,\n    description: show.description,\n    imageUrl: show.images[0]?.url,\n    publisher: show.publisher,\n  }));\n}\n```\n\n## Rate Limiting for Search\n| Provider | Window | Max Requests | Reason |\n|----------|--------|--------------|--------|\n| YouTube | 1 min | 3 | 100 quota units per search |\n| Spotify | 1 min | 10 | Moderate rate limits |\n\n```typescript\nasync function rateLimitSearch(userId: string, provider: Provider, env: Env) {\n  const key = `search:rate:${userId}:${provider}`;\n  const limit = provider === 'YOUTUBE' ? 3 : 10;\n  \n  const current = parseInt(await env.KV.get(key) || '0', 10);\n  if (current \u003e= limit) {\n    throw new TRPCError({ code: 'TOO_MANY_REQUESTS', message: 'Search rate limit exceeded' });\n  }\n  \n  await env.KV.put(key, String(current + 1), { expirationTtl: 60 });\n}\n```\n\n## Response Type\n```typescript\ninterface ProviderChannel {\n  id: string;\n  name: string;\n  description?: string;\n  imageUrl?: string;\n  publisher?: string; // Spotify shows only\n}\n```\n\n## Files to Modify\n- apps/worker/src/trpc/routers/subscriptions.ts - Add discover sub-router\n- apps/worker/src/providers/youtube.ts - Add searchYouTubeChannels\n- apps/worker/src/providers/spotify.ts - Add searchSpotifyShows\n\n## Dependencies\n- zine-teq.10 (YouTube SDK)\n- zine-teq.11 (Spotify SDK)\n- zine-teq.13 (subscriptions router structure)\n\n## Acceptance Criteria\n- [ ] available returns provider subscriptions not in Zine\n- [ ] available handles disconnected providers gracefully\n- [ ] search finds channels/shows by name\n- [ ] search is rate limited (especially YouTube)\n- [ ] Both endpoints require active provider connection\n- [ ] Integration tests cover discovery flow","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:11:49.573004-06:00","updated_at":"2025-12-16T22:11:49.573004-06:00","dependencies":[{"issue_id":"zine-teq.14","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:11:49.573414-06:00","created_by":"daemon"},{"issue_id":"zine-teq.14","depends_on_id":"zine-teq.10","type":"blocks","created_at":"2025-12-16T22:19:27.619549-06:00","created_by":"daemon"},{"issue_id":"zine-teq.14","depends_on_id":"zine-teq.11","type":"blocks","created_at":"2025-12-16T22:19:27.668676-06:00","created_by":"daemon"},{"issue_id":"zine-teq.14","depends_on_id":"zine-teq.13","type":"blocks","created_at":"2025-12-16T22:19:27.714839-06:00","created_by":"daemon"}]}
{"id":"zine-teq.15","title":"tRPC: Subscriptions pause/resume and syncNow","description":"Implement pause, resume, and manual sync (syncNow) endpoints for subscription management.\n\n## Use Cases\n- **Pause**: User wants to temporarily stop receiving content from a subscription without unsubscribing\n- **Resume**: User wants to restart content delivery after pausing\n- **Sync Now**: User wants to immediately check for new content instead of waiting for next poll\n\n## Router Additions\n```typescript\n// apps/worker/src/trpc/routers/subscriptions.ts (add to existing)\n\n// Pause a subscription (stops polling)\npause: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(/* ... */),\n\n// Resume a paused subscription\nresume: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(/* ... */),\n\n// Manually trigger a sync (rate limited)\nsyncNow: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(/* ... */),\n```\n\n## Pause Endpoint\n```typescript\npause: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    const result = await ctx.db.update(subscriptions)\n      .set({ \n        status: 'PAUSED', \n        updatedAt: Date.now() \n      })\n      .where(and(\n        eq(subscriptions.id, input.subscriptionId),\n        eq(subscriptions.userId, ctx.userId),\n        eq(subscriptions.status, 'ACTIVE') // Can only pause active subscriptions\n      ))\n      .returning({ id: subscriptions.id });\n    \n    if (result.length === 0) {\n      throw new TRPCError({\n        code: 'NOT_FOUND',\n        message: 'Subscription not found or not active',\n      });\n    }\n    \n    return { success: true };\n  }),\n```\n\n## Resume Endpoint\n```typescript\nresume: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    // 1. Check subscription exists and is paused\n    const subscription = await ctx.db.query.subscriptions.findFirst({\n      where: and(\n        eq(subscriptions.id, input.subscriptionId),\n        eq(subscriptions.userId, ctx.userId),\n        eq(subscriptions.status, 'PAUSED')\n      ),\n    });\n    \n    if (!subscription) {\n      throw new TRPCError({\n        code: 'NOT_FOUND',\n        message: 'Subscription not found or not paused',\n      });\n    }\n    \n    // 2. Verify provider connection is still active\n    const connection = await ctx.db.query.providerConnections.findFirst({\n      where: and(\n        eq(providerConnections.userId, ctx.userId),\n        eq(providerConnections.provider, subscription.provider),\n        eq(providerConnections.status, 'ACTIVE')\n      ),\n    });\n    \n    if (!connection) {\n      throw new TRPCError({\n        code: 'PRECONDITION_FAILED',\n        message: 'Provider connection expired. Please reconnect.',\n      });\n    }\n    \n    // 3. Resume subscription\n    await ctx.db.update(subscriptions)\n      .set({ \n        status: 'ACTIVE',\n        updatedAt: Date.now(),\n        // Clear lastPolledAt to prioritize in next cron\n        lastPolledAt: null,\n      })\n      .where(eq(subscriptions.id, input.subscriptionId));\n    \n    return { success: true };\n  }),\n```\n\n## Sync Now Endpoint (Manual Poll)\n```typescript\nsyncNow: protectedProcedure\n  .input(z.object({\n    subscriptionId: z.string(),\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    // 1. Rate limit: 1 per 5 minutes per subscription\n    const rateLimitKey = `manual-sync:${input.subscriptionId}`;\n    const lastSync = await ctx.env.KV.get(rateLimitKey);\n    \n    if (lastSync) {\n      const elapsed = Date.now() - parseInt(lastSync, 10);\n      const cooldown = 5 * 60 * 1000; // 5 minutes\n      \n      if (elapsed \u003c cooldown) {\n        const remainingSeconds = Math.ceil((cooldown - elapsed) / 1000);\n        throw new TRPCError({\n          code: 'TOO_MANY_REQUESTS',\n          message: `Please wait ${remainingSeconds} seconds before syncing again`,\n        });\n      }\n    }\n    \n    // 2. Get subscription and verify ownership\n    const subscription = await ctx.db.query.subscriptions.findFirst({\n      where: and(\n        eq(subscriptions.id, input.subscriptionId),\n        eq(subscriptions.userId, ctx.userId),\n        eq(subscriptions.status, 'ACTIVE')\n      ),\n    });\n    \n    if (!subscription) {\n      throw new TRPCError({\n        code: 'NOT_FOUND',\n        message: 'Subscription not found or not active',\n      });\n    }\n    \n    // 3. Get provider connection\n    const connection = await ctx.db.query.providerConnections.findFirst({\n      where: and(\n        eq(providerConnections.userId, ctx.userId),\n        eq(providerConnections.provider, subscription.provider),\n        eq(providerConnections.status, 'ACTIVE')\n      ),\n    });\n    \n    if (!connection) {\n      throw new TRPCError({\n        code: 'PRECONDITION_FAILED',\n        message: 'Provider connection expired',\n      });\n    }\n    \n    // 4. Perform sync\n    const result = await pollSingleSubscription(subscription, connection, ctx.env);\n    \n    // 5. Set rate limit\n    await ctx.env.KV.put(rateLimitKey, Date.now().toString(), { expirationTtl: 300 });\n    \n    return {\n      success: result.success,\n      itemsFound: result.itemsFound,\n      newItems: result.newItems,\n      error: result.error,\n    };\n  }),\n```\n\n## Response Type for syncNow\n```typescript\ninterface SyncResult {\n  success: boolean;\n  itemsFound: number;    // Total items checked\n  newItems: number;      // Items added to inbox\n  error?: string;        // Error message if failed\n}\n```\n\n## Status Transitions\n```\nACTIVE ──pause──→ PAUSED\nPAUSED ──resume──→ ACTIVE\nACTIVE ──disconnect──→ DISCONNECTED\nDISCONNECTED ──reconnect──→ ACTIVE (handled by resume after reconnect)\n```\n\n## Rate Limiting Summary\n| Action | Limit | Window | Key |\n|--------|-------|--------|-----|\n| syncNow | 1 | 5 min | subscriptionId |\n\n## Files to Modify\n- apps/worker/src/trpc/routers/subscriptions.ts - Add pause, resume, syncNow\n\n## Dependencies\n- zine-teq.13 (subscriptions router structure)\n- zine-teq.17 (polling logic for syncNow - can stub initially)\n\n## Acceptance Criteria\n- [ ] pause changes status from ACTIVE to PAUSED\n- [ ] pause rejects if not ACTIVE\n- [ ] resume changes status from PAUSED to ACTIVE\n- [ ] resume verifies provider connection is active\n- [ ] syncNow triggers immediate poll\n- [ ] syncNow is rate limited to 1 per 5 minutes\n- [ ] syncNow returns item counts\n- [ ] Integration tests cover state transitions","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:12:13.848217-06:00","updated_at":"2025-12-16T22:12:13.848217-06:00","dependencies":[{"issue_id":"zine-teq.15","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:12:13.848597-06:00","created_by":"daemon"},{"issue_id":"zine-teq.15","depends_on_id":"zine-teq.13","type":"blocks","created_at":"2025-12-16T22:19:31.677667-06:00","created_by":"daemon"}]}
{"id":"zine-teq.16","title":"Item Transformation: YouTube video and Spotify episode mappers","description":"Implement transformation functions to convert provider-specific content into canonical Zine items.\n\n## Purpose\nWhen we fetch videos/episodes from providers, we need to transform them into our unified 'items' table format. These mappers handle:\n- Field mapping (provider fields → our schema)\n- Type conversion (especially timestamps)\n- Default values for optional fields\n\n## YouTube Video Transformer\n\n```typescript\n// apps/worker/src/ingestion/transformers.ts\n\nimport { ContentType, Provider } from '@zine/shared';\nimport { ulid } from 'ulid';\n\ninterface YouTubePlaylistItem {\n  contentDetails?: {\n    videoId?: string;\n  };\n  snippet?: {\n    title?: string;\n    description?: string;\n    channelTitle?: string;\n    channelId?: string;\n    publishedAt?: string;\n    thumbnails?: {\n      high?: { url?: string };\n      default?: { url?: string };\n    };\n  };\n}\n\nexport interface NewItem {\n  id: string;\n  contentType: ContentType;\n  provider: Provider;\n  providerId: string;\n  canonicalUrl: string;\n  title: string;\n  description?: string;\n  creator: string;\n  creatorId?: string;\n  imageUrl?: string;\n  durationSeconds?: number;\n  publishedAt: number; // Unix ms\n  createdAt: number;\n}\n\nexport function transformYouTubeVideo(playlistItem: YouTubePlaylistItem): NewItem {\n  const videoId = playlistItem.contentDetails?.videoId;\n  if (!videoId) {\n    throw new TransformError('YouTube video missing videoId');\n  }\n  \n  const snippet = playlistItem.snippet || {};\n  \n  return {\n    id: ulid(),\n    contentType: 'VIDEO',\n    provider: 'YOUTUBE',\n    providerId: videoId,\n    canonicalUrl: `https://www.youtube.com/watch?v=${videoId}`,\n    title: snippet.title || 'Untitled',\n    description: snippet.description,\n    creator: snippet.channelTitle || 'Unknown',\n    creatorId: snippet.channelId,\n    imageUrl: snippet.thumbnails?.high?.url || snippet.thumbnails?.default?.url,\n    // Duration not available from playlistItems.list - would need videos.list (extra quota)\n    durationSeconds: undefined,\n    publishedAt: snippet.publishedAt \n      ? new Date(snippet.publishedAt).getTime() \n      : Date.now(),\n    createdAt: Date.now(),\n  };\n}\n```\n\n## Spotify Episode Transformer\n\n```typescript\ninterface SpotifyEpisode {\n  id: string;\n  name: string;\n  description?: string;\n  release_date: string; // YYYY-MM-DD, YYYY-MM, or YYYY\n  duration_ms: number;\n  external_urls: {\n    spotify: string;\n  };\n  images?: Array\u003c{ url: string }\u003e;\n}\n\nexport function transformSpotifyEpisode(\n  episode: SpotifyEpisode,\n  showName: string\n): NewItem {\n  return {\n    id: ulid(),\n    contentType: 'PODCAST',\n    provider: 'SPOTIFY',\n    providerId: episode.id,\n    canonicalUrl: episode.external_urls.spotify,\n    title: episode.name,\n    description: episode.description,\n    creator: showName,\n    // Spotify doesn't provide show ID in episode response, handled separately\n    creatorId: undefined,\n    imageUrl: episode.images?.[0]?.url,\n    durationSeconds: Math.floor(episode.duration_ms / 1000),\n    publishedAt: parseSpotifyReleaseDate(episode.release_date),\n    createdAt: Date.now(),\n  };\n}\n\n/**\n * Parse Spotify's variable-precision release dates\n * - \"2024-01-15\" → full date\n * - \"2024-01\" → first of month\n * - \"2024\" → first of year\n */\nfunction parseSpotifyReleaseDate(dateStr: string): number {\n  // Pad incomplete dates to avoid timezone issues\n  let normalized = dateStr;\n  if (dateStr.length === 4) {\n    normalized = `${dateStr}-01-01`;\n  } else if (dateStr.length === 7) {\n    normalized = `${dateStr}-01`;\n  }\n  \n  // Parse as UTC to avoid timezone shifting\n  const parsed = new Date(`${normalized}T00:00:00Z`);\n  \n  if (isNaN(parsed.getTime())) {\n    console.warn(`Invalid Spotify release date: ${dateStr}, using now`);\n    return Date.now();\n  }\n  \n  return parsed.getTime();\n}\n```\n\n## Error Handling\n```typescript\nexport class TransformError extends Error {\n  constructor(message: string, public readonly context?: unknown) {\n    super(message);\n    this.name = 'TransformError';\n  }\n}\n```\n\n## Batch Transformation\n```typescript\nexport function transformYouTubeVideos(\n  items: YouTubePlaylistItem[]\n): { items: NewItem[]; errors: TransformError[] } {\n  const results: NewItem[] = [];\n  const errors: TransformError[] = [];\n  \n  for (const item of items) {\n    try {\n      results.push(transformYouTubeVideo(item));\n    } catch (e) {\n      errors.push(e instanceof TransformError ? e : new TransformError('Unknown error', e));\n    }\n  }\n  \n  return { items: results, errors };\n}\n\nexport function transformSpotifyEpisodes(\n  episodes: SpotifyEpisode[],\n  showName: string\n): { items: NewItem[]; errors: TransformError[] } {\n  const results: NewItem[] = [];\n  const errors: TransformError[] = [];\n  \n  for (const episode of episodes) {\n    try {\n      results.push(transformSpotifyEpisode(episode, showName));\n    } catch (e) {\n      errors.push(e instanceof TransformError ? e : new TransformError('Unknown error', e));\n    }\n  }\n  \n  return { items: results, errors };\n}\n```\n\n## Files to Create\n- apps/worker/src/ingestion/transformers.ts\n\n## Dependencies\n- zine-teq.5 (shared types for ContentType, Provider)\n\n## Acceptance Criteria\n- [ ] transformYouTubeVideo maps all fields correctly\n- [ ] transformSpotifyEpisode maps all fields correctly\n- [ ] Spotify release date parsing handles all formats\n- [ ] Missing required fields throw TransformError\n- [ ] Batch functions collect errors without stopping\n- [ ] Unit tests cover valid and invalid inputs\n- [ ] Timestamps are in milliseconds","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:12:38.384045-06:00","updated_at":"2025-12-16T22:12:38.384045-06:00","dependencies":[{"issue_id":"zine-teq.16","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:12:38.38444-06:00","created_by":"daemon"},{"issue_id":"zine-teq.16","depends_on_id":"zine-teq.5","type":"blocks","created_at":"2025-12-16T22:19:35.01398-06:00","created_by":"daemon"}]}
{"id":"zine-teq.17","title":"Ingestion Pipeline: Idempotent item processing with transactions","description":"Implement the idempotent ingestion pipeline with atomic transactions and deduplication.\n\n## Timestamp Format Bridge\n\n**CRITICAL**: This pipeline bridges two timestamp formats:\n- **Subscription system** (new tables): Unix milliseconds (INTEGER)\n- **Existing items/user_items tables**: ISO8601 strings (TEXT)\n\nThe ingestion pipeline MUST convert timestamps when writing to existing tables.\n\n```typescript\nfunction toISO8601(timestamp: number | string): string {\n  if (typeof timestamp === 'string') return timestamp;\n  return new Date(timestamp).toISOString();\n}\n```\n\n## Flow Diagram\n```\nProvider Data → Transform → Idempotency Check → Atomic Write\n                   │               │                  │\n                   │               │                  ├─ Find/create canonical item (items table)\n                   │               │                  ├─ Create user_item (INBOX state)\n                   │               │                  ├─ Create subscription_item (tracking)\n                   │               │                  └─ Create provider_items_seen (idempotency)\n                   │               │\n                   │               └─ Check (user_id, provider, provider_item_id)\n                   │\n                   └─ YouTube/Spotify transformer\n```\n\n## Main Ingestion Function\n\n```typescript\n// apps/worker/src/ingestion/processor.ts\n\nexport interface IngestResult {\n  created: boolean;\n  itemId?: string;\n  userItemId?: string;\n  skipped?: 'already_seen';\n}\n\nexport async function ingestItem\u003cT\u003e(\n  userId: string,\n  subscriptionId: string,\n  rawItem: T,\n  provider: Provider,\n  db: DrizzleDB,\n  transformFn: (raw: T) =\u003e NewItem\n): Promise\u003cIngestResult\u003e {\n  // 1. Transform raw provider data to our item format\n  const transformedItem = transformFn(rawItem);\n  \n  // 2. Check idempotency (has this user already seen this item?)\n  const seen = await db.query.providerItemsSeen.findFirst({\n    where: and(\n      eq(providerItemsSeen.userId, userId),\n      eq(providerItemsSeen.provider, provider),\n      eq(providerItemsSeen.providerItemId, transformedItem.providerId)\n    ),\n  });\n  \n  if (seen) {\n    return { created: false, skipped: 'already_seen' };\n  }\n  \n  // 3. Atomic transaction for all writes\n  return await db.transaction(async (tx) =\u003e {\n    // 3a. Find or create canonical item\n    const item = await findOrCreateCanonicalItem(\n      transformedItem,\n      provider,\n      tx\n    );\n    \n    // 3b. Create user_item in INBOX state\n    // Note: Convert timestamps to ISO8601 for existing table format\n    const userItemId = ulid();\n    const now = new Date().toISOString();\n    \n    await tx.insert(userItems).values({\n      id: userItemId,\n      userId,\n      itemId: item.id,\n      state: 'INBOX',\n      ingestedAt: now,\n      createdAt: now,\n      updatedAt: now,\n    });\n    \n    // 3c. Create subscription_item for tracking\n    await tx.insert(subscriptionItems).values({\n      id: ulid(),\n      subscriptionId,\n      itemId: item.id,\n      providerItemId: transformedItem.providerId,\n      publishedAt: transformedItem.publishedAt, // Unix ms\n      fetchedAt: Date.now(),\n    });\n    \n    // 3d. Mark as seen for idempotency\n    await tx.insert(providerItemsSeen).values({\n      id: ulid(),\n      userId,\n      provider,\n      providerItemId: transformedItem.providerId,\n      sourceId: subscriptionId, // Links to subscription\n      firstSeenAt: now, // ISO8601 for existing table\n    });\n    \n    return {\n      created: true,\n      itemId: item.id,\n      userItemId,\n    };\n  });\n}\n```\n\n## Find or Create Canonical Item\n\n```typescript\nasync function findOrCreateCanonicalItem(\n  newItem: NewItem,\n  provider: Provider,\n  tx: Transaction\n): Promise\u003cItem\u003e {\n  // Check if item already exists (shared across users)\n  const existing = await tx.query.items.findFirst({\n    where: and(\n      eq(items.provider, provider),\n      eq(items.providerId, newItem.providerId)\n    ),\n  });\n  \n  if (existing) {\n    return existing;\n  }\n  \n  // Create new canonical item\n  // Convert timestamps to ISO8601 for existing items table\n  const now = new Date().toISOString();\n  const publishedAtISO = newItem.publishedAt \n    ? new Date(newItem.publishedAt).toISOString() \n    : null;\n  \n  const itemId = ulid();\n  await tx.insert(items).values({\n    id: itemId,\n    contentType: newItem.contentType,\n    provider,\n    providerId: newItem.providerId,\n    canonicalUrl: newItem.canonicalUrl,\n    title: newItem.title,\n    creator: newItem.creator,\n    thumbnailUrl: newItem.thumbnailUrl,\n    duration: newItem.durationSeconds,\n    publishedAt: publishedAtISO,\n    createdAt: now,\n    updatedAt: now,\n  });\n  \n  return {\n    id: itemId,\n    contentType: newItem.contentType,\n    provider,\n    providerId: newItem.providerId,\n    canonicalUrl: newItem.canonicalUrl,\n    title: newItem.title,\n    creator: newItem.creator,\n    thumbnailUrl: newItem.thumbnailUrl,\n    duration: newItem.durationSeconds,\n    publishedAt: publishedAtISO,\n    createdAt: now,\n    updatedAt: now,\n  };\n}\n```\n\n## NewItem Interface\n\n```typescript\n// Interface for transformed items (before DB insertion)\nexport interface NewItem {\n  contentType: ContentType;\n  providerId: string;\n  canonicalUrl: string;\n  title: string;\n  creator: string;\n  thumbnailUrl?: string;\n  durationSeconds?: number;\n  publishedAt?: number; // Unix milliseconds from transformer\n}\n```\n\n## Two-Table Deduplication Explained\n\n| Table | Purpose | Scope |\n|-------|---------|-------|\n| `provider_items_seen` | Prevent duplicate ingestion | User-wide |\n| `subscription_items` | Track which items came from which subscription | Per-subscription |\n\n**Why both?**\n- User subscribes to channels A and B\n- Both A and B feature the same video (collab)\n- `provider_items_seen`: Ingests video once (user-wide dedup)\n- `subscription_items`: Records video came from A's subscription\n- If user unsubscribes from A, video remains (came from B too)\n\n## Files to Create\n- apps/worker/src/ingestion/processor.ts\n- apps/worker/src/ingestion/types.ts\n\n## Dependencies\n- zine-teq.3 (subscription_items table)\n- zine-teq.4 (provider_items_seen table - existing, verify compatibility)\n- zine-teq.16 (transformers)\n\n## Acceptance Criteria\n- [ ] Idempotent: same item never creates duplicate user_items\n- [ ] Atomic: all writes succeed or all fail\n- [ ] Canonical items shared across users\n- [ ] Subscription tracking maintained\n- [ ] Timestamp conversion between formats\n- [ ] Transaction isolation prevents race conditions\n- [ ] Unit tests cover deduplication scenarios","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:13:03.422298-06:00","updated_at":"2025-12-16T22:26:48.557737-06:00","dependencies":[{"issue_id":"zine-teq.17","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:13:03.422694-06:00","created_by":"daemon"},{"issue_id":"zine-teq.17","depends_on_id":"zine-teq.3","type":"blocks","created_at":"2025-12-16T22:19:38.689573-06:00","created_by":"daemon"},{"issue_id":"zine-teq.17","depends_on_id":"zine-teq.4","type":"blocks","created_at":"2025-12-16T22:19:38.739366-06:00","created_by":"daemon"},{"issue_id":"zine-teq.17","depends_on_id":"zine-teq.16","type":"blocks","created_at":"2025-12-16T22:19:38.784868-06:00","created_by":"daemon"}]}
{"id":"zine-teq.18","title":"Initial Fetch: Latest item semantics on subscription creation","description":"Implement initial fetch logic that triggers when a subscription is created, fetching only the latest item.\n\n## Relationship to zine-teq.13\nThis bead implements the `triggerInitialFetch()` helper function that is called from the subscriptions router's `add` mutation (zine-teq.13). It is NOT a separate module but rather part of the subscription creation flow.\n\n## Why Initial Fetch is Special\nWhen a user subscribes to a channel/show, we DON'T want to:\n- Flood their inbox with 100+ historical items\n- Spend excessive API quota on old content\n\nInstead, we:\n- Fetch the SINGLE latest published item\n- Mark it as seen (idempotency)\n- Add it to inbox as a \"welcome\" item\n- Future polls will fetch items newer than this\n\n## Definition of \"Latest\"\n\n### YouTube\n- First **public, already-published** video in uploads playlist (by upload order)\n- **NOT** scheduled/upcoming videos\n- **NOT** sorted by publishedAt (use playlist order)\n\n```typescript\nasync function fetchLatestYouTubeVideo(\n  client: YouTubeClient,\n  channelId: string\n): Promise\u003cYouTubeVideo | null\u003e {\n  const uploadsPlaylistId = await getChannelUploadsPlaylistId(client, channelId);\n  \n  const videos = await client.api.playlistItems.list({\n    part: ['snippet', 'contentDetails', 'status'],\n    playlistId: uploadsPlaylistId,\n    maxResults: 5, // Fetch a few in case some are private/scheduled\n  });\n  \n  // Filter to public, already-published videos\n  const now = Date.now();\n  const eligibleVideos = videos.data.items?.filter(video =\u003e {\n    const status = video.status?.privacyStatus;\n    const publishedAt = new Date(video.snippet?.publishedAt || 0).getTime();\n    return status === 'public' \u0026\u0026 publishedAt \u003c= now;\n  }) || [];\n  \n  return eligibleVideos[0] || null; // First in playlist order\n}\n```\n\n### Spotify\n- First episode with `release_date \u003c= today`\n- **NOT** future episodes\n\n```typescript\nasync function fetchLatestSpotifyEpisode(\n  client: SpotifyApi,\n  showId: string\n): Promise\u003cSpotifyEpisode | null\u003e {\n  const episodes = await client.shows.episodes(showId, undefined, 5);\n  \n  const today = new Date().toISOString().split('T')[0]; // YYYY-MM-DD\n  const eligibleEpisodes = episodes.items.filter(ep =\u003e {\n    // Spotify dates can be YYYY, YYYY-MM, or YYYY-MM-DD\n    const releaseDate = ep.release_date.padEnd(10, '-01'); // Normalize to YYYY-MM-DD\n    return releaseDate \u003c= today;\n  });\n  \n  return eligibleEpisodes[0] || null;\n}\n```\n\n## Main Implementation\n\n```typescript\n// apps/worker/src/subscriptions/initial-fetch.ts\n\nexport async function triggerInitialFetch(\n  userId: string,\n  subscriptionId: string,\n  connection: ProviderConnection,\n  provider: Provider,\n  providerChannelId: string,\n  env: Env\n): Promise\u003c{ itemIngested: boolean }\u003e {\n  try {\n    let rawItem: YouTubeVideo | SpotifyEpisode | null = null;\n    let transformer: TransformFn;\n    \n    if (provider === 'YOUTUBE') {\n      const client = await getYouTubeClientForConnection(connection, env);\n      rawItem = await fetchLatestYouTubeVideo(client, providerChannelId);\n      transformer = transformYouTubeVideo;\n    } else if (provider === 'SPOTIFY') {\n      const client = await getSpotifyClientForConnection(connection, env);\n      rawItem = await fetchLatestSpotifyEpisode(client, providerChannelId);\n      transformer = transformSpotifyEpisode;\n    } else {\n      return { itemIngested: false };\n    }\n    \n    if (!rawItem) {\n      // Channel is empty or only has scheduled content\n      console.log(`No eligible items for initial fetch: ${subscriptionId}`);\n      return { itemIngested: false };\n    }\n    \n    // Ingest the single item\n    const result = await ingestItem(\n      userId,\n      subscriptionId,\n      rawItem,\n      provider,\n      db,\n      transformer\n    );\n    \n    // Update subscription with initial poll timestamp\n    await db.update(subscriptions)\n      .set({\n        lastPolledAt: Date.now(),\n        lastPublishedAt: new Date(rawItem.publishedAt || rawItem.release_date).getTime(),\n        updatedAt: Date.now(),\n      })\n      .where(eq(subscriptions.id, subscriptionId));\n    \n    return { itemIngested: result.created };\n  } catch (error) {\n    // Log but don't fail subscription creation\n    console.error(`Initial fetch failed for ${subscriptionId}:`, error);\n    return { itemIngested: false };\n  }\n}\n```\n\n## Edge Cases\n\n| Scenario | Handling |\n|----------|----------|\n| Empty channel | Return `{ itemIngested: false }`, subscription still created |\n| Only scheduled videos | Skip them, may return no item |\n| Private videos | Skip them, return first public video |\n| API error | Log error, return `{ itemIngested: false }` |\n| Already seen item | Idempotency check prevents duplicate |\n\n## Files to Create\n- apps/worker/src/subscriptions/initial-fetch.ts\n\n## Dependencies\n- zine-teq.10 (YouTube SDK)\n- zine-teq.11 (Spotify SDK)\n- zine-teq.17 (ingestion pipeline)\n\n## Acceptance Criteria\n- [ ] Only fetches single latest item\n- [ ] Filters out scheduled/private content\n- [ ] Uses playlist order for YouTube (not publishedAt sort)\n- [ ] Handles empty channels gracefully\n- [ ] Updates subscription timestamps after initial fetch\n- [ ] Errors don't fail subscription creation\n- [ ] Unit tests cover edge cases","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:13:30.337091-06:00","updated_at":"2025-12-16T22:26:18.863284-06:00","dependencies":[{"issue_id":"zine-teq.18","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:13:30.337474-06:00","created_by":"daemon"},{"issue_id":"zine-teq.18","depends_on_id":"zine-teq.10","type":"blocks","created_at":"2025-12-16T22:19:42.535828-06:00","created_by":"daemon"},{"issue_id":"zine-teq.18","depends_on_id":"zine-teq.11","type":"blocks","created_at":"2025-12-16T22:19:42.584945-06:00","created_by":"daemon"},{"issue_id":"zine-teq.18","depends_on_id":"zine-teq.17","type":"blocks","created_at":"2025-12-16T22:19:42.630455-06:00","created_by":"daemon"}]}
{"id":"zine-teq.19","title":"Polling: Cron job with distributed locking and batch processing","description":"Implement the main subscription polling cron job with distributed locks to prevent overlapping executions.\n\n## Cron Configuration\n```toml\n# wrangler.toml\n[triggers]\ncrons = [\"*/15 * * * *\"]  # Every 15 minutes\n```\n\n## Why Distributed Locks?\nCloudflare Workers cron can run on multiple instances. Without locking:\n- Same subscriptions polled multiple times\n- Wasted API quota\n- Potential race conditions in ingestion\n\n## Main Cron Handler\n\n```typescript\n// apps/worker/src/scheduled.ts\n\nexport async function scheduled(\n  event: ScheduledEvent,\n  env: Env,\n  ctx: ExecutionContext\n): Promise\u003cvoid\u003e {\n  switch (event.cron) {\n    case '*/15 * * * *':\n      await pollSubscriptions(env, ctx);\n      break;\n    // Add other crons here as needed\n  }\n}\n```\n\n## Polling Logic with Lock\n\n```typescript\n// apps/worker/src/polling/scheduler.ts\n\nconst POLL_LOCK_KEY = 'cron:poll-subscriptions:lock';\nconst POLL_LOCK_TTL = 900; // 15 minutes (matches cron interval)\nconst BATCH_SIZE = 50;\n\nexport async function pollSubscriptions(\n  env: Env,\n  ctx: ExecutionContext\n): Promise\u003cPollResult\u003e {\n  // 1. Try to acquire distributed lock\n  const existingLock = await env.KV.get(POLL_LOCK_KEY);\n  if (existingLock) {\n    const elapsedMs = Date.now() - parseInt(existingLock, 10);\n    if (elapsedMs \u003c POLL_LOCK_TTL * 1000) {\n      console.log('Poll skipped: lock held by another worker');\n      return { skipped: true, reason: 'lock_held' };\n    }\n    // Lock is stale, proceed to acquire\n  }\n  \n  // 2. Acquire lock (optimistic, KV is eventually consistent)\n  await env.KV.put(POLL_LOCK_KEY, Date.now().toString(), { \n    expirationTtl: POLL_LOCK_TTL \n  });\n  \n  try {\n    // 3. Find due subscriptions\n    const now = Date.now();\n    const dueSubscriptions = await db.query.subscriptions.findMany({\n      where: and(\n        eq(subscriptions.status, 'ACTIVE'),\n        or(\n          isNull(subscriptions.lastPolledAt),\n          lt(\n            subscriptions.lastPolledAt, \n            sql`${now} - (${subscriptions.pollIntervalSeconds} * 1000)`\n          )\n        )\n      ),\n      orderBy: [asc(subscriptions.lastPolledAt)], // Oldest first\n      limit: BATCH_SIZE,\n    });\n    \n    if (dueSubscriptions.length === 0) {\n      return { skipped: false, processed: 0, reason: 'no_due_subscriptions' };\n    }\n    \n    // 4. Group by provider for efficient token usage\n    const byProvider = groupBy(dueSubscriptions, 'provider');\n    \n    // 5. Process each provider's subscriptions\n    const results = await Promise.all([\n      processYouTubeBatch(byProvider.YOUTUBE || [], env),\n      processSpotifyBatch(byProvider.SPOTIFY || [], env),\n    ]);\n    \n    const totalProcessed = results.reduce((sum, r) =\u003e sum + r.processed, 0);\n    const totalNewItems = results.reduce((sum, r) =\u003e sum + r.newItems, 0);\n    \n    return {\n      skipped: false,\n      processed: totalProcessed,\n      newItems: totalNewItems,\n    };\n  } finally {\n    // 6. Release lock\n    await env.KV.delete(POLL_LOCK_KEY);\n  }\n}\n```\n\n## Provider Batch Processing\n\n```typescript\nasync function processYouTubeBatch(\n  subscriptions: Subscription[],\n  env: Env\n): Promise\u003cBatchResult\u003e {\n  if (subscriptions.length === 0) {\n    return { processed: 0, newItems: 0 };\n  }\n  \n  // Group subscriptions by user (to share client/token)\n  const byUser = groupBy(subscriptions, 'userId');\n  \n  let processed = 0;\n  let newItems = 0;\n  \n  for (const [userId, userSubs] of Object.entries(byUser)) {\n    // Check rate limit before processing user's subscriptions\n    const rateCheck = await isRateLimited('YOUTUBE', userId, env.KV);\n    if (rateCheck.limited) {\n      console.log(`Skipping user ${userId}: rate limited`);\n      continue;\n    }\n    \n    // Get user's connection\n    const connection = await getActiveConnection(userId, 'YOUTUBE', env);\n    if (!connection) {\n      // Mark subscriptions as DISCONNECTED\n      await markSubscriptionsDisconnected(userSubs.map(s =\u003e s.id), env);\n      continue;\n    }\n    \n    try {\n      const client = await getYouTubeClientForConnection(connection, env);\n      \n      for (const sub of userSubs) {\n        const result = await pollSingleYouTubeSubscription(sub, client, userId, env);\n        processed++;\n        newItems += result.newItems;\n      }\n    } catch (error) {\n      if (isAuthError(error)) {\n        await markConnectionExpired(connection.id, env);\n        await markSubscriptionsDisconnected(userSubs.map(s =\u003e s.id), env);\n      }\n      console.error(`YouTube batch error for user ${userId}:`, error);\n    }\n  }\n  \n  return { processed, newItems };\n}\n```\n\n## Single Subscription Poll\n\n```typescript\nasync function pollSingleYouTubeSubscription(\n  subscription: Subscription,\n  client: YouTubeClient,\n  userId: string,\n  env: Env\n): Promise\u003c{ newItems: number }\u003e {\n  try {\n    // 1. Fetch recent videos since last poll\n    const uploadsPlaylistId = await getChannelUploadsPlaylistId(\n      client, \n      subscription.providerChannelId\n    );\n    \n    const videos = await fetchRecentVideos(client, uploadsPlaylistId, 10);\n    \n    // 2. Filter to new videos (published after last_polled_at)\n    const newVideos = subscription.lastPolledAt\n      ? videos.filter(v =\u003e \n          new Date(v.publishedAt).getTime() \u003e subscription.lastPolledAt!\n        )\n      : videos.slice(0, 1); // First poll: only latest\n    \n    // 3. Ingest new items\n    let newItems = 0;\n    for (const video of newVideos) {\n      const result = await ingestItem(\n        userId,\n        subscription.id,\n        video,\n        'YOUTUBE',\n        db,\n        transformYouTubeVideo\n      );\n      if (result.created) newItems++;\n    }\n    \n    // 4. Update subscription\n    const newestPublishedAt = videos.length \u003e 0\n      ? Math.max(...videos.map(v =\u003e new Date(v.publishedAt).getTime()))\n      : subscription.lastPublishedAt;\n    \n    await db.update(subscriptions)\n      .set({\n        lastPolledAt: Date.now(),\n        lastPublishedAt: newestPublishedAt,\n        updatedAt: Date.now(),\n      })\n      .where(eq(subscriptions.id, subscription.id));\n    \n    // Clear poll failure count on success\n    await clearPollFailures(subscription.id, env);\n    \n    return { newItems };\n  } catch (error) {\n    // Track poll failure\n    await trackPollFailure(subscription.id, error as Error, env);\n    \n    // Update lastPolledAt even on error to prevent tight retry loops\n    await db.update(subscriptions)\n      .set({ lastPolledAt: Date.now(), updatedAt: Date.now() })\n      .where(eq(subscriptions.id, subscription.id));\n    \n    throw error;\n  }\n}\n```\n\n## Result Types\n```typescript\ninterface PollResult {\n  skipped: boolean;\n  reason?: string;\n  processed?: number;\n  newItems?: number;\n}\n\ninterface BatchResult {\n  processed: number;\n  newItems: number;\n}\n```\n\n## Files to Create/Modify\n- apps/worker/src/scheduled.ts - Cron handler\n- apps/worker/src/polling/scheduler.ts - Main polling logic\n- apps/worker/wrangler.toml - Add cron trigger\n\n## Dependencies\n- zine-teq.9 (token refresh)\n- zine-teq.10 (YouTube SDK)\n- zine-teq.11 (Spotify SDK)\n- zine-teq.17 (ingestion pipeline)\n- zine-teq.22 (rate limiter)\n- zine-teq.25 (connection health - for trackPollFailure)\n\n## Acceptance Criteria\n- [ ] Cron triggers every 15 minutes\n- [ ] Distributed lock prevents overlapping executions\n- [ ] Only processes subscriptions due for polling\n- [ ] Groups by provider and user for efficiency\n- [ ] Updates lastPolledAt after each subscription\n- [ ] Handles auth errors by marking disconnected\n- [ ] Continues processing on individual subscription errors\n- [ ] Rate limits respected per user/provider\n- [ ] Poll failures tracked for health monitoring\n- [ ] Integration tests verify polling behavior","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:14:01.383353-06:00","updated_at":"2025-12-16T22:25:26.511796-06:00","dependencies":[{"issue_id":"zine-teq.19","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:14:01.383764-06:00","created_by":"daemon"},{"issue_id":"zine-teq.19","depends_on_id":"zine-teq.9","type":"blocks","created_at":"2025-12-16T22:19:47.545616-06:00","created_by":"daemon"},{"issue_id":"zine-teq.19","depends_on_id":"zine-teq.10","type":"blocks","created_at":"2025-12-16T22:19:47.595066-06:00","created_by":"daemon"},{"issue_id":"zine-teq.19","depends_on_id":"zine-teq.11","type":"blocks","created_at":"2025-12-16T22:19:47.641007-06:00","created_by":"daemon"},{"issue_id":"zine-teq.19","depends_on_id":"zine-teq.17","type":"blocks","created_at":"2025-12-16T22:19:47.686476-06:00","created_by":"daemon"}]}
{"id":"zine-teq.2","title":"Database Schema: subscriptions table","description":"Create the subscriptions table to track user subscriptions to YouTube channels and Spotify shows.\n\n## Table Definition\n```sql\nCREATE TABLE subscriptions (\n  id TEXT PRIMARY KEY,                    -- ULID\n  user_id TEXT NOT NULL,                  -- FK to users\n  provider TEXT NOT NULL,                 -- 'YOUTUBE' | 'SPOTIFY'\n  provider_channel_id TEXT NOT NULL,      -- YouTube channel ID (UC...) or Spotify show ID\n  name TEXT NOT NULL,                     -- Channel/show display name\n  description TEXT,                       -- Channel/show description (cached)\n  image_url TEXT,                         -- Thumbnail/artwork URL (cached)\n  external_url TEXT,                      -- Link to channel/show on provider\n  total_items INTEGER,                    -- Total videos/episodes (cached, informational)\n  last_published_at INTEGER,              -- Timestamp of newest known item (ms)\n  last_polled_at INTEGER,                 -- Last successful poll timestamp (ms)\n  poll_interval_seconds INTEGER NOT NULL DEFAULT 3600, -- Polling frequency\n  status TEXT NOT NULL DEFAULT 'ACTIVE',  -- ACTIVE | PAUSED | DISCONNECTED | UNSUBSCRIBED\n  created_at INTEGER NOT NULL DEFAULT (unixepoch() * 1000),\n  updated_at INTEGER NOT NULL DEFAULT (unixepoch() * 1000),\n  \n  UNIQUE(user_id, provider, provider_channel_id)\n);\n\nCREATE INDEX idx_subscriptions_poll ON subscriptions(status, last_polled_at);\nCREATE INDEX idx_subscriptions_user ON subscriptions(user_id, status);\n```\n\n## Implementation Notes\n- **Polling index**: idx_subscriptions_poll enables efficient queries for 'find subscriptions due for polling'\n- **User index**: idx_subscriptions_user supports fast listing of a user's active subscriptions\n- **poll_interval_seconds**: Stored in seconds (not ms) since it's a duration, not a timestamp\n- **Soft delete via status**: UNSUBSCRIBED preserves metadata; hard delete only for subscription_items\n\n## Status Semantics\n- ACTIVE: Polling enabled, content delivered to inbox\n- PAUSED: User-initiated pause, no polling, can resume\n- DISCONNECTED: Provider connection lost/expired, needs reconnection\n- UNSUBSCRIBED: Soft-deleted, preserved for re-subscribe detection\n\n## Why This Design\n- Caching name/image_url avoids provider API calls for display\n- last_published_at enables showing 'last updated X ago' in UI\n- poll_interval_seconds per-subscription enables adaptive polling\n- External URL useful for 'open in YouTube/Spotify' actions\n\n## Files to Modify\n- apps/worker/src/db/schema.ts\n- apps/worker/src/db/migrations/\n\n## Acceptance Criteria\n- [ ] Table created with all columns and constraints\n- [ ] Both indexes created for query performance\n- [ ] Migration runs successfully\n- [ ] Drizzle schema exports the table","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:07:39.601359-06:00","updated_at":"2025-12-16T22:07:39.601359-06:00","dependencies":[{"issue_id":"zine-teq.2","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:07:39.60172-06:00","created_by":"daemon"}]}
{"id":"zine-teq.20","title":"Polling: Adaptive interval adjustment based on channel activity","description":"Implement adaptive polling intervals that adjust based on channel publishing frequency.\n\n## Motivation\nPolling every hour for a channel that posts monthly wastes quota and resources. Conversely, a daily vlogger needs more frequent checks.\n\n## Interval Tiers\n| Channel Activity | Polling Interval | Detection Criteria |\n|-----------------|------------------|-------------------|\n| Very active | 1 hour | 7+ items in last 7 days |\n| Active | 4 hours | 1-6 items in last 7 days |\n| Moderate | 12 hours | 1-4 items in last 30 days |\n| Inactive | 24 hours | No items in 30+ days |\n\n## Implementation\n\n### Activity Detection\n```typescript\n// apps/worker/src/polling/adaptive.ts\n\ninterface ActivityMetrics {\n  itemsLast7Days: number;\n  itemsLast30Days: number;\n  daysSinceLastItem: number | null;\n}\n\nexport function calculateOptimalInterval(metrics: ActivityMetrics): number {\n  // Very active: 7+ items in last week\n  if (metrics.itemsLast7Days \u003e= 7) {\n    return 3600; // 1 hour\n  }\n  \n  // Active: at least 1 item in last week\n  if (metrics.itemsLast7Days \u003e= 1) {\n    return 4 * 3600; // 4 hours\n  }\n  \n  // Moderate: at least 1 item in last 30 days\n  if (metrics.itemsLast30Days \u003e= 1) {\n    return 12 * 3600; // 12 hours\n  }\n  \n  // Inactive: no items in 30+ days\n  return 24 * 3600; // 24 hours\n}\n\nexport async function getActivityMetrics(\n  subscriptionId: string,\n  db: DrizzleDB\n): Promise\u003cActivityMetrics\u003e {\n  const now = Date.now();\n  const sevenDaysAgo = now - 7 * 24 * 3600 * 1000;\n  const thirtyDaysAgo = now - 30 * 24 * 3600 * 1000;\n  \n  // Count items from this subscription by published_at\n  const items = await db.query.subscriptionItems.findMany({\n    where: eq(subscriptionItems.subscriptionId, subscriptionId),\n    columns: { publishedAt: true },\n    orderBy: [desc(subscriptionItems.publishedAt)],\n    limit: 100, // Enough to calculate metrics\n  });\n  \n  return {\n    itemsLast7Days: items.filter(i =\u003e i.publishedAt \u0026\u0026 i.publishedAt \u003e sevenDaysAgo).length,\n    itemsLast30Days: items.filter(i =\u003e i.publishedAt \u0026\u0026 i.publishedAt \u003e thirtyDaysAgo).length,\n    daysSinceLastItem: items.length \u003e 0 \u0026\u0026 items[0].publishedAt\n      ? Math.floor((now - items[0].publishedAt) / (24 * 3600 * 1000))\n      : null,\n  };\n}\n```\n\n### Interval Update Hook\nCalled after successful poll:\n\n```typescript\nexport async function maybeUpdatePollInterval(\n  subscriptionId: string,\n  db: DrizzleDB\n): Promise\u003cvoid\u003e {\n  const metrics = await getActivityMetrics(subscriptionId, db);\n  const optimalInterval = calculateOptimalInterval(metrics);\n  \n  const subscription = await db.query.subscriptions.findFirst({\n    where: eq(subscriptions.id, subscriptionId),\n    columns: { pollIntervalSeconds: true },\n  });\n  \n  if (!subscription) return;\n  \n  // Only update if interval changed significantly (avoid DB writes for minor changes)\n  const currentInterval = subscription.pollIntervalSeconds;\n  const change = Math.abs(optimalInterval - currentInterval) / currentInterval;\n  \n  if (change \u003e= 0.5) { // 50% change threshold\n    await db.update(subscriptions)\n      .set({ pollIntervalSeconds: optimalInterval, updatedAt: Date.now() })\n      .where(eq(subscriptions.id, subscriptionId));\n    \n    console.log(`Adjusted poll interval for ${subscriptionId}: ${currentInterval}s → ${optimalInterval}s`);\n  }\n}\n```\n\n### Integration with Polling\nAdd to pollSingleSubscription after successful ingestion:\n\n```typescript\n// In polling/scheduler.ts\nasync function pollSingleYouTubeSubscription(...) {\n  // ... existing poll logic ...\n  \n  // After successful poll, consider adjusting interval\n  if (shouldAdjustInterval(subscription)) {\n    await maybeUpdatePollInterval(subscription.id, db);\n  }\n}\n\nfunction shouldAdjustInterval(subscription: Subscription): boolean {\n  // Only adjust periodically to avoid constant DB writes\n  // Check roughly once per day\n  const dayInMs = 24 * 3600 * 1000;\n  const timeSinceCreation = Date.now() - subscription.createdAt;\n  const pollCount = Math.floor(timeSinceCreation / (subscription.pollIntervalSeconds * 1000));\n  \n  // Adjust every ~24 polls (roughly daily for most intervals)\n  return pollCount % 24 === 0;\n}\n```\n\n## Quota Impact Analysis\nWith adaptive polling, a user with 10 subscriptions:\n\n**Without adaptive polling** (all 1 hour):\n- 10 subs × 24 polls/day = 240 polls/day\n- × 2 API calls/poll = 480 quota/day\n\n**With adaptive polling** (realistic mix):\n- 2 very active (1h) = 48 polls\n- 3 active (4h) = 18 polls  \n- 3 moderate (12h) = 6 polls\n- 2 inactive (24h) = 2 polls\n- Total: 74 polls × 2 = 148 quota/day\n\n**Savings: ~70%** quota reduction!\n\n## Override Capability\nAllow users to set preferred interval (future feature):\n```sql\nALTER TABLE subscriptions ADD COLUMN user_poll_interval_seconds INTEGER;\n```\n\nIf set, use max(user_poll_interval_seconds, adaptive_interval) to prevent excessive polling.\n\n## Files to Create/Modify\n- apps/worker/src/polling/adaptive.ts - New file\n- apps/worker/src/polling/scheduler.ts - Integration\n\n## Dependencies\n- zine-teq.19 (polling cron)\n- zine-teq.3 (subscription_items table)\n\n## Acceptance Criteria\n- [ ] Activity metrics calculated from subscription_items\n- [ ] Interval tiers applied correctly\n- [ ] Updates only on significant changes (50%+ difference)\n- [ ] Adjustment happens periodically (not every poll)\n- [ ] Unit tests for each activity tier\n- [ ] Integration test verifies interval changes","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:14:28.786412-06:00","updated_at":"2025-12-16T22:14:28.786412-06:00","dependencies":[{"issue_id":"zine-teq.20","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:14:28.786813-06:00","created_by":"daemon"},{"issue_id":"zine-teq.20","depends_on_id":"zine-teq.19","type":"blocks","created_at":"2025-12-16T22:19:51.224296-06:00","created_by":"daemon"},{"issue_id":"zine-teq.20","depends_on_id":"zine-teq.3","type":"blocks","created_at":"2025-12-16T22:19:51.272861-06:00","created_by":"daemon"}]}
{"id":"zine-teq.21","title":"YouTube: Quota tracking and graceful degradation","description":"Implement YouTube API quota tracking and graceful degradation when approaching limits.\n\n## YouTube Quota System\n- **Daily quota**: 10,000 units (default, resets at midnight Pacific Time)\n- **Per-call costs**: Most operations cost 1 unit, search costs 100 units\n- **No programmatic way to check remaining quota** (must track ourselves)\n\n## Quota Cost Reference\n| Operation | Cost | Notes |\n|-----------|------|-------|\n| channels.list | 1 | Get channel info, uploads playlist |\n| playlistItems.list | 1 | List videos in playlist |\n| subscriptions.list | 1 | User's YouTube subscriptions |\n| videos.list | 1 | Video details (duration, etc.) |\n| search.list | **100** | Channel/video search - AVOID |\n\n## Implementation\n\n### Quota Tracker\n```typescript\n// apps/worker/src/providers/youtube-quota.ts\n\nconst DAILY_QUOTA = 10_000;\nconst WARNING_THRESHOLD = 0.8; // 80%\nconst CRITICAL_THRESHOLD = 0.95; // 95%\n\ninterface QuotaState {\n  used: number;\n  date: string; // YYYY-MM-DD in Pacific Time\n  lastUpdated: number;\n}\n\nexport async function trackQuotaUsage(\n  units: number,\n  env: Env\n): Promise\u003cQuotaStatus\u003e {\n  const today = getPacificDateString();\n  const key = `youtube:quota:${today}`;\n  \n  // Get current usage\n  const stateJson = await env.KV.get(key);\n  const state: QuotaState = stateJson \n    ? JSON.parse(stateJson)\n    : { used: 0, date: today, lastUpdated: Date.now() };\n  \n  // Update usage\n  state.used += units;\n  state.lastUpdated = Date.now();\n  \n  // Persist with TTL (2 days to be safe across timezone edge)\n  await env.KV.put(key, JSON.stringify(state), { expirationTtl: 2 * 24 * 3600 });\n  \n  return {\n    used: state.used,\n    remaining: DAILY_QUOTA - state.used,\n    percentUsed: (state.used / DAILY_QUOTA) * 100,\n    isWarning: state.used / DAILY_QUOTA \u003e= WARNING_THRESHOLD,\n    isCritical: state.used / DAILY_QUOTA \u003e= CRITICAL_THRESHOLD,\n  };\n}\n\nfunction getPacificDateString(): string {\n  return new Date().toLocaleDateString('en-CA', { \n    timeZone: 'America/Los_Angeles' \n  });\n}\n```\n\n### Pre-call Quota Check\n```typescript\nexport async function canUseQuota(\n  estimatedUnits: number,\n  env: Env\n): Promise\u003c{ allowed: boolean; reason?: string }\u003e {\n  const today = getPacificDateString();\n  const key = `youtube:quota:${today}`;\n  \n  const stateJson = await env.KV.get(key);\n  const state: QuotaState = stateJson \n    ? JSON.parse(stateJson)\n    : { used: 0, date: today, lastUpdated: Date.now() };\n  \n  const projectedUsage = state.used + estimatedUnits;\n  const projectedPercent = projectedUsage / DAILY_QUOTA;\n  \n  // Block if would exceed quota\n  if (projectedUsage \u003e DAILY_QUOTA) {\n    return { \n      allowed: false, \n      reason: `Would exceed daily quota (used: ${state.used}, requested: ${estimatedUnits})`\n    };\n  }\n  \n  // Block non-essential operations when critical\n  if (projectedPercent \u003e= CRITICAL_THRESHOLD \u0026\u0026 estimatedUnits \u003e 2) {\n    return {\n      allowed: false,\n      reason: `Critical quota level (${Math.round(projectedPercent * 100)}%), only essential operations allowed`\n    };\n  }\n  \n  return { allowed: true };\n}\n```\n\n### Wrapped API Calls\n```typescript\n// apps/worker/src/providers/youtube.ts\n\nexport async function fetchRecentVideosWithQuota(\n  client: YouTubeClient,\n  uploadsPlaylistId: string,\n  maxResults: number,\n  env: Env\n): Promise\u003cYouTubeVideo[]\u003e {\n  // Estimate: 1 unit for playlistItems.list\n  const check = await canUseQuota(1, env);\n  if (!check.allowed) {\n    throw new QuotaExhaustedError(check.reason!);\n  }\n  \n  const videos = await client.api.playlistItems.list({\n    part: ['snippet', 'contentDetails'],\n    playlistId: uploadsPlaylistId,\n    maxResults,\n  });\n  \n  await trackQuotaUsage(1, env);\n  \n  return videos.data.items || [];\n}\n\nexport class QuotaExhaustedError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'QuotaExhaustedError';\n  }\n}\n```\n\n### Graceful Degradation Strategies\n\n#### When Warning (80%):\n- Reduce batch sizes\n- Increase polling intervals for inactive channels\n- Log warning for monitoring\n\n```typescript\nasync function processYouTubeBatchWithQuota(\n  subscriptions: Subscription[],\n  env: Env\n): Promise\u003cBatchResult\u003e {\n  const status = await getQuotaStatus(env);\n  \n  if (status.isCritical) {\n    // Skip YouTube polling entirely when critical\n    console.warn('YouTube quota critical, skipping batch');\n    return { processed: 0, newItems: 0, skipped: subscriptions.length };\n  }\n  \n  if (status.isWarning) {\n    // Process only most important subscriptions\n    const prioritized = subscriptions\n      .filter(s =\u003e s.pollIntervalSeconds \u003c= 3600) // Only hourly subs\n      .slice(0, 10); // Limit batch\n    return processYouTubeBatch(prioritized, env);\n  }\n  \n  return processYouTubeBatch(subscriptions, env);\n}\n```\n\n#### When Critical (95%):\n- Skip all YouTube polling\n- Send notification to users\n- Continue Spotify polling (unaffected)\n\n### Capacity Estimation\nWith default 10K quota and careful management:\n- ~60 users with 10 subs each (average 4h polling)\n- OR ~120 users with 5 subs each\n- Search severely limited (100 units each!)\n\n## Monitoring\nTrack daily quota patterns to:\n- Request quota increase if consistently near limit\n- Identify abusive patterns\n- Plan for scaling\n\n```typescript\nexport async function logQuotaMetrics(env: Env): Promise\u003cvoid\u003e {\n  const status = await getQuotaStatus(env);\n  console.log(`YouTube Quota: ${status.used}/${DAILY_QUOTA} (${status.percentUsed.toFixed(1)}%)`);\n  \n  if (status.isWarning) {\n    // Could trigger alerting here\n    console.warn('YouTube quota warning level reached');\n  }\n}\n```\n\n## Files to Create/Modify\n- apps/worker/src/providers/youtube-quota.ts - New file\n- apps/worker/src/providers/youtube.ts - Add quota checks to API calls\n- apps/worker/src/polling/scheduler.ts - Integration with graceful degradation\n\n## Dependencies\n- zine-teq.10 (YouTube SDK)\n- zine-teq.19 (polling cron)\n\n## Acceptance Criteria\n- [ ] Quota tracked per Pacific Time day\n- [ ] Pre-call checks prevent over-quota operations\n- [ ] Warning threshold triggers reduced operations\n- [ ] Critical threshold blocks non-essential operations\n- [ ] Quota errors don't crash polling (graceful skip)\n- [ ] Daily metrics logged for monitoring\n- [ ] Unit tests cover threshold behaviors","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:14:59.36417-06:00","updated_at":"2025-12-16T22:14:59.36417-06:00","dependencies":[{"issue_id":"zine-teq.21","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:14:59.364577-06:00","created_by":"daemon"},{"issue_id":"zine-teq.21","depends_on_id":"zine-teq.10","type":"blocks","created_at":"2025-12-16T22:19:54.825851-06:00","created_by":"daemon"},{"issue_id":"zine-teq.21","depends_on_id":"zine-teq.19","type":"blocks","created_at":"2025-12-16T22:19:54.87434-06:00","created_by":"daemon"}]}
{"id":"zine-teq.22","title":"Rate Limiting: Provider-aware fetch with backoff","description":"Implement a rate-limited fetcher with exponential backoff that respects provider-specific limits.\n\n## Provider Rate Limits\n\n### YouTube\n- No official rate limit (quota-based instead)\n- Retry on 403 with 'quotaExceeded' error\n- Back off on 429 (rare)\n\n### Spotify  \n- Rolling 30-second window\n- ~100-180 requests per 30s depending on endpoint\n- Returns 429 with Retry-After header\n\n## Implementation\n\n### Rate Limited Fetcher\n```typescript\n// apps/worker/src/lib/rate-limiter.ts\n\ninterface RateLimitState {\n  retryAfter: number | null; // Unix timestamp when we can retry\n  consecutiveFailures: number;\n  lastRequest: number;\n}\n\nexport class RateLimitedFetcher {\n  private state: Map\u003cstring, RateLimitState\u003e = new Map();\n  \n  constructor(private kv: KVNamespace) {}\n  \n  async fetch(\n    provider: Provider,\n    userId: string,\n    fn: () =\u003e Promise\u003cResponse\u003e\n  ): Promise\u003cResponse\u003e {\n    const key = `rate:${provider}:${userId}`;\n    \n    // 1. Check if we're rate limited\n    const state = await this.getState(key);\n    if (state.retryAfter \u0026\u0026 Date.now() \u003c state.retryAfter) {\n      const waitMs = state.retryAfter - Date.now();\n      throw new RateLimitError(provider, waitMs);\n    }\n    \n    // 2. Execute request\n    try {\n      const response = await fn();\n      \n      // 3. Handle rate limit response\n      if (response.status === 429) {\n        const retryAfter = this.parseRetryAfter(response);\n        await this.setRateLimited(key, retryAfter);\n        throw new RateLimitError(provider, retryAfter - Date.now());\n      }\n      \n      // 4. Clear failure count on success\n      await this.clearState(key);\n      return response;\n      \n    } catch (error) {\n      if (error instanceof RateLimitError) throw error;\n      \n      // 5. Exponential backoff on other errors\n      const newState = await this.incrementFailures(key);\n      const backoffMs = this.calculateBackoff(newState.consecutiveFailures);\n      \n      console.warn(`Request failed, backing off ${backoffMs}ms`, error);\n      throw error;\n    }\n  }\n  \n  private parseRetryAfter(response: Response): number {\n    const header = response.headers.get('Retry-After');\n    if (header) {\n      // Could be seconds or HTTP date\n      const seconds = parseInt(header, 10);\n      if (!isNaN(seconds)) {\n        return Date.now() + seconds * 1000;\n      }\n      // Try parsing as date\n      const date = new Date(header).getTime();\n      if (!isNaN(date)) {\n        return date;\n      }\n    }\n    // Default: 30 seconds\n    return Date.now() + 30 * 1000;\n  }\n  \n  private calculateBackoff(failures: number): number {\n    // Exponential backoff with jitter: 2^n * 1000ms + random 0-1000ms\n    const base = Math.min(Math.pow(2, failures) * 1000, 300000); // Max 5 min\n    const jitter = Math.random() * 1000;\n    return base + jitter;\n  }\n  \n  private async getState(key: string): Promise\u003cRateLimitState\u003e {\n    const cached = this.state.get(key);\n    if (cached) return cached;\n    \n    const stored = await this.kv.get(key);\n    const state = stored \n      ? JSON.parse(stored) \n      : { retryAfter: null, consecutiveFailures: 0, lastRequest: 0 };\n    \n    this.state.set(key, state);\n    return state;\n  }\n  \n  private async setRateLimited(key: string, retryAfter: number): Promise\u003cvoid\u003e {\n    const state = await this.getState(key);\n    state.retryAfter = retryAfter;\n    state.consecutiveFailures++;\n    this.state.set(key, state);\n    \n    const ttl = Math.ceil((retryAfter - Date.now()) / 1000) + 60;\n    await this.kv.put(key, JSON.stringify(state), { expirationTtl: ttl });\n  }\n  \n  private async incrementFailures(key: string): Promise\u003cRateLimitState\u003e {\n    const state = await this.getState(key);\n    state.consecutiveFailures++;\n    state.lastRequest = Date.now();\n    this.state.set(key, state);\n    \n    await this.kv.put(key, JSON.stringify(state), { expirationTtl: 3600 });\n    return state;\n  }\n  \n  private async clearState(key: string): Promise\u003cvoid\u003e {\n    this.state.delete(key);\n    await this.kv.delete(key);\n  }\n}\n\nexport class RateLimitError extends Error {\n  constructor(\n    public provider: Provider,\n    public retryInMs: number\n  ) {\n    super(`Rate limited by ${provider}, retry in ${Math.ceil(retryInMs / 1000)}s`);\n    this.name = 'RateLimitError';\n  }\n}\n```\n\n### Pre-emptive Rate Limit Check\n```typescript\nexport async function isRateLimited(\n  provider: Provider,\n  userId: string,\n  kv: KVNamespace\n): Promise\u003c{ limited: boolean; retryInMs?: number }\u003e {\n  const key = `rate:${provider}:${userId}`;\n  const stored = await kv.get(key);\n  \n  if (!stored) return { limited: false };\n  \n  const state: RateLimitState = JSON.parse(stored);\n  if (!state.retryAfter || Date.now() \u003e= state.retryAfter) {\n    return { limited: false };\n  }\n  \n  return { \n    limited: true, \n    retryInMs: state.retryAfter - Date.now() \n  };\n}\n```\n\n### Integration with Polling\n```typescript\n// In polling/scheduler.ts\nasync function pollSingleSubscription(\n  subscription: Subscription,\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cPollResult\u003e {\n  // Check rate limit before attempting\n  const rateCheck = await isRateLimited(\n    subscription.provider, \n    subscription.userId, \n    env.KV\n  );\n  \n  if (rateCheck.limited) {\n    console.log(`Skipping ${subscription.id}: rate limited for ${rateCheck.retryInMs}ms`);\n    return { skipped: true, reason: 'rate_limited' };\n  }\n  \n  // Proceed with poll...\n}\n```\n\n## Backoff Schedule\n| Consecutive Failures | Backoff |\n|---------------------|---------|\n| 1 | 2s + jitter |\n| 2 | 4s + jitter |\n| 3 | 8s + jitter |\n| 4 | 16s + jitter |\n| 5+ | 32s + jitter (capped) |\n\n## Files to Create\n- apps/worker/src/lib/rate-limiter.ts\n\n## Dependencies\n- zine-teq.26 (Wrangler config with KV namespace)\n\n## Acceptance Criteria\n- [ ] Respects Retry-After header from providers\n- [ ] Exponential backoff on repeated failures\n- [ ] Jitter prevents thundering herd\n- [ ] Pre-emptive check skips rate-limited requests\n- [ ] State persisted in KV for cross-worker consistency\n- [ ] Unit tests cover all backoff scenarios","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:15:25.84527-06:00","updated_at":"2025-12-16T22:24:50.563525-06:00","dependencies":[{"issue_id":"zine-teq.22","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:15:25.845662-06:00","created_by":"daemon"},{"issue_id":"zine-teq.22","depends_on_id":"zine-teq.7","type":"blocks","created_at":"2025-12-16T22:19:58.235193-06:00","created_by":"daemon"}]}
{"id":"zine-teq.23","title":"YouTube: PubSubHubbub push notifications (optional)","description":"Implement YouTube PubSubHubbub integration for real-time notifications as an alternative to polling.\n\n## Overview\nYouTube supports WebSub (PubSubHubbub) for push notifications when channels publish new videos. Benefits:\n- **Zero quota cost** (notifications pushed, not pulled)\n- **Near real-time** (seconds vs hours with polling)\n- **Scales infinitely** (no per-subscription API calls)\n\n## Architecture\n\n### Subscription Flow\n1. When user subscribes to a channel, register with PubSubHubbub hub\n2. Hub verifies our callback URL (GET request with challenge)\n3. Hub pushes notifications to callback when channel posts (POST with Atom feed)\n4. We process notification and ingest items\n\n### Lease Management\n- Leases last up to 432,000 seconds (5 days)\n- Must renew before expiry\n- Store lease expiry in subscriptions table\n\n## Implementation\n\n### Hub Registration\n```typescript\n// apps/worker/src/providers/youtube-push.ts\n\nconst HUB_URL = 'https://pubsubhubbub.appspot.com/subscribe';\n\nexport async function subscribeToYouTubeChannel(\n  channelId: string,\n  env: Env\n): Promise\u003cvoid\u003e {\n  const callbackUrl = `${env.BASE_URL}/webhooks/youtube?channel=${channelId}`;\n  const topicUrl = `https://www.youtube.com/xml/feeds/videos.xml?channel_id=${channelId}`;\n  \n  const response = await fetch(HUB_URL, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n    body: new URLSearchParams({\n      'hub.callback': callbackUrl,\n      'hub.topic': topicUrl,\n      'hub.mode': 'subscribe',\n      'hub.lease_seconds': '432000', // 5 days\n      'hub.verify': 'async',\n    }),\n  });\n  \n  if (!response.ok) {\n    throw new PushSubscriptionError(`Hub returned ${response.status}`);\n  }\n}\n\nexport async function unsubscribeFromYouTubeChannel(\n  channelId: string,\n  env: Env\n): Promise\u003cvoid\u003e {\n  const callbackUrl = `${env.BASE_URL}/webhooks/youtube?channel=${channelId}`;\n  const topicUrl = `https://www.youtube.com/xml/feeds/videos.xml?channel_id=${channelId}`;\n  \n  await fetch(HUB_URL, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n    body: new URLSearchParams({\n      'hub.callback': callbackUrl,\n      'hub.topic': topicUrl,\n      'hub.mode': 'unsubscribe',\n    }),\n  });\n}\n```\n\n### Webhook Handler\n```typescript\n// apps/worker/src/routes/webhooks.ts\n\nexport async function handleYouTubeWebhook(\n  request: Request,\n  env: Env\n): Promise\u003cResponse\u003e {\n  const url = new URL(request.url);\n  const channelId = url.searchParams.get('channel');\n  \n  if (!channelId) {\n    return new Response('Missing channel', { status: 400 });\n  }\n  \n  // Hub verification (GET request with challenge)\n  if (request.method === 'GET') {\n    const challenge = url.searchParams.get('hub.challenge');\n    const mode = url.searchParams.get('hub.mode');\n    \n    if (mode === 'subscribe' \u0026\u0026 challenge) {\n      console.log(`Verified push subscription for channel ${channelId}`);\n      return new Response(challenge, { status: 200 });\n    }\n    \n    return new Response('Invalid verification', { status: 400 });\n  }\n  \n  // Notification (POST with Atom feed)\n  if (request.method === 'POST') {\n    const body = await request.text();\n    await processYouTubeNotification(channelId, body, env);\n    return new Response('OK', { status: 200 });\n  }\n  \n  return new Response('Method not allowed', { status: 405 });\n}\n```\n\n### Notification Processing\n```typescript\nexport async function processYouTubeNotification(\n  channelId: string,\n  atomXml: string,\n  env: Env\n): Promise\u003cvoid\u003e {\n  // Parse Atom feed to extract video details\n  const videos = parseAtomFeed(atomXml);\n  \n  if (videos.length === 0) {\n    console.log(`Push notification for ${channelId} contained no videos`);\n    return;\n  }\n  \n  // Find all subscriptions for this channel\n  const subs = await db.query.subscriptions.findMany({\n    where: and(\n      eq(subscriptions.provider, 'YOUTUBE'),\n      eq(subscriptions.providerChannelId, channelId),\n      eq(subscriptions.status, 'ACTIVE')\n    ),\n  });\n  \n  // Ingest for each user (respecting idempotency)\n  for (const sub of subs) {\n    for (const video of videos) {\n      await ingestItem(\n        sub.userId,\n        sub.id,\n        video,\n        'YOUTUBE',\n        db,\n        transformYouTubeVideoFromAtom\n      );\n    }\n    \n    // Update lastPolledAt to prevent redundant polling\n    await db.update(subscriptions)\n      .set({ lastPolledAt: Date.now() })\n      .where(eq(subscriptions.id, sub.id));\n  }\n}\n```\n\n### Lease Renewal Cron\n```toml\n# wrangler.toml\n[triggers]\ncrons = [\n  \"*/15 * * * *\",   # Poll subscriptions\n  \"0 4 * * *\",      # Renew push leases daily at 4 AM\n]\n```\n\n```typescript\nexport async function renewPushLeases(env: Env): Promise\u003cvoid\u003e {\n  const expiringWithin = 2 * 24 * 3600 * 1000; // 2 days\n  const now = Date.now();\n  \n  // Find subscriptions with expiring leases\n  const expiring = await db.query.subscriptions.findMany({\n    where: and(\n      eq(subscriptions.provider, 'YOUTUBE'),\n      eq(subscriptions.status, 'ACTIVE'),\n      lt(subscriptions.pushLeaseExpiresAt, now + expiringWithin)\n    ),\n    columns: { providerChannelId: true },\n  });\n  \n  // Get unique channels\n  const channels = [...new Set(expiring.map(s =\u003e s.providerChannelId))];\n  \n  for (const channelId of channels) {\n    try {\n      await subscribeToYouTubeChannel(channelId, env);\n      await db.update(subscriptions)\n        .set({ pushLeaseExpiresAt: now + 5 * 24 * 3600 * 1000 })\n        .where(and(\n          eq(subscriptions.provider, 'YOUTUBE'),\n          eq(subscriptions.providerChannelId, channelId)\n        ));\n    } catch (e) {\n      console.error(`Failed to renew lease for ${channelId}:`, e);\n    }\n  }\n}\n```\n\n## Schema Addition\n```sql\nALTER TABLE subscriptions \nADD COLUMN push_lease_expires_at INTEGER;\n```\n\n## Hybrid Approach\nUse push as primary, polling as fallback:\n- Register push subscription on channel add\n- If push lease expires or fails, fall back to polling\n- Polling cron skips channels with active push subscriptions\n\n## Considerations\n- Requires publicly accessible callback URL\n- Notifications can be delayed (usually \u003c1 min)\n- Some notifications may be duplicate (idempotency handles this)\n- Not all YouTube events trigger notifications\n\n## Files to Create/Modify\n- apps/worker/src/providers/youtube-push.ts - Push subscription logic\n- apps/worker/src/routes/webhooks.ts - Webhook handler\n- apps/worker/src/polling/scheduler.ts - Skip push-enabled subscriptions\n- apps/worker/wrangler.toml - Add lease renewal cron\n\n## Dependencies\n- zine-teq.17 (ingestion pipeline)\n- zine-teq.19 (polling cron integration)\n- zine-teq.2 (subscriptions table - may need migration)\n\n## Acceptance Criteria\n- [ ] Push subscription registered on channel add\n- [ ] Webhook verifies hub challenges\n- [ ] Notifications trigger ingestion\n- [ ] Lease renewal cron runs daily\n- [ ] Polling skips channels with active push\n- [ ] Fallback to polling on push failure\n- [ ] Integration tests with mock hub","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:15:57.711947-06:00","updated_at":"2025-12-16T22:15:57.711947-06:00","dependencies":[{"issue_id":"zine-teq.23","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:15:57.712342-06:00","created_by":"daemon"},{"issue_id":"zine-teq.23","depends_on_id":"zine-teq.17","type":"blocks","created_at":"2025-12-16T22:20:02.352111-06:00","created_by":"daemon"},{"issue_id":"zine-teq.23","depends_on_id":"zine-teq.19","type":"blocks","created_at":"2025-12-16T22:20:02.40378-06:00","created_by":"daemon"},{"issue_id":"zine-teq.23","depends_on_id":"zine-teq.2","type":"blocks","created_at":"2025-12-16T22:20:02.4517-06:00","created_by":"daemon"}]}
{"id":"zine-teq.24","title":"Security: Encryption key rotation support","description":"Implement encryption key rotation to support periodic key changes without downtime.\n\n## Why Key Rotation\n- Security best practice: limit exposure if key is compromised\n- Compliance requirements may mandate periodic rotation\n- Ability to respond to key leaks without emergency\n\n## Versioned Ciphertext Format\nCurrent format: `{iv}:{ciphertext}`\nNew format: `v{version}:{iv}:{ciphertext}`\n\nVersion allows decryption with correct key even during transition.\n\n## Implementation\n\n### Multi-Key Decryption\n```typescript\n// apps/worker/src/lib/crypto.ts\n\ninterface EncryptionKeys {\n  current: { version: number; keyHex: string };\n  previous?: { version: number; keyHex: string };\n}\n\nexport async function encryptWithVersion(\n  plaintext: string,\n  keys: EncryptionKeys\n): Promise\u003cstring\u003e {\n  const key = await importKey(keys.current.keyHex);\n  const iv = crypto.getRandomValues(new Uint8Array(12));\n  const encoded = new TextEncoder().encode(plaintext);\n  \n  const ciphertext = await crypto.subtle.encrypt(\n    { name: 'AES-GCM', iv },\n    key,\n    encoded\n  );\n  \n  return `v${keys.current.version}:${bytesToHex(iv)}:${bytesToHex(new Uint8Array(ciphertext))}`;\n}\n\nexport async function decryptWithVersion(\n  encrypted: string,\n  keys: EncryptionKeys\n): Promise\u003cstring\u003e {\n  // Handle legacy format (no version prefix)\n  if (!encrypted.startsWith('v')) {\n    // Assume version 1 or try current key\n    return decryptLegacy(encrypted, keys.current.keyHex);\n  }\n  \n  const [versionPart, ivHex, ciphertextHex] = encrypted.split(':');\n  const version = parseInt(versionPart.slice(1), 10);\n  \n  // Select appropriate key\n  let keyHex: string;\n  if (version === keys.current.version) {\n    keyHex = keys.current.keyHex;\n  } else if (keys.previous \u0026\u0026 version === keys.previous.version) {\n    keyHex = keys.previous.keyHex;\n  } else {\n    throw new CryptoError('KEY_VERSION_NOT_FOUND', `Unknown key version: ${version}`);\n  }\n  \n  const key = await importKey(keyHex);\n  const iv = hexToBytes(ivHex);\n  const ciphertext = hexToBytes(ciphertextHex);\n  \n  try {\n    const decrypted = await crypto.subtle.decrypt(\n      { name: 'AES-GCM', iv },\n      key,\n      ciphertext\n    );\n    return new TextDecoder().decode(decrypted);\n  } catch (e) {\n    throw new CryptoError('DECRYPTION_FAILED', 'Failed to decrypt');\n  }\n}\n```\n\n### Environment Configuration\n```typescript\n// Keys from environment\nfunction getEncryptionKeys(env: Env): EncryptionKeys {\n  return {\n    current: {\n      version: parseInt(env.ENCRYPTION_KEY_VERSION || '1', 10),\n      keyHex: env.ENCRYPTION_KEY,\n    },\n    previous: env.ENCRYPTION_KEY_PREVIOUS ? {\n      version: parseInt(env.ENCRYPTION_KEY_VERSION_PREVIOUS || '0', 10),\n      keyHex: env.ENCRYPTION_KEY_PREVIOUS,\n    } : undefined,\n  };\n}\n```\n\n### Migration Job\nRe-encrypt all tokens with the new key:\n\n```typescript\n// apps/worker/src/jobs/rotate-keys.ts\n\nexport async function migrateEncryptionKeys(\n  env: Env,\n  batchSize = 100\n): Promise\u003cMigrationResult\u003e {\n  const keys = getEncryptionKeys(env);\n  let migrated = 0;\n  let failed = 0;\n  \n  // Process in batches to avoid timeout\n  let cursor: string | null = null;\n  \n  while (true) {\n    const connections = await db.query.providerConnections.findMany({\n      where: cursor ? gt(providerConnections.id, cursor) : undefined,\n      orderBy: [asc(providerConnections.id)],\n      limit: batchSize,\n    });\n    \n    if (connections.length === 0) break;\n    \n    for (const conn of connections) {\n      try {\n        // Check if already on current version\n        if (conn.accessToken.startsWith(`v${keys.current.version}:`)) {\n          continue;\n        }\n        \n        // Decrypt with any available key\n        const accessToken = await decryptWithVersion(conn.accessToken, keys);\n        const refreshToken = await decryptWithVersion(conn.refreshToken, keys);\n        \n        // Re-encrypt with current key\n        const newAccessToken = await encryptWithVersion(accessToken, keys);\n        const newRefreshToken = await encryptWithVersion(refreshToken, keys);\n        \n        await db.update(providerConnections)\n          .set({\n            accessToken: newAccessToken,\n            refreshToken: newRefreshToken,\n          })\n          .where(eq(providerConnections.id, conn.id));\n        \n        migrated++;\n      } catch (e) {\n        console.error(`Failed to migrate ${conn.id}:`, e);\n        failed++;\n      }\n    }\n    \n    cursor = connections[connections.length - 1].id;\n  }\n  \n  return { migrated, failed };\n}\n```\n\n## Rotation Procedure\n1. Generate new key: `openssl rand -hex 32`\n2. Deploy with both keys:\n   - `ENCRYPTION_KEY` = new key\n   - `ENCRYPTION_KEY_VERSION` = 2\n   - `ENCRYPTION_KEY_PREVIOUS` = old key  \n   - `ENCRYPTION_KEY_VERSION_PREVIOUS` = 1\n3. New encryptions use v2\n4. Run migration job to re-encrypt existing tokens\n5. Verify migration: no v1 tokens remain\n6. Remove `ENCRYPTION_KEY_PREVIOUS` after grace period (1 week)\n\n## Error Recovery\n| Scenario | Action |\n|----------|--------|\n| Migration fails mid-way | Re-run (idempotent) |\n| Key leak during rotation | Complete rotation, revoke old key |\n| Decryption fails | Mark connection EXPIRED, user re-auths |\n\n## Files to Modify\n- apps/worker/src/lib/crypto.ts - Versioned encryption\n- apps/worker/src/jobs/rotate-keys.ts - Migration job\n- apps/worker/worker-configuration.d.ts - New env vars\n\n## Dependencies\n- zine-teq.6 (base encryption utilities)\n- zine-teq.1 (provider_connections table)\n\n## Acceptance Criteria\n- [ ] Versioned ciphertext format implemented\n- [ ] Decryption works with current and previous keys\n- [ ] Legacy format handled gracefully\n- [ ] Migration job re-encrypts all tokens\n- [ ] Migration is idempotent\n- [ ] Unknown version throws descriptive error\n- [ ] Integration tests cover rotation scenario","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:16:24.520201-06:00","updated_at":"2025-12-16T22:16:24.520201-06:00","dependencies":[{"issue_id":"zine-teq.24","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:16:24.520598-06:00","created_by":"daemon"},{"issue_id":"zine-teq.24","depends_on_id":"zine-teq.6","type":"blocks","created_at":"2025-12-16T22:20:07.036504-06:00","created_by":"daemon"},{"issue_id":"zine-teq.24","depends_on_id":"zine-teq.1","type":"blocks","created_at":"2025-12-16T22:20:07.086448-06:00","created_by":"daemon"}]}
{"id":"zine-teq.25","title":"Connection Health: Status monitoring and recovery","description":"Implement connection health monitoring with automatic status transitions and user notifications.\n\n## Connection Status Flow\n```\nACTIVE ──(refresh fails)──→ EXPIRED\n   ↑                          │\n   │                          │ (user revoked)\n   │                          ↓\n   └───(user reconnects)─── REVOKED\n```\n\n## Health Monitoring During Polling\n\n### Detect and Handle Auth Errors\n```typescript\n// apps/worker/src/polling/health.ts\n\nexport async function handlePollingAuthError(\n  connection: ProviderConnection,\n  error: Error,\n  env: Env\n): Promise\u003cvoid\u003e {\n  // Classify error\n  if (isTokenExpiredError(error)) {\n    // Try refresh first\n    try {\n      await refreshProviderToken(connection, env);\n      return; // Success, no status change needed\n    } catch (refreshError) {\n      if (isRefreshTokenInvalid(refreshError)) {\n        await markConnectionExpired(connection.id, 'refresh_token_invalid', env);\n      } else {\n        // Transient error, don't change status yet\n        console.warn(`Token refresh failed (transient):`, refreshError);\n      }\n    }\n  } else if (isAccessRevokedError(error)) {\n    await markConnectionRevoked(connection.id, env);\n  }\n}\n\nfunction isTokenExpiredError(error: Error): boolean {\n  const message = error.message.toLowerCase();\n  return message.includes('401') || \n         message.includes('unauthorized') ||\n         message.includes('token expired');\n}\n\nfunction isRefreshTokenInvalid(error: Error): boolean {\n  const message = error.message.toLowerCase();\n  return message.includes('invalid_grant') ||\n         message.includes('refresh token') ||\n         message.includes('revoked');\n}\n\nfunction isAccessRevokedError(error: Error): boolean {\n  const message = error.message.toLowerCase();\n  return message.includes('403') ||\n         message.includes('access revoked') ||\n         message.includes('insufficient permissions');\n}\n```\n\n### Status Transitions\n```typescript\nexport async function markConnectionExpired(\n  connectionId: string,\n  reason: string,\n  env: Env\n): Promise\u003cvoid\u003e {\n  await db.update(providerConnections)\n    .set({ \n      status: 'EXPIRED',\n      updatedAt: Date.now(),\n    })\n    .where(eq(providerConnections.id, connectionId));\n  \n  // Mark related subscriptions as disconnected\n  const conn = await db.query.providerConnections.findFirst({\n    where: eq(providerConnections.id, connectionId),\n    columns: { userId: true, provider: true },\n  });\n  \n  if (conn) {\n    await db.update(subscriptions)\n      .set({ status: 'DISCONNECTED', updatedAt: Date.now() })\n      .where(and(\n        eq(subscriptions.userId, conn.userId),\n        eq(subscriptions.provider, conn.provider),\n        eq(subscriptions.status, 'ACTIVE')\n      ));\n    \n    // Notify user\n    await createUserNotification(conn.userId, {\n      type: 'connection_expired',\n      provider: conn.provider,\n      reason,\n    }, env);\n  }\n}\n\nexport async function markConnectionRevoked(\n  connectionId: string,\n  env: Env\n): Promise\u003cvoid\u003e {\n  await db.update(providerConnections)\n    .set({ status: 'REVOKED', updatedAt: Date.now() })\n    .where(eq(providerConnections.id, connectionId));\n  \n  // Same subscription updates and notification as expired\n  // ...\n}\n```\n\n## User Notifications\n\n### Notification Creation with Deduplication\n```typescript\n// apps/worker/src/notifications/index.ts\n\ninterface NotificationParams {\n  type: 'connection_expired' | 'connection_revoked' | 'poll_failures';\n  provider: Provider;\n  reason?: string;\n}\n\nconst NOTIFICATION_MESSAGES = {\n  connection_expired: (provider: Provider) =\u003e \n    `Your ${provider} connection has expired. Please reconnect to continue receiving updates.`,\n  connection_revoked: (provider: Provider) =\u003e\n    `Your ${provider} access was revoked. Please reconnect to continue receiving updates.`,\n  poll_failures: (provider: Provider) =\u003e\n    `We're having trouble checking for new ${provider} content. This may resolve automatically.`,\n};\n\nexport async function createUserNotification(\n  userId: string,\n  params: NotificationParams,\n  env: Env\n): Promise\u003cvoid\u003e {\n  try {\n    await db.insert(userNotifications).values({\n      id: ulid(),\n      userId,\n      type: params.type,\n      provider: params.provider,\n      title: getNotificationTitle(params.type, params.provider),\n      message: NOTIFICATION_MESSAGES[params.type](params.provider),\n      data: params.reason ? JSON.stringify({ reason: params.reason }) : null,\n      createdAt: Date.now(),\n    }).onConflictDoNothing(); // Deduplication via unique constraint\n  } catch (e) {\n    // Log but don't fail the parent operation\n    console.error('Failed to create notification:', e);\n  }\n}\n```\n\n### Auto-Resolution\nWhen user reconnects, clear related notifications:\n\n```typescript\n// In OAuth callback, after successful reconnection\nexport async function resolveConnectionNotifications(\n  userId: string,\n  provider: Provider,\n  db: DrizzleDB\n): Promise\u003cvoid\u003e {\n  await db.update(userNotifications)\n    .set({ resolvedAt: Date.now() })\n    .where(and(\n      eq(userNotifications.userId, userId),\n      eq(userNotifications.provider, provider),\n      isNull(userNotifications.resolvedAt),\n      inArray(userNotifications.type, ['connection_expired', 'connection_revoked'])\n    ));\n}\n```\n\n## Poll Failure Tracking\nNotify after 3+ consecutive failures:\n\n```typescript\nconst FAILURE_THRESHOLD = 3;\n\nexport async function trackPollFailure(\n  subscriptionId: string,\n  error: Error,\n  env: Env\n): Promise\u003cvoid\u003e {\n  const key = `poll:failures:${subscriptionId}`;\n  const current = parseInt(await env.KV.get(key) || '0', 10);\n  const newCount = current + 1;\n  \n  await env.KV.put(key, String(newCount), { expirationTtl: 24 * 3600 }); // Reset after 24h\n  \n  if (newCount === FAILURE_THRESHOLD) {\n    const sub = await db.query.subscriptions.findFirst({\n      where: eq(subscriptions.id, subscriptionId),\n      columns: { userId: true, provider: true, name: true },\n    });\n    \n    if (sub) {\n      await createUserNotification(sub.userId, {\n        type: 'poll_failures',\n        provider: sub.provider,\n      }, env);\n    }\n  }\n}\n\nexport async function clearPollFailures(\n  subscriptionId: string,\n  env: Env\n): Promise\u003cvoid\u003e {\n  await env.KV.delete(`poll:failures:${subscriptionId}`);\n}\n```\n\n## Files to Create/Modify\n- apps/worker/src/polling/health.ts - Health monitoring\n- apps/worker/src/notifications/index.ts - Notification creation\n- apps/worker/src/trpc/routers/connections.ts - Clear notifications on reconnect\n\n## Dependencies\n- zine-teq.9 (token refresh)\n- zine-teq.19 (polling cron integration)\n- zine-teq.29 (user_notifications table)\n\n## Acceptance Criteria\n- [ ] Auth errors correctly classified\n- [ ] Expired connections trigger status change\n- [ ] Related subscriptions marked DISCONNECTED\n- [ ] User notifications created with deduplication\n- [ ] Notifications auto-resolve on reconnection\n- [ ] Poll failures tracked and notified after threshold\n- [ ] Integration tests cover status transitions","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:16:55.641081-06:00","updated_at":"2025-12-16T22:24:21.215868-06:00","dependencies":[{"issue_id":"zine-teq.25","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:16:55.641482-06:00","created_by":"daemon"},{"issue_id":"zine-teq.25","depends_on_id":"zine-teq.9","type":"blocks","created_at":"2025-12-16T22:20:14.170323-06:00","created_by":"daemon"},{"issue_id":"zine-teq.25","depends_on_id":"zine-teq.19","type":"blocks","created_at":"2025-12-16T22:20:14.21961-06:00","created_by":"daemon"}]}
{"id":"zine-teq.26","title":"Wrangler Configuration: Cron triggers and secrets","description":"Configure wrangler.toml with all required cron triggers, KV namespaces, secrets, and environment variables.\n\n## Cron Triggers\n```toml\n# wrangler.toml\n\n[triggers]\ncrons = [\n  \"*/15 * * * *\",   # Poll subscriptions every 15 minutes\n  \"0 4 * * *\",      # Renew YouTube push leases daily at 4 AM\n  \"0 */6 * * *\",    # YouTube fallback polling every 6 hours (for push failures)\n  \"0 3 * * 0\"       # Cleanup job Sundays at 3 AM UTC\n]\n```\n\n## KV Namespaces\n```toml\n[[kv_namespaces]]\nbinding = \"KV\"\nid = \"\u003ccreate-with-wrangler\u003e\"\npreview_id = \"\u003ccreate-for-preview\u003e\"\n```\n\nUsed for:\n- OAuth state storage (`oauth:state:{state}`)\n- Distributed locks (`cron:poll-subscriptions:lock`)\n- Token refresh locks (`token:refresh:{connectionId}`)\n- Rate limit state (`rate:{provider}:{userId}`)\n- YouTube quota tracking (`youtube:quota:{date}`)\n- Poll failure counts (`poll:failures:{subscriptionId}`)\n- Manual sync rate limiting (`manual-sync:{subscriptionId}`)\n\n## Queue Configuration (Optional for webhooks)\n```toml\n[[queues.producers]]\nqueue = \"youtube-notifications\"\nbinding = \"YOUTUBE_QUEUE\"\n\n[[queues.consumers]]\nqueue = \"youtube-notifications\"\nmax_batch_size = 10\nmax_retries = 3\n```\n\n## Environment Variables\n```toml\n[vars]\n# Base URL for callbacks\nBASE_URL = \"https://api.zine.app\"\n\n# OAuth redirect URIs\nYOUTUBE_REDIRECT_URI = \"zine://auth/youtube/callback\"\nSPOTIFY_REDIRECT_URI = \"zine://auth/spotify/callback\"\n\n# Polling configuration\nPOLL_BATCH_SIZE = \"50\"\nPOLL_LOCK_TTL_SECONDS = \"900\"\n\n# Feature flags\nENABLE_YOUTUBE_PUSH = \"false\"  # Enable when ready\n```\n\n## Secrets (via wrangler secret put)\nRequired secrets:\n```bash\n# OAuth credentials\nwrangler secret put YOUTUBE_CLIENT_ID\nwrangler secret put YOUTUBE_CLIENT_SECRET\nwrangler secret put SPOTIFY_CLIENT_ID\nwrangler secret put SPOTIFY_CLIENT_SECRET\n\n# Encryption\nwrangler secret put ENCRYPTION_KEY           # 64 hex chars (256 bits)\nwrangler secret put ENCRYPTION_KEY_VERSION   # e.g., \"1\"\n\n# For key rotation (optional, add when rotating)\nwrangler secret put ENCRYPTION_KEY_PREVIOUS\nwrangler secret put ENCRYPTION_KEY_VERSION_PREVIOUS\n```\n\n## TypeScript Environment Types\n```typescript\n// apps/worker/worker-configuration.d.ts\n\ninterface Env {\n  // Database\n  DB: D1Database;\n  \n  // KV Namespace\n  KV: KVNamespace;\n  \n  // Queues (optional)\n  YOUTUBE_QUEUE?: Queue;\n  \n  // Environment variables\n  BASE_URL: string;\n  YOUTUBE_REDIRECT_URI: string;\n  SPOTIFY_REDIRECT_URI: string;\n  POLL_BATCH_SIZE: string;\n  POLL_LOCK_TTL_SECONDS: string;\n  ENABLE_YOUTUBE_PUSH: string;\n  \n  // Secrets\n  YOUTUBE_CLIENT_ID: string;\n  YOUTUBE_CLIENT_SECRET: string;\n  SPOTIFY_CLIENT_ID: string;\n  SPOTIFY_CLIENT_SECRET: string;\n  ENCRYPTION_KEY: string;\n  ENCRYPTION_KEY_VERSION: string;\n  ENCRYPTION_KEY_PREVIOUS?: string;\n  ENCRYPTION_KEY_VERSION_PREVIOUS?: string;\n}\n```\n\n## Scheduled Handler\n```typescript\n// apps/worker/src/index.ts\n\nexport default {\n  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise\u003cResponse\u003e {\n    // ... existing fetch handler ...\n  },\n  \n  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext): Promise\u003cvoid\u003e {\n    switch (event.cron) {\n      case '*/15 * * * *':\n        await pollSubscriptions(env, ctx);\n        break;\n      case '0 4 * * *':\n        await renewPushLeases(env, ctx);\n        break;\n      case '0 */6 * * *':\n        await fallbackYouTubePolling(env, ctx);\n        break;\n      case '0 3 * * 0':\n        await cleanupJob(env, ctx);\n        break;\n    }\n  },\n  \n  async queue(batch: MessageBatch, env: Env): Promise\u003cvoid\u003e {\n    // Handle YouTube push notification queue\n    for (const message of batch.messages) {\n      await processYouTubeNotification(message.body, env);\n      message.ack();\n    }\n  },\n};\n```\n\n## Cleanup Job\n```typescript\n// apps/worker/src/jobs/cleanup.ts\n\nexport async function cleanupJob(env: Env, ctx: ExecutionContext): Promise\u003cvoid\u003e {\n  // 1. Clean up old provider_items_seen (optional, for storage management)\n  // Keep for re-subscribe prevention, but could archive very old records\n  \n  // 2. Clean up orphaned subscription_items\n  await db.delete(subscriptionItems)\n    .where(notExists(\n      db.select()\n        .from(subscriptions)\n        .where(eq(subscriptions.id, subscriptionItems.subscriptionId))\n    ));\n  \n  // 3. Expire old notifications\n  const thirtyDaysAgo = Date.now() - 30 * 24 * 3600 * 1000;\n  await db.delete(userNotifications)\n    .where(lt(userNotifications.createdAt, thirtyDaysAgo));\n}\n```\n\n## Files to Modify\n- apps/worker/wrangler.toml - Full configuration\n- apps/worker/worker-configuration.d.ts - TypeScript types\n- apps/worker/src/index.ts - Add scheduled handler\n\n## KV Namespace Creation Commands\n```bash\n# Create production namespace\nwrangler kv:namespace create \"KV\"\n\n# Create preview namespace\nwrangler kv:namespace create \"KV\" --preview\n```\n\n## Dependencies\nNone - this is foundational configuration\n\n## Acceptance Criteria\n- [ ] All cron triggers configured\n- [ ] KV namespace created and bound\n- [ ] All secrets documented and added\n- [ ] TypeScript Env type complete\n- [ ] Scheduled handler routes to correct functions\n- [ ] Preview environment works locally\n- [ ] Production deployment succeeds","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:17:23.603563-06:00","updated_at":"2025-12-16T22:17:23.603563-06:00","dependencies":[{"issue_id":"zine-teq.26","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:17:23.603939-06:00","created_by":"daemon"}]}
{"id":"zine-teq.27","title":"Testing: Unit tests for crypto, transformers, and ingestion","description":"Write comprehensive unit tests for the core utility modules.\n\n## Test Structure\n```\napps/worker/src/\n├── lib/\n│   ├── crypto.test.ts\n│   ├── rate-limiter.test.ts\n│   └── locks.test.ts\n├── ingestion/\n│   ├── transformers.test.ts\n│   └── processor.test.ts\n├── providers/\n│   ├── youtube.test.ts\n│   └── spotify.test.ts\n└── polling/\n    └── adaptive.test.ts\n```\n\n## Crypto Tests\n```typescript\n// apps/worker/src/lib/crypto.test.ts\nimport { describe, it, expect } from 'vitest';\nimport { encrypt, decrypt, encryptWithVersion, decryptWithVersion, CryptoError } from './crypto';\n\ndescribe('crypto', () =\u003e {\n  const validKey = 'a'.repeat(64); // 256-bit key in hex\n  const invalidKey = 'short';\n  \n  describe('encrypt/decrypt', () =\u003e {\n    it('should round-trip encrypt and decrypt', async () =\u003e {\n      const plaintext = 'my secret token';\n      const encrypted = await encrypt(plaintext, validKey);\n      const decrypted = await decrypt(encrypted, validKey);\n      expect(decrypted).toBe(plaintext);\n    });\n    \n    it('should produce different ciphertext each time (random IV)', async () =\u003e {\n      const plaintext = 'test';\n      const e1 = await encrypt(plaintext, validKey);\n      const e2 = await encrypt(plaintext, validKey);\n      expect(e1).not.toBe(e2);\n    });\n    \n    it('should throw on invalid key length', async () =\u003e {\n      await expect(encrypt('test', invalidKey))\n        .rejects.toThrow(CryptoError);\n    });\n    \n    it('should throw on wrong decryption key', async () =\u003e {\n      const encrypted = await encrypt('test', validKey);\n      const wrongKey = 'b'.repeat(64);\n      await expect(decrypt(encrypted, wrongKey))\n        .rejects.toThrow('DECRYPTION_FAILED');\n    });\n    \n    it('should throw on tampered ciphertext', async () =\u003e {\n      const encrypted = await encrypt('test', validKey);\n      const tampered = encrypted.slice(0, -2) + 'xx';\n      await expect(decrypt(tampered, validKey))\n        .rejects.toThrow('DECRYPTION_FAILED');\n    });\n  });\n  \n  describe('versioned encryption', () =\u003e {\n    const keys = {\n      current: { version: 2, keyHex: validKey },\n      previous: { version: 1, keyHex: 'b'.repeat(64) },\n    };\n    \n    it('should encrypt with version prefix', async () =\u003e {\n      const encrypted = await encryptWithVersion('test', keys);\n      expect(encrypted).toMatch(/^v2:/);\n    });\n    \n    it('should decrypt current version', async () =\u003e {\n      const encrypted = await encryptWithVersion('test', keys);\n      const decrypted = await decryptWithVersion(encrypted, keys);\n      expect(decrypted).toBe('test');\n    });\n    \n    it('should decrypt previous version', async () =\u003e {\n      const oldKeys = { current: keys.previous! };\n      const encrypted = await encryptWithVersion('test', oldKeys);\n      const decrypted = await decryptWithVersion(encrypted, keys);\n      expect(decrypted).toBe('test');\n    });\n    \n    it('should throw on unknown version', async () =\u003e {\n      const encrypted = 'v99:abc:def';\n      await expect(decryptWithVersion(encrypted, keys))\n        .rejects.toThrow('KEY_VERSION_NOT_FOUND');\n    });\n  });\n});\n```\n\n## Transformer Tests\n```typescript\n// apps/worker/src/ingestion/transformers.test.ts\nimport { describe, it, expect } from 'vitest';\nimport { \n  transformYouTubeVideo, \n  transformSpotifyEpisode,\n  TransformError \n} from './transformers';\n\ndescribe('transformers', () =\u003e {\n  describe('transformYouTubeVideo', () =\u003e {\n    const validVideo = {\n      contentDetails: { videoId: 'abc123' },\n      snippet: {\n        title: 'Test Video',\n        channelTitle: 'Test Channel',\n        channelId: 'UCabc123',\n        publishedAt: '2024-01-15T10:00:00Z',\n        thumbnails: { high: { url: 'https://example.com/thumb.jpg' } },\n      },\n    };\n    \n    it('should transform valid video', () =\u003e {\n      const item = transformYouTubeVideo(validVideo);\n      expect(item.providerId).toBe('abc123');\n      expect(item.title).toBe('Test Video');\n      expect(item.creator).toBe('Test Channel');\n      expect(item.contentType).toBe('VIDEO');\n      expect(item.provider).toBe('YOUTUBE');\n      expect(item.canonicalUrl).toBe('https://www.youtube.com/watch?v=abc123');\n    });\n    \n    it('should throw on missing videoId', () =\u003e {\n      expect(() =\u003e transformYouTubeVideo({ contentDetails: {} }))\n        .toThrow(TransformError);\n    });\n    \n    it('should handle missing optional fields', () =\u003e {\n      const minimal = { contentDetails: { videoId: 'xyz' } };\n      const item = transformYouTubeVideo(minimal);\n      expect(item.title).toBe('Untitled');\n      expect(item.creator).toBe('Unknown');\n    });\n  });\n  \n  describe('transformSpotifyEpisode', () =\u003e {\n    const validEpisode = {\n      id: 'spotify123',\n      name: 'Episode 1',\n      description: 'Description',\n      release_date: '2024-01-15',\n      duration_ms: 3600000,\n      external_urls: { spotify: 'https://spotify.com/episode/123' },\n      images: [{ url: 'https://example.com/art.jpg' }],\n    };\n    \n    it('should transform valid episode', () =\u003e {\n      const item = transformSpotifyEpisode(validEpisode, 'Test Show');\n      expect(item.providerId).toBe('spotify123');\n      expect(item.title).toBe('Episode 1');\n      expect(item.creator).toBe('Test Show');\n      expect(item.durationSeconds).toBe(3600);\n      expect(item.contentType).toBe('PODCAST');\n    });\n    \n    it('should parse YYYY-MM-DD date', () =\u003e {\n      const item = transformSpotifyEpisode(validEpisode, 'Show');\n      expect(item.publishedAt).toBe(new Date('2024-01-15T00:00:00Z').getTime());\n    });\n    \n    it('should parse YYYY-MM date', () =\u003e {\n      const episode = { ...validEpisode, release_date: '2024-01' };\n      const item = transformSpotifyEpisode(episode, 'Show');\n      expect(item.publishedAt).toBe(new Date('2024-01-01T00:00:00Z').getTime());\n    });\n    \n    it('should parse YYYY date', () =\u003e {\n      const episode = { ...validEpisode, release_date: '2024' };\n      const item = transformSpotifyEpisode(episode, 'Show');\n      expect(item.publishedAt).toBe(new Date('2024-01-01T00:00:00Z').getTime());\n    });\n  });\n});\n```\n\n## Adaptive Polling Tests\n```typescript\n// apps/worker/src/polling/adaptive.test.ts\nimport { describe, it, expect } from 'vitest';\nimport { calculateOptimalInterval } from './adaptive';\n\ndescribe('adaptive polling', () =\u003e {\n  it('should return 1 hour for very active channels', () =\u003e {\n    const interval = calculateOptimalInterval({\n      itemsLast7Days: 10,\n      itemsLast30Days: 30,\n      daysSinceLastItem: 0,\n    });\n    expect(interval).toBe(3600);\n  });\n  \n  it('should return 4 hours for active channels', () =\u003e {\n    const interval = calculateOptimalInterval({\n      itemsLast7Days: 3,\n      itemsLast30Days: 10,\n      daysSinceLastItem: 2,\n    });\n    expect(interval).toBe(4 * 3600);\n  });\n  \n  it('should return 12 hours for moderate channels', () =\u003e {\n    const interval = calculateOptimalInterval({\n      itemsLast7Days: 0,\n      itemsLast30Days: 2,\n      daysSinceLastItem: 10,\n    });\n    expect(interval).toBe(12 * 3600);\n  });\n  \n  it('should return 24 hours for inactive channels', () =\u003e {\n    const interval = calculateOptimalInterval({\n      itemsLast7Days: 0,\n      itemsLast30Days: 0,\n      daysSinceLastItem: 45,\n    });\n    expect(interval).toBe(24 * 3600);\n  });\n});\n```\n\n## Rate Limiter Tests\n```typescript\n// apps/worker/src/lib/rate-limiter.test.ts\nimport { describe, it, expect, vi } from 'vitest';\nimport { RateLimitedFetcher, RateLimitError } from './rate-limiter';\n\ndescribe('rate limiter', () =\u003e {\n  const mockKV = {\n    get: vi.fn(),\n    put: vi.fn(),\n    delete: vi.fn(),\n  };\n  \n  it('should allow requests when not rate limited', async () =\u003e {\n    mockKV.get.mockResolvedValue(null);\n    const fetcher = new RateLimitedFetcher(mockKV as any);\n    \n    const response = new Response('OK', { status: 200 });\n    const result = await fetcher.fetch('YOUTUBE', 'user1', async () =\u003e response);\n    \n    expect(result.status).toBe(200);\n  });\n  \n  it('should block requests when rate limited', async () =\u003e {\n    mockKV.get.mockResolvedValue(JSON.stringify({\n      retryAfter: Date.now() + 10000,\n      consecutiveFailures: 1,\n    }));\n    \n    const fetcher = new RateLimitedFetcher(mockKV as any);\n    \n    await expect(fetcher.fetch('SPOTIFY', 'user1', async () =\u003e new Response()))\n      .rejects.toThrow(RateLimitError);\n  });\n  \n  it('should parse Retry-After header', async () =\u003e {\n    mockKV.get.mockResolvedValue(null);\n    const fetcher = new RateLimitedFetcher(mockKV as any);\n    \n    const response = new Response('', { \n      status: 429,\n      headers: { 'Retry-After': '60' },\n    });\n    \n    await expect(fetcher.fetch('SPOTIFY', 'user1', async () =\u003e response))\n      .rejects.toThrow(RateLimitError);\n    \n    expect(mockKV.put).toHaveBeenCalledWith(\n      expect.any(String),\n      expect.stringContaining('retryAfter'),\n      expect.any(Object)\n    );\n  });\n});\n```\n\n## Running Tests\n```bash\n# Run all tests\ncd apps/worker \u0026\u0026 npm test\n\n# Run specific test file\nnpm test -- crypto.test.ts\n\n# Run with coverage\nnpm test -- --coverage\n```\n\n## Files to Create\n- apps/worker/src/lib/crypto.test.ts\n- apps/worker/src/lib/rate-limiter.test.ts\n- apps/worker/src/lib/locks.test.ts\n- apps/worker/src/ingestion/transformers.test.ts\n- apps/worker/src/ingestion/processor.test.ts\n- apps/worker/src/polling/adaptive.test.ts\n\n## Dependencies\n- zine-teq.6 (crypto utilities)\n- zine-teq.16 (transformers)\n- zine-teq.17 (ingestion processor)\n- zine-teq.20 (adaptive polling)\n- zine-teq.22 (rate limiter)\n\n## Acceptance Criteria\n- [ ] All crypto functions have test coverage\n- [ ] Transformer edge cases covered\n- [ ] Adaptive polling tiers verified\n- [ ] Rate limiter backoff tested\n- [ ] Tests run in CI\n- [ ] Coverage \u003e 80% for tested modules","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:18:01.713885-06:00","updated_at":"2025-12-16T22:18:01.713885-06:00","dependencies":[{"issue_id":"zine-teq.27","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:18:01.714297-06:00","created_by":"daemon"},{"issue_id":"zine-teq.27","depends_on_id":"zine-teq.6","type":"blocks","created_at":"2025-12-16T22:20:18.786678-06:00","created_by":"daemon"},{"issue_id":"zine-teq.27","depends_on_id":"zine-teq.16","type":"blocks","created_at":"2025-12-16T22:20:18.834486-06:00","created_by":"daemon"},{"issue_id":"zine-teq.27","depends_on_id":"zine-teq.17","type":"blocks","created_at":"2025-12-16T22:20:18.881567-06:00","created_by":"daemon"},{"issue_id":"zine-teq.27","depends_on_id":"zine-teq.20","type":"blocks","created_at":"2025-12-16T22:20:18.92801-06:00","created_by":"daemon"},{"issue_id":"zine-teq.27","depends_on_id":"zine-teq.22","type":"blocks","created_at":"2025-12-16T22:20:18.973872-06:00","created_by":"daemon"}]}
{"id":"zine-teq.28","title":"Integration Tests: OAuth flow and subscription lifecycle","description":"Write integration tests for the complete OAuth flow and subscription management.\n\n## Test Scope\nIntegration tests verify the full flow across multiple components, including:\n- OAuth state registration → callback → token storage\n- Subscription creation → initial fetch → ingestion\n- Polling flow → new item detection → inbox delivery\n- Connection expiry → subscription disconnection → notification\n\n## OAuth Flow Tests\n```typescript\n// apps/worker/src/trpc/routers/connections.test.ts\nimport { describe, it, expect, beforeEach } from 'vitest';\nimport { createTestContext, mockYouTubeTokenExchange } from '../test-utils';\n\ndescribe('connections router', () =\u003e {\n  describe('OAuth flow', () =\u003e {\n    it('should complete full OAuth flow', async () =\u003e {\n      const ctx = await createTestContext();\n      \n      // 1. Register state\n      const state = 'random-state-123';\n      await ctx.caller.connections.registerState({\n        provider: 'YOUTUBE',\n        state,\n      });\n      \n      // Verify state stored in KV\n      expect(await ctx.env.KV.get(`oauth:state:${state}`)).toBe(ctx.userId);\n      \n      // 2. Mock provider token exchange\n      mockYouTubeTokenExchange({\n        access_token: 'access-123',\n        refresh_token: 'refresh-123',\n        expires_in: 3600,\n      });\n      \n      // 3. Complete callback\n      const result = await ctx.caller.connections.callback({\n        provider: 'YOUTUBE',\n        code: 'auth-code',\n        state,\n        codeVerifier: 'a'.repeat(43),\n      });\n      \n      expect(result.success).toBe(true);\n      \n      // 4. Verify connection stored\n      const connections = await ctx.caller.connections.list();\n      expect(connections.YOUTUBE).toBeDefined();\n      expect(connections.YOUTUBE?.status).toBe('ACTIVE');\n      \n      // 5. Verify state deleted\n      expect(await ctx.env.KV.get(`oauth:state:${state}`)).toBeNull();\n    });\n    \n    it('should reject invalid state', async () =\u003e {\n      const ctx = await createTestContext();\n      \n      await expect(ctx.caller.connections.callback({\n        provider: 'YOUTUBE',\n        code: 'auth-code',\n        state: 'invalid-state',\n        codeVerifier: 'a'.repeat(43),\n      })).rejects.toThrow('Invalid state');\n    });\n    \n    it('should update existing connection on reconnect', async () =\u003e {\n      const ctx = await createTestContext();\n      await createExistingConnection(ctx, 'YOUTUBE');\n      \n      // Reconnect flow\n      const state = 'new-state';\n      await ctx.caller.connections.registerState({ provider: 'YOUTUBE', state });\n      mockYouTubeTokenExchange({ access_token: 'new-token' });\n      \n      await ctx.caller.connections.callback({\n        provider: 'YOUTUBE',\n        code: 'new-code',\n        state,\n        codeVerifier: 'a'.repeat(43),\n      });\n      \n      // Should still be one connection, not two\n      const connections = await ctx.db.query.providerConnections.findMany({\n        where: eq(providerConnections.userId, ctx.userId),\n      });\n      expect(connections.length).toBe(1);\n    });\n  });\n  \n  describe('disconnect', () =\u003e {\n    it('should disconnect and mark subscriptions disconnected', async () =\u003e {\n      const ctx = await createTestContext();\n      await createExistingConnection(ctx, 'YOUTUBE');\n      await createSubscription(ctx, 'YOUTUBE', 'UCabc123');\n      \n      await ctx.caller.connections.disconnect({ provider: 'YOUTUBE' });\n      \n      // Connection should be deleted\n      const connections = await ctx.caller.connections.list();\n      expect(connections.YOUTUBE).toBeNull();\n      \n      // Subscription should be DISCONNECTED\n      const subs = await ctx.caller.subscriptions.list({});\n      expect(subs.items[0].status).toBe('DISCONNECTED');\n    });\n  });\n});\n```\n\n## Subscription Lifecycle Tests\n```typescript\n// apps/worker/src/trpc/routers/subscriptions.test.ts\nimport { describe, it, expect } from 'vitest';\nimport { createTestContext, mockYouTubeAPI } from '../test-utils';\n\ndescribe('subscriptions router', () =\u003e {\n  describe('add', () =\u003e {\n    it('should create subscription and fetch initial item', async () =\u003e {\n      const ctx = await createTestContext();\n      await createExistingConnection(ctx, 'YOUTUBE');\n      \n      // Mock YouTube API responses\n      mockYouTubeAPI.channels({ uploadsPlaylistId: 'UUabc123' });\n      mockYouTubeAPI.playlistItems([\n        { videoId: 'video1', title: 'Latest Video', publishedAt: '2024-01-15T10:00:00Z' },\n      ]);\n      \n      const result = await ctx.caller.subscriptions.add({\n        provider: 'YOUTUBE',\n        providerChannelId: 'UCabc123456789012345678',\n      });\n      \n      expect(result.subscriptionId).toBeDefined();\n      \n      // Verify initial item ingested\n      const inbox = await ctx.caller.items.list({ state: 'INBOX' });\n      expect(inbox.items.length).toBe(1);\n      expect(inbox.items[0].title).toBe('Latest Video');\n    });\n    \n    it('should require active connection', async () =\u003e {\n      const ctx = await createTestContext();\n      // No connection created\n      \n      await expect(ctx.caller.subscriptions.add({\n        provider: 'YOUTUBE',\n        providerChannelId: 'UCabc123456789012345678',\n      })).rejects.toThrow('not connected');\n    });\n    \n    it('should validate channel ID format', async () =\u003e {\n      const ctx = await createTestContext();\n      await createExistingConnection(ctx, 'YOUTUBE');\n      \n      await expect(ctx.caller.subscriptions.add({\n        provider: 'YOUTUBE',\n        providerChannelId: 'invalid-id',\n      })).rejects.toThrow('Invalid YouTube channel ID');\n    });\n  });\n  \n  describe('remove', () =\u003e {\n    it('should soft delete and clean up inbox items', async () =\u003e {\n      const ctx = await createTestContext();\n      const { subscriptionId, itemId } = await setupSubscriptionWithItem(ctx);\n      \n      await ctx.caller.subscriptions.remove({ subscriptionId });\n      \n      // Subscription should be UNSUBSCRIBED\n      const subs = await ctx.caller.subscriptions.list({});\n      expect(subs.items.find(s =\u003e s.id === subscriptionId)?.status).toBe('UNSUBSCRIBED');\n      \n      // INBOX item should be deleted\n      const inbox = await ctx.caller.items.list({ state: 'INBOX' });\n      expect(inbox.items.find(i =\u003e i.id === itemId)).toBeUndefined();\n      \n      // provider_items_seen should remain (for re-subscribe protection)\n      const seen = await ctx.db.query.providerItemsSeen.findMany({\n        where: eq(providerItemsSeen.userId, ctx.userId),\n      });\n      expect(seen.length).toBeGreaterThan(0);\n    });\n    \n    it('should preserve saved items', async () =\u003e {\n      const ctx = await createTestContext();\n      const { subscriptionId, itemId } = await setupSubscriptionWithItem(ctx);\n      \n      // Save the item\n      await ctx.caller.items.save({ itemId });\n      \n      await ctx.caller.subscriptions.remove({ subscriptionId });\n      \n      // SAVED item should remain\n      const saved = await ctx.caller.items.list({ state: 'SAVED' });\n      expect(saved.items.find(i =\u003e i.id === itemId)).toBeDefined();\n    });\n  });\n  \n  describe('pause/resume', () =\u003e {\n    it('should pause and resume subscription', async () =\u003e {\n      const ctx = await createTestContext();\n      await createExistingConnection(ctx, 'YOUTUBE');\n      const sub = await createSubscription(ctx, 'YOUTUBE', 'UCabc123');\n      \n      // Pause\n      await ctx.caller.subscriptions.pause({ subscriptionId: sub.id });\n      let subs = await ctx.caller.subscriptions.list({});\n      expect(subs.items[0].status).toBe('PAUSED');\n      \n      // Resume\n      await ctx.caller.subscriptions.resume({ subscriptionId: sub.id });\n      subs = await ctx.caller.subscriptions.list({});\n      expect(subs.items[0].status).toBe('ACTIVE');\n    });\n  });\n});\n```\n\n## Polling Integration Tests\n```typescript\n// apps/worker/src/polling/scheduler.test.ts\nimport { describe, it, expect, vi } from 'vitest';\nimport { pollSubscriptions } from './scheduler';\n\ndescribe('polling scheduler', () =\u003e {\n  it('should poll due subscriptions and ingest new items', async () =\u003e {\n    const ctx = await createTestContext();\n    await createExistingConnection(ctx, 'YOUTUBE');\n    const sub = await createSubscription(ctx, 'YOUTUBE', 'UCabc123');\n    \n    // Set lastPolledAt to past\n    await ctx.db.update(subscriptions)\n      .set({ lastPolledAt: Date.now() - 2 * 3600 * 1000 })\n      .where(eq(subscriptions.id, sub.id));\n    \n    // Mock new videos since last poll\n    mockYouTubeAPI.playlistItems([\n      { videoId: 'new1', title: 'New Video', publishedAt: new Date().toISOString() },\n    ]);\n    \n    const result = await pollSubscriptions(ctx.env, {} as ExecutionContext);\n    \n    expect(result.processed).toBe(1);\n    expect(result.newItems).toBe(1);\n    \n    // Verify item in inbox\n    const inbox = await ctx.caller.items.list({ state: 'INBOX' });\n    expect(inbox.items.some(i =\u003e i.title === 'New Video')).toBe(true);\n  });\n  \n  it('should respect distributed lock', async () =\u003e {\n    const ctx = await createTestContext();\n    \n    // Simulate lock held by another worker\n    await ctx.env.KV.put('cron:poll-subscriptions:lock', Date.now().toString());\n    \n    const result = await pollSubscriptions(ctx.env, {} as ExecutionContext);\n    \n    expect(result.skipped).toBe(true);\n    expect(result.reason).toBe('lock_held');\n  });\n  \n  it('should handle auth errors and mark connections expired', async () =\u003e {\n    const ctx = await createTestContext();\n    await createExistingConnection(ctx, 'YOUTUBE');\n    const sub = await createSubscription(ctx, 'YOUTUBE', 'UCabc123');\n    \n    // Mock 401 response\n    mockYouTubeAPI.error(401, 'unauthorized');\n    \n    await pollSubscriptions(ctx.env, {} as ExecutionContext);\n    \n    // Connection should be EXPIRED\n    const connections = await ctx.caller.connections.list();\n    expect(connections.YOUTUBE?.status).toBe('EXPIRED');\n    \n    // Subscription should be DISCONNECTED\n    const subs = await ctx.caller.subscriptions.list({});\n    expect(subs.items[0].status).toBe('DISCONNECTED');\n  });\n});\n```\n\n## Test Utilities\n```typescript\n// apps/worker/src/test-utils.ts\n\nexport async function createTestContext() {\n  const db = await createTestDatabase();\n  const kv = createMockKV();\n  const userId = ulid();\n  \n  // ... setup test context\n}\n\nexport const mockYouTubeAPI = {\n  channels: (data: any) =\u003e { /* mock implementation */ },\n  playlistItems: (items: any[]) =\u003e { /* mock implementation */ },\n  error: (status: number, message: string) =\u003e { /* mock implementation */ },\n};\n```\n\n## Files to Create\n- apps/worker/src/trpc/routers/connections.test.ts\n- apps/worker/src/trpc/routers/subscriptions.test.ts\n- apps/worker/src/polling/scheduler.test.ts\n- apps/worker/src/test-utils.ts\n\n## Dependencies\n- zine-teq.27 (unit tests - shared utilities)\n- zine-teq.12 (connections router)\n- zine-teq.13 (subscriptions router)\n- zine-teq.19 (polling scheduler)\n\n## Acceptance Criteria\n- [ ] OAuth flow tested end-to-end\n- [ ] Subscription lifecycle tested\n- [ ] Polling integration verified\n- [ ] Error scenarios covered\n- [ ] Test utilities reusable\n- [ ] Tests pass in CI","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:18:42.049908-06:00","updated_at":"2025-12-16T22:18:42.049908-06:00","dependencies":[{"issue_id":"zine-teq.28","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:18:42.050314-06:00","created_by":"daemon"},{"issue_id":"zine-teq.28","depends_on_id":"zine-teq.27","type":"blocks","created_at":"2025-12-16T22:20:23.717865-06:00","created_by":"daemon"},{"issue_id":"zine-teq.28","depends_on_id":"zine-teq.12","type":"blocks","created_at":"2025-12-16T22:20:23.769029-06:00","created_by":"daemon"},{"issue_id":"zine-teq.28","depends_on_id":"zine-teq.13","type":"blocks","created_at":"2025-12-16T22:20:23.81562-06:00","created_by":"daemon"},{"issue_id":"zine-teq.28","depends_on_id":"zine-teq.19","type":"blocks","created_at":"2025-12-16T22:20:23.861721-06:00","created_by":"daemon"}]}
{"id":"zine-teq.29","title":"Database Schema: user_notifications table","description":"Create the user_notifications table for connection health alerts and system messages.\n\n## Table Definition\n```sql\nCREATE TABLE user_notifications (\n  id TEXT PRIMARY KEY,           -- ULID\n  user_id TEXT NOT NULL,\n  type TEXT NOT NULL,            -- connection_expired, poll_failures, etc.\n  provider TEXT,                 -- YOUTUBE, SPOTIFY (null for system-wide)\n  title TEXT NOT NULL,           -- Short title\n  message TEXT NOT NULL,         -- Full message body\n  data TEXT,                     -- JSON with additional details\n  read_at INTEGER,               -- Unix timestamp ms when read\n  resolved_at INTEGER,           -- Unix timestamp ms when auto-resolved\n  created_at INTEGER NOT NULL DEFAULT (unixepoch() * 1000),\n  \n  -- Deduplication: one active notification per type/provider combo\n  UNIQUE(user_id, type, provider) WHERE resolved_at IS NULL\n);\n\n-- Index for efficient inbox queries\nCREATE INDEX idx_user_notifications_inbox \n  ON user_notifications(user_id, resolved_at, created_at DESC);\n```\n\n## Notification Types\n| Type | Provider | Trigger | Auto-resolves |\n|------|----------|---------|---------------|\n| `connection_expired` | YOUTUBE/SPOTIFY | OAuth token refresh fails | On reconnect |\n| `connection_revoked` | YOUTUBE/SPOTIFY | Provider returns 403 | On reconnect |\n| `poll_failures` | YOUTUBE/SPOTIFY | 3+ consecutive poll failures | On successful poll |\n| `quota_warning` | YOUTUBE | Quota \u003e 80% | Next day (quota reset) |\n\n## Drizzle Schema\n```typescript\nexport const userNotifications = sqliteTable('user_notifications', {\n  id: text('id').primaryKey(),\n  userId: text('user_id').notNull().references(() =\u003e users.id),\n  type: text('type').notNull(),\n  provider: text('provider'),\n  title: text('title').notNull(),\n  message: text('message').notNull(),\n  data: text('data'), // JSON\n  readAt: integer('read_at'),\n  resolvedAt: integer('resolved_at'),\n  createdAt: integer('created_at').notNull().default(sql`(unixepoch() * 1000)`),\n}, (table) =\u003e [\n  index('idx_user_notifications_inbox').on(table.userId, table.resolvedAt, table.createdAt),\n]);\n```\n\n## Notification Enum\nAdd to shared types:\n```typescript\nexport enum NotificationType {\n  CONNECTION_EXPIRED = 'connection_expired',\n  CONNECTION_REVOKED = 'connection_revoked',\n  POLL_FAILURES = 'poll_failures',\n  QUOTA_WARNING = 'quota_warning',\n}\n```\n\n## Files to Create/Modify\n- apps/worker/src/db/schema.ts - Add table definition\n- apps/worker/src/db/migrations/ - New migration\n- packages/shared/src/types/domain.ts - Add NotificationType enum\n\n## Dependencies\n- None (foundational table)\n\n## Acceptance Criteria\n- [ ] Table created with all columns\n- [ ] Unique constraint prevents duplicate active notifications\n- [ ] Index supports efficient inbox queries\n- [ ] Migration runs successfully\n- [ ] NotificationType enum exported from shared package","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:23:51.133494-06:00","updated_at":"2025-12-16T22:23:51.133494-06:00","dependencies":[{"issue_id":"zine-teq.29","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:23:51.133832-06:00","created_by":"daemon"}]}
{"id":"zine-teq.3","title":"Database Schema: subscription_items table","description":"Create the subscription_items table to track which items came from which subscription.\n\n## Table Definition\n```sql\nCREATE TABLE subscription_items (\n  id TEXT PRIMARY KEY,              -- ULID\n  subscription_id TEXT NOT NULL,    -- FK to subscriptions\n  item_id TEXT NOT NULL,            -- FK to items (canonical content)\n  provider_item_id TEXT NOT NULL,   -- YouTube video ID or Spotify episode ID\n  published_at INTEGER,             -- When item was published (ms)\n  fetched_at INTEGER NOT NULL DEFAULT (unixepoch() * 1000), -- When we fetched it\n  \n  UNIQUE(subscription_id, provider_item_id)\n);\n\nCREATE INDEX idx_subscription_items_sub ON subscription_items(subscription_id);\n```\n\n## Purpose \u0026 Distinction from provider_items_seen\nThis table answers: 'What items came from this subscription?'\n- **Scope**: Per-subscription\n- **Use case**: Display subscription history, count items from a source\n- **Lifecycle**: Hard deleted when subscription is removed\n\nvs provider_items_seen which answers: 'Have I already ingested this item for this user?'\n- **Scope**: User-wide across all providers\n- **Use case**: Idempotency check during ingestion\n- **Lifecycle**: Preserved even after unsubscribe (prevents re-ingestion on re-subscribe)\n\n## Implementation Notes\n- Links subscription → items for provenance tracking\n- provider_item_id is denormalized for efficient lookups\n- published_at cached here to enable 'newest first' sorting without joining items\n- fetched_at useful for debugging ingestion timing issues\n\n## Why Both Tables Exist\nConsider: User subscribes to Channel A, video X appears. They unsubscribe, then re-subscribe.\n- subscription_items: Deleted on unsubscribe, recreated on re-subscribe (clean slate)\n- provider_items_seen: Preserved, so video X won't re-appear in inbox\n\n## Files to Modify\n- apps/worker/src/db/schema.ts\n- apps/worker/src/db/migrations/\n\n## Acceptance Criteria\n- [ ] Table created with all columns and constraints\n- [ ] Index on subscription_id for efficient lookups\n- [ ] Migration runs successfully\n- [ ] Drizzle schema exports the table","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:07:52.213141-06:00","updated_at":"2025-12-16T22:07:52.213141-06:00","dependencies":[{"issue_id":"zine-teq.3","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:07:52.213518-06:00","created_by":"daemon"}]}
{"id":"zine-teq.4","title":"Database Schema: provider_items_seen table","description":"**IMPORTANT: This table already exists in schema.ts!** This bead migrates/extends the existing `provider_items_seen` table to add subscription tracking.\n\n## Current Table (apps/worker/src/db/schema.ts)\n```sql\nCREATE TABLE provider_items_seen (\n  id TEXT PRIMARY KEY,           -- ULID\n  user_id TEXT NOT NULL,\n  provider TEXT NOT NULL,\n  provider_item_id TEXT NOT NULL,\n  source_id TEXT,                -- FK to sources\n  first_seen_at TEXT NOT NULL,   -- ISO8601\n  UNIQUE(user_id, provider, provider_item_id)\n);\n```\n\n## Changes Required\nThe existing table is **sufficient** for the subscriptions feature. The `source_id` column can reference the new `subscriptions` table instead of `sources`.\n\n### Migration Strategy\n1. Keep existing table structure - no schema changes needed\n2. The `source_id` column will store `subscription.id` values going forward\n3. `first_seen_at` serves the same purpose as `fetched_at` in the spec\n\n### Table Purpose\nThis table prevents duplicate ingestion across the user's entire account:\n- When polling finds a video, check if `(user_id, provider, provider_item_id)` exists\n- If exists → skip (already ingested, regardless of which subscription)\n- If not exists → ingest and create record\n\n### Key Differences from Backend Spec\n| Spec Column | Existing Column | Status |\n|-------------|----------------|--------|\n| N/A | id | ✅ Exists (ULID primary key) |\n| user_id | user_id | ✅ Exists |\n| provider | provider | ✅ Exists |\n| provider_item_id | provider_item_id | ✅ Exists |\n| source_id | source_id | ✅ Exists (will store subscription IDs) |\n| N/A | first_seen_at | ✅ Exists (ISO8601 format) |\n\n### Code Updates Needed\n- Update references from `sources.id` to `subscriptions.id` in ingestion code\n- Ensure `first_seen_at` uses ISO8601 format (matches existing convention)\n\n## Files to Modify\n- apps/worker/src/db/schema.ts - No changes needed\n- apps/worker/src/ingestion/ - Use existing table structure\n\n## Acceptance Criteria\n- [ ] Verified existing table meets requirements\n- [ ] Ingestion code uses correct column names\n- [ ] FK reference points to subscriptions table conceptually (no actual FK constraint change needed)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:08:05.366652-06:00","updated_at":"2025-12-16T22:23:35.870681-06:00","dependencies":[{"issue_id":"zine-teq.4","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:08:05.367006-06:00","created_by":"daemon"}]}
{"id":"zine-teq.5","title":"Shared Types: Add subscription-related enums and schemas","description":"Add subscription-related enums and Zod validation schemas to the shared package.\n\n## CRITICAL: Timestamp Format Decision\n\n**The existing codebase uses ISO8601 strings for timestamps. The backend spec proposes Unix milliseconds.**\n\n### Resolution: Use Unix Milliseconds for New Tables\n- **New tables** (provider_connections, subscriptions, subscription_items): Use INTEGER with milliseconds\n- **Existing tables** (items, user_items, sources): Keep ISO8601 strings for backwards compatibility\n- **Conversion**: When ingesting items, convert milliseconds to ISO8601 for the items/user_items tables\n\nThis matches JavaScript's `Date.now()` and avoids conversion bugs in the new subscription system.\n\n## New Enums\n\nAdd to `packages/shared/src/types/domain.ts`:\n\n```typescript\n// Provider connection status for OAuth credentials\nexport enum ProviderConnectionStatus {\n  ACTIVE = 'ACTIVE',\n  EXPIRED = 'EXPIRED',\n  REVOKED = 'REVOKED',\n}\n\n// Subscription status for polling management\nexport enum SubscriptionStatus {\n  ACTIVE = 'ACTIVE',\n  PAUSED = 'PAUSED',\n  DISCONNECTED = 'DISCONNECTED',\n  UNSUBSCRIBED = 'UNSUBSCRIBED',\n}\n\n// Notification types for user alerts\nexport enum NotificationType {\n  CONNECTION_EXPIRED = 'connection_expired',\n  CONNECTION_REVOKED = 'connection_revoked',\n  POLL_FAILURES = 'poll_failures',\n  QUOTA_WARNING = 'quota_warning',\n}\n```\n\n## Zod Validation Schemas\n\nAdd to `packages/shared/src/schemas/index.ts`:\n\n```typescript\nimport { z } from 'zod';\nimport { Provider, ProviderConnectionStatus, SubscriptionStatus } from '../types/domain';\n\n// Provider enum schema\nexport const ProviderSchema = z.nativeEnum(Provider);\n\n// Connection status schema\nexport const ProviderConnectionStatusSchema = z.nativeEnum(ProviderConnectionStatus);\n\n// Subscription status schema\nexport const SubscriptionStatusSchema = z.nativeEnum(SubscriptionStatus);\n\n// YouTube channel ID: UC + 22 base64url characters\nexport const YouTubeChannelIdSchema = z\n  .string()\n  .regex(\n    /^UC[a-zA-Z0-9_-]{22}$/,\n    'Invalid YouTube channel ID format. Expected UC + 22 characters'\n  );\n\n// Spotify show ID: 22 alphanumeric characters\nexport const SpotifyShowIdSchema = z\n  .string()\n  .regex(\n    /^[a-zA-Z0-9]{22}$/,\n    'Invalid Spotify show ID format. Expected 22 alphanumeric characters'\n  );\n\n// Provider channel ID (polymorphic - validates based on provider)\nexport const ProviderChannelIdSchema = z.string().min(1);\n\n// Validate provider channel ID based on provider type\nexport function validateProviderChannelId(provider: Provider, channelId: string): boolean {\n  switch (provider) {\n    case Provider.YOUTUBE:\n      return YouTubeChannelIdSchema.safeParse(channelId).success;\n    case Provider.SPOTIFY:\n      return SpotifyShowIdSchema.safeParse(channelId).success;\n    default:\n      return true; // RSS/Substack don't have strict formats\n  }\n}\n```\n\n## tRPC Input Schemas\n\nThese schemas define the API contract with the frontend:\n\n```typescript\n// Connection management\nexport const RegisterOAuthStateInput = z.object({\n  provider: ProviderSchema,\n  state: z.string().uuid(),\n});\n\nexport const OAuthCallbackInput = z.object({\n  provider: ProviderSchema,\n  code: z.string().min(1),\n  state: z.string().uuid(),\n  codeVerifier: z.string().min(43).max(128),\n});\n\nexport const DisconnectInput = z.object({\n  provider: ProviderSchema,\n});\n\n// Subscription management\nexport const AddSubscriptionInput = z.object({\n  provider: ProviderSchema,\n  providerChannelId: z.string().min(1),\n  name: z.string().optional(),\n  imageUrl: z.string().url().optional(),\n});\n\nexport const RemoveSubscriptionInput = z.object({\n  subscriptionId: z.string().ulid(),\n});\n\nexport const PauseResumeInput = z.object({\n  subscriptionId: z.string().ulid(),\n});\n\nexport const SyncNowInput = z.object({\n  subscriptionId: z.string().ulid(),\n});\n\nexport const ListSubscriptionsInput = z.object({\n  provider: ProviderSchema.optional(),\n  status: SubscriptionStatusSchema.optional(),\n  limit: z.number().min(1).max(100).default(50),\n  cursor: z.string().ulid().optional(),\n});\n\n// Discovery\nexport const DiscoverAvailableInput = z.object({\n  provider: ProviderSchema,\n});\n\nexport const SearchChannelsInput = z.object({\n  provider: ProviderSchema,\n  query: z.string().min(1).max(100),\n  limit: z.number().min(1).max(50).default(20),\n});\n```\n\n## Type Guards\n\n```typescript\nexport function isProviderConnectionStatus(value: unknown): value is ProviderConnectionStatus {\n  return Object.values(ProviderConnectionStatus).includes(value as ProviderConnectionStatus);\n}\n\nexport function isSubscriptionStatus(value: unknown): value is SubscriptionStatus {\n  return Object.values(SubscriptionStatus).includes(value as SubscriptionStatus);\n}\n```\n\n## Files to Modify\n- packages/shared/src/types/domain.ts - Add enums\n- packages/shared/src/schemas/index.ts - Add Zod schemas\n- packages/shared/src/index.ts - Export new types and schemas\n\n## Dependencies\nNone - this is foundational\n\n## Acceptance Criteria\n- [ ] All enums exported and documented\n- [ ] Zod schemas for provider channel IDs with validation\n- [ ] tRPC input schemas for all endpoints\n- [ ] Type guards for runtime validation\n- [ ] Package builds successfully\n- [ ] Types importable from @zine/shared","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:08:22.273729-06:00","updated_at":"2025-12-16T22:25:50.99341-06:00","dependencies":[{"issue_id":"zine-teq.5","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:08:22.274098-06:00","created_by":"daemon"}]}
{"id":"zine-teq.6","title":"Token Encryption: AES-256-GCM utilities","description":"Implement encryption utilities for secure OAuth token storage using AES-256-GCM.\n\n## Why AES-256-GCM\n- **AES-256**: Industry standard, 256-bit key provides excellent security margin\n- **GCM mode**: Provides both confidentiality AND integrity (authenticated encryption)\n- **Web Crypto API**: Available in Cloudflare Workers, no external dependencies\n\n## Implementation\n\n### apps/worker/src/lib/crypto.ts\n```typescript\n/**\n * Encrypt a string using AES-256-GCM\n * Returns format: {iv}:{ciphertext} (both hex-encoded)\n * \n * For key rotation support, can be extended to:\n * v{version}:{iv}:{ciphertext}\n */\nexport async function encrypt(plaintext: string, keyHex: string): Promise\u003cstring\u003e {\n  const key = await importKey(keyHex);\n  const iv = crypto.getRandomValues(new Uint8Array(12)); // 96-bit IV for GCM\n  const encoded = new TextEncoder().encode(plaintext);\n  \n  const ciphertext = await crypto.subtle.encrypt(\n    { name: 'AES-GCM', iv },\n    key,\n    encoded\n  );\n  \n  return `${bytesToHex(iv)}:${bytesToHex(new Uint8Array(ciphertext))}`;\n}\n\n/**\n * Decrypt a string encrypted with encrypt()\n * Throws on invalid format, wrong key, or tampering (GCM auth tag)\n */\nexport async function decrypt(encrypted: string, keyHex: string): Promise\u003cstring\u003e {\n  const [ivHex, ciphertextHex] = encrypted.split(':');\n  if (!ivHex || !ciphertextHex) {\n    throw new CryptoError('INVALID_FORMAT', 'Encrypted data has invalid format');\n  }\n  \n  const key = await importKey(keyHex);\n  const iv = hexToBytes(ivHex);\n  const ciphertext = hexToBytes(ciphertextHex);\n  \n  try {\n    const decrypted = await crypto.subtle.decrypt(\n      { name: 'AES-GCM', iv },\n      key,\n      ciphertext\n    );\n    return new TextDecoder().decode(decrypted);\n  } catch (e) {\n    throw new CryptoError('DECRYPTION_FAILED', 'Failed to decrypt (wrong key or corrupted data)');\n  }\n}\n\nasync function importKey(keyHex: string): Promise\u003cCryptoKey\u003e {\n  const keyBytes = hexToBytes(keyHex);\n  if (keyBytes.length !== 32) {\n    throw new CryptoError('INVALID_KEY', 'Key must be 256 bits (64 hex characters)');\n  }\n  return crypto.subtle.importKey('raw', keyBytes, 'AES-GCM', false, ['encrypt', 'decrypt']);\n}\n```\n\n## Error Types\n```typescript\nexport class CryptoError extends Error {\n  constructor(\n    public code: 'INVALID_FORMAT' | 'INVALID_KEY' | 'DECRYPTION_FAILED' | 'KEY_VERSION_NOT_FOUND',\n    message: string\n  ) {\n    super(message);\n    this.name = 'CryptoError';\n  }\n}\n```\n\n## Environment Setup\nAdd to wrangler.toml secrets:\n```\nENCRYPTION_KEY = \"...\" # 64 hex characters (256 bits)\n```\n\nGenerate key: `openssl rand -hex 32`\n\n## Key Rotation Preparation\nThe format can be extended to `v{version}:{iv}:{ciphertext}` to support:\n1. Deploy new key with version 2\n2. New encryptions use v2\n3. Decryptions check version, use appropriate key\n4. Background job re-encrypts old tokens\n5. Retire v1 key after grace period\n\n## Files to Create/Modify\n- apps/worker/src/lib/crypto.ts - New file with encrypt/decrypt\n- apps/worker/wrangler.toml - Document ENCRYPTION_KEY secret\n- apps/worker/worker-configuration.d.ts - Add ENCRYPTION_KEY to Env type\n\n## Acceptance Criteria\n- [ ] encrypt() produces different output each call (random IV)\n- [ ] decrypt(encrypt(x)) === x for any string\n- [ ] decrypt() throws CryptoError on wrong key\n- [ ] decrypt() throws CryptoError on tampered ciphertext (GCM integrity)\n- [ ] Works in Cloudflare Workers environment\n- [ ] Unit tests cover happy path and error cases","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:08:41.897439-06:00","updated_at":"2025-12-16T22:08:41.897439-06:00","dependencies":[{"issue_id":"zine-teq.6","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:08:41.897818-06:00","created_by":"daemon"}]}
{"id":"zine-teq.7","title":"OAuth: State management for CSRF protection","description":"Implement OAuth state parameter management using Cloudflare KV for CSRF protection.\n\n## Background\nThe OAuth 'state' parameter prevents CSRF attacks where an attacker tricks a user into connecting the attacker's account. The flow:\n1. Client generates state, sends to server with registerState\n2. Server stores state → userId mapping in KV\n3. Client includes state in OAuth redirect\n4. Provider callback includes state\n5. Server validates state matches userId before exchanging tokens\n\n## Implementation\n\n### State Registration Endpoint\n```typescript\n// apps/worker/src/trpc/routers/connections.ts\nregisterState: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema,\n    state: z.string().min(32).max(128), // Client-generated, cryptographically random\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    const key = `oauth:state:${input.state}`;\n    \n    // Check for replay attacks\n    const existing = await ctx.env.KV.get(key);\n    if (existing) {\n      throw new TRPCError({ \n        code: 'BAD_REQUEST', \n        message: 'State already registered' \n      });\n    }\n    \n    // Store with 30 minute expiry (OAuth flow should complete faster)\n    await ctx.env.KV.put(key, ctx.userId, { expirationTtl: 1800 });\n    \n    return { success: true };\n  }),\n```\n\n### State Validation (in callback)\n```typescript\n// Inside callback mutation\nconst storedUserId = await ctx.env.KV.get(`oauth:state:${input.state}`);\nif (!storedUserId) {\n  throw new TRPCError({ code: 'BAD_REQUEST', message: 'State expired or invalid' });\n}\nif (storedUserId !== ctx.userId) {\n  throw new TRPCError({ code: 'BAD_REQUEST', message: 'State mismatch' });\n}\n// Delete after successful validation\nawait ctx.env.KV.delete(`oauth:state:${input.state}`);\n```\n\n## KV Namespace Setup\nAdd to wrangler.toml:\n```toml\n[[kv_namespaces]]\nbinding = \"KV\"\nid = \"...\" # Create with: wrangler kv:namespace create \"KV\"\n```\n\n## Rate Limiting\nApply rate limits to prevent abuse:\n| Endpoint        | Window   | Max Requests | Key    |\n| --------------- | -------- | ------------ | ------ |\n| registerState   | 1 minute | 5            | userId |\n\n## Why Not Server-Generated State?\nThe spec emphasizes client-generated state because:\n1. Client already generates PKCE verifier (similar security model)\n2. Reduces server round-trips\n3. Client can correlate state with its pending auth flow\n4. Follows OAuth 2.1 best practices\n\n## Files to Modify\n- apps/worker/src/trpc/routers/connections.ts - Add registerState procedure\n- apps/worker/wrangler.toml - Add KV namespace binding\n- apps/worker/worker-configuration.d.ts - Add KV to Env type\n\n## Acceptance Criteria\n- [ ] registerState stores state → userId in KV with TTL\n- [ ] Duplicate state registration is rejected\n- [ ] Callback validates state matches authenticated user\n- [ ] State is deleted after successful callback\n- [ ] Rate limiting prevents state flooding\n- [ ] Integration tests cover CSRF attack scenario","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:08:59.621916-06:00","updated_at":"2025-12-16T22:08:59.621916-06:00","dependencies":[{"issue_id":"zine-teq.7","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:08:59.622288-06:00","created_by":"daemon"}]}
{"id":"zine-teq.8","title":"OAuth: Token exchange endpoint (callback)","description":"Implement the OAuth callback endpoint that exchanges authorization code + PKCE verifier for tokens.\n\n## PKCE Security Model\n**Critical**: The code verifier is generated on the mobile client and NEVER stored on the server. This ensures that even if an attacker intercepts the authorization code, they cannot exchange it without the verifier.\n\nFlow:\n1. Mobile generates code_verifier (random 43-128 chars)\n2. Mobile computes code_challenge = BASE64URL(SHA256(code_verifier))\n3. Mobile redirects to provider with code_challenge\n4. Provider returns code to mobile via redirect\n5. Mobile calls our callback with code + code_verifier\n6. Server exchanges code + code_verifier for tokens\n\n## Implementation\n\n### Token Exchange Endpoint\n```typescript\n// apps/worker/src/trpc/routers/connections.ts\ncallback: protectedProcedure\n  .input(z.object({\n    provider: ProviderSchema,\n    code: z.string(),\n    state: z.string(),\n    codeVerifier: z.string().min(43).max(128), // PKCE verifier\n  }))\n  .mutation(async ({ ctx, input }) =\u003e {\n    // 1. Validate state (CSRF protection)\n    const storedUserId = await ctx.env.KV.get(`oauth:state:${input.state}`);\n    if (storedUserId !== ctx.userId) {\n      throw new TRPCError({ code: 'BAD_REQUEST', message: 'Invalid state' });\n    }\n    \n    // 2. Exchange code + verifier for tokens\n    const tokens = await exchangeCodeForTokens(\n      input.provider,\n      input.code,\n      input.codeVerifier,\n      ctx.env\n    );\n    \n    // 3. Get provider user info (for provider_user_id)\n    const providerUser = await getProviderUserInfo(input.provider, tokens.access_token);\n    \n    // 4. Store encrypted tokens (upsert)\n    await ctx.db.insert(providerConnections).values({\n      id: ulid(),\n      userId: ctx.userId,\n      provider: input.provider,\n      providerUserId: providerUser.id,\n      accessToken: await encrypt(tokens.access_token, ctx.env.ENCRYPTION_KEY),\n      refreshToken: await encrypt(tokens.refresh_token, ctx.env.ENCRYPTION_KEY),\n      tokenExpiresAt: Date.now() + tokens.expires_in * 1000, // Convert to ms\n      scopes: tokens.scope,\n      status: 'ACTIVE',\n      connectedAt: Date.now(),\n    }).onConflictDoUpdate({\n      target: [providerConnections.userId, providerConnections.provider],\n      set: {\n        providerUserId: providerUser.id,\n        accessToken: await encrypt(tokens.access_token, ctx.env.ENCRYPTION_KEY),\n        refreshToken: await encrypt(tokens.refresh_token, ctx.env.ENCRYPTION_KEY),\n        tokenExpiresAt: Date.now() + tokens.expires_in * 1000,\n        scopes: tokens.scope,\n        status: 'ACTIVE',\n        lastRefreshedAt: Date.now(),\n      },\n    });\n    \n    // 5. Clean up state\n    await ctx.env.KV.delete(`oauth:state:${input.state}`);\n    \n    return { success: true, provider: input.provider };\n  }),\n```\n\n### Provider-Specific Token Exchange\n```typescript\n// apps/worker/src/lib/oauth.ts\nasync function exchangeCodeForTokens(\n  provider: Provider,\n  code: string,\n  codeVerifier: string,\n  env: Env\n): Promise\u003cTokenResponse\u003e {\n  const config = getProviderConfig(provider, env);\n  \n  const response = await fetch(config.tokenUrl, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n    body: new URLSearchParams({\n      grant_type: 'authorization_code',\n      code,\n      redirect_uri: config.redirectUri,\n      client_id: config.clientId,\n      client_secret: config.clientSecret,\n      code_verifier: codeVerifier, // PKCE\n    }),\n  });\n  \n  if (!response.ok) {\n    const error = await response.json();\n    throw new OAuthError(error.error, error.error_description);\n  }\n  \n  return response.json();\n}\n```\n\n## Provider Configuration\n| Provider | Token URL | Redirect URI |\n|----------|-----------|--------------|\n| YouTube  | https://oauth2.googleapis.com/token | {BASE_URL}/auth/youtube/callback |\n| Spotify  | https://accounts.spotify.com/api/token | {BASE_URL}/auth/spotify/callback |\n\n## Rate Limiting\n| Endpoint | Window | Max | Key |\n|----------|--------|-----|-----|\n| callback | 1 min  | 10  | userId |\n\n## Error Handling\n- Invalid code → 'Authorization code expired or invalid'\n- Invalid verifier → 'PKCE verification failed'\n- Provider error → Forward provider's error_description\n\n## Files to Create/Modify\n- apps/worker/src/trpc/routers/connections.ts - Add callback procedure\n- apps/worker/src/lib/oauth.ts - Token exchange utilities\n\n## Dependencies\n- zine-teq.6 (encryption utilities)\n- zine-teq.7 (state management)\n- zine-teq.1 (provider_connections table)\n\n## Acceptance Criteria\n- [ ] Successfully exchanges code for tokens with both providers\n- [ ] Tokens stored encrypted in database\n- [ ] State validated and deleted after use\n- [ ] PKCE verifier passed to provider correctly\n- [ ] Reconnection updates existing connection (upsert)\n- [ ] Integration tests cover successful and failed exchanges","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:09:23.606107-06:00","updated_at":"2025-12-16T22:09:23.606107-06:00","dependencies":[{"issue_id":"zine-teq.8","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:09:23.606478-06:00","created_by":"daemon"},{"issue_id":"zine-teq.8","depends_on_id":"zine-teq.6","type":"blocks","created_at":"2025-12-16T22:19:04.763407-06:00","created_by":"daemon"},{"issue_id":"zine-teq.8","depends_on_id":"zine-teq.7","type":"blocks","created_at":"2025-12-16T22:19:04.813353-06:00","created_by":"daemon"},{"issue_id":"zine-teq.8","depends_on_id":"zine-teq.1","type":"blocks","created_at":"2025-12-16T22:19:04.860592-06:00","created_by":"daemon"}]}
{"id":"zine-teq.9","title":"OAuth: Token refresh with distributed locking","description":"Implement proactive token refresh with distributed locking to prevent race conditions.\n\n## Why Proactive Refresh\nTokens expire in ~1 hour for both YouTube and Spotify. If we wait until they expire:\n- Mid-operation failures when token expires during a batch\n- Multiple workers might try to refresh simultaneously\n- Race conditions can cause token invalidation\n\n**Solution**: Refresh 5 minutes before expiry, with distributed locks.\n\n## Implementation\n\n### Token Refresh Service\n```typescript\n// apps/worker/src/lib/token-refresh.ts\nconst REFRESH_BUFFER_MS = 5 * 60 * 1000; // 5 minutes\nconst REFRESH_LOCK_TTL = 30; // seconds\n\nexport async function getValidAccessToken(\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cstring\u003e {\n  const now = Date.now();\n  \n  // Check if token is still valid (with buffer)\n  if (connection.tokenExpiresAt - REFRESH_BUFFER_MS \u003e now) {\n    return decrypt(connection.accessToken, env.ENCRYPTION_KEY);\n  }\n  \n  // Need to refresh - acquire distributed lock\n  return refreshWithLock(connection, env);\n}\n\nasync function refreshWithLock(\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cstring\u003e {\n  const lockKey = `token:refresh:${connection.id}`;\n  \n  // Try to acquire lock\n  const lockAcquired = await tryAcquireLock(env.KV, lockKey, REFRESH_LOCK_TTL);\n  \n  if (!lockAcquired) {\n    // Another worker is refreshing - wait and read updated token\n    await sleep(2000);\n    const updated = await getConnectionById(connection.id, env);\n    if (updated \u0026\u0026 updated.tokenExpiresAt \u003e Date.now()) {\n      return decrypt(updated.accessToken, env.ENCRYPTION_KEY);\n    }\n    throw new TokenRefreshError('REFRESH_IN_PROGRESS', 'Token refresh in progress by another worker');\n  }\n  \n  try {\n    const refreshed = await refreshProviderToken(connection, env);\n    await persistRefreshedTokens(connection.id, refreshed, env);\n    return refreshed.accessToken;\n  } finally {\n    await releaseLock(env.KV, lockKey);\n  }\n}\n```\n\n### Provider-Specific Refresh\n```typescript\nasync function refreshProviderToken(\n  connection: ProviderConnection,\n  env: Env\n): Promise\u003cRefreshedTokens\u003e {\n  const config = getProviderConfig(connection.provider, env);\n  const currentRefreshToken = await decrypt(connection.refreshToken, env.ENCRYPTION_KEY);\n  \n  const response = await fetch(config.tokenUrl, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },\n    body: new URLSearchParams({\n      grant_type: 'refresh_token',\n      refresh_token: currentRefreshToken,\n      client_id: config.clientId,\n      client_secret: config.clientSecret,\n    }),\n  });\n  \n  if (!response.ok) {\n    const error = await response.json();\n    // Mark connection as expired if refresh token is invalid\n    if (error.error === 'invalid_grant') {\n      await markConnectionExpired(connection.id, env);\n    }\n    throw new TokenRefreshError(error.error, error.error_description);\n  }\n  \n  const tokens = await response.json();\n  \n  // Important: Spotify may rotate refresh tokens\n  return {\n    accessToken: tokens.access_token,\n    refreshToken: tokens.refresh_token || currentRefreshToken, // Keep old if not rotated\n    expiresAt: Date.now() + tokens.expires_in * 1000,\n  };\n}\n```\n\n### Lock Utilities\n```typescript\n// apps/worker/src/lib/locks.ts\nexport async function tryAcquireLock(\n  kv: KVNamespace,\n  key: string,\n  ttlSeconds: number\n): Promise\u003cboolean\u003e {\n  const existing = await kv.get(key);\n  if (existing) {\n    // Check if lock is stale (shouldn't happen with TTL, but defensive)\n    const lockTime = parseInt(existing, 10);\n    if (Date.now() - lockTime \u003c ttlSeconds * 1000) {\n      return false;\n    }\n  }\n  \n  // Set lock with TTL (auto-expires if worker crashes)\n  await kv.put(key, Date.now().toString(), { expirationTtl: ttlSeconds });\n  return true;\n}\n\nexport async function releaseLock(kv: KVNamespace, key: string): Promise\u003cvoid\u003e {\n  await kv.delete(key);\n}\n```\n\n## Refresh Token Rotation Handling\nSpotify rotates refresh tokens. YouTube typically doesn't. \n**Critical**: Always persist the new refresh token if provided, keeping the old one only if the provider didn't return a new one.\n\n## Error States\n| Error | Cause | Action |\n|-------|-------|--------|\n| invalid_grant | Refresh token revoked/expired | Mark EXPIRED, notify user |\n| rate_limited | Too many refresh attempts | Exponential backoff |\n| network_error | Provider unreachable | Retry with backoff |\n\n## Files to Create/Modify\n- apps/worker/src/lib/token-refresh.ts - Main refresh logic\n- apps/worker/src/lib/locks.ts - Distributed lock utilities\n\n## Dependencies\n- zine-teq.6 (encryption utilities)\n- zine-teq.1 (provider_connections table)\n\n## Acceptance Criteria\n- [ ] Tokens refreshed proactively before expiry\n- [ ] Distributed lock prevents concurrent refreshes\n- [ ] Rotated refresh tokens are persisted\n- [ ] Invalid refresh tokens mark connection EXPIRED\n- [ ] Workers waiting on lock get updated token\n- [ ] Unit tests mock provider responses","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T22:09:46.702078-06:00","updated_at":"2025-12-16T22:09:46.702078-06:00","dependencies":[{"issue_id":"zine-teq.9","depends_on_id":"zine-teq","type":"parent-child","created_at":"2025-12-16T22:09:46.702442-06:00","created_by":"daemon"},{"issue_id":"zine-teq.9","depends_on_id":"zine-teq.6","type":"blocks","created_at":"2025-12-16T22:19:08.771538-06:00","created_by":"daemon"},{"issue_id":"zine-teq.9","depends_on_id":"zine-teq.1","type":"blocks","created_at":"2025-12-16T22:19:08.820337-06:00","created_by":"daemon"}]}
